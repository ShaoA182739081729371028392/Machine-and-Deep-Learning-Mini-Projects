{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Disaster Prediction - TensorFlow",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23e7fdbe9229422ba3eea4623f49d06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_037dfe01cd83412e80d62a172c2f9f18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_adad298e2a734165b0fc010d65488997",
              "IPY_MODEL_f030a6124aa7479b848b218aed55ee87"
            ]
          }
        },
        "037dfe01cd83412e80d62a172c2f9f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adad298e2a734165b0fc010d65488997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9dbbf8271d645ff8eac82fdafcd9d8c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3263,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3263,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_506d07e9cf9a46b7b4ef69478518bdf9"
          }
        },
        "f030a6124aa7479b848b218aed55ee87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b9f938ea550448696937c3624735af0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3263/3263 [00:10&lt;00:00, 321.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa6fd25752374f978a66ff1f97d9106d"
          }
        },
        "e9dbbf8271d645ff8eac82fdafcd9d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "506d07e9cf9a46b7b4ef69478518bdf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b9f938ea550448696937c3624735af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa6fd25752374f978a66ff1f97d9106d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfe49ee4249845da81021402a1aae895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0389e2dde4b245758259655136f04b07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8725763d75754d1fa6f3dd64fbeda6e8",
              "IPY_MODEL_2b099e3cfcd1464facb3740d1c5ac983"
            ]
          }
        },
        "0389e2dde4b245758259655136f04b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8725763d75754d1fa6f3dd64fbeda6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee718cc06db0481f8f80efb0616d8e03",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 204,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 204,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_851a4b9d0cfe4be0ae8ed2efcb3cae78"
          }
        },
        "2b099e3cfcd1464facb3740d1c5ac983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7f327e97d75940aa93b58d580bbe003d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 204/204 [01:36&lt;00:00,  2.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_038fea79aad04c8791ceb35933a7b587"
          }
        },
        "ee718cc06db0481f8f80efb0616d8e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "851a4b9d0cfe4be0ae8ed2efcb3cae78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f327e97d75940aa93b58d580bbe003d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "038fea79aad04c8791ceb35933a7b587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB3cvpuoD2Wf"
      },
      "source": [
        "# Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZCh8w4SEDE_"
      },
      "source": [
        "%%capture\r\n",
        "!pip install kaggle\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow.keras as keras\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import sklearn\r\n",
        "import re\r\n",
        "import collections\r\n",
        "import math\r\n",
        "import copy\r\n",
        "import tqdm.notebook as tqdm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random\r\n",
        "import nltk\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "!pip install transformers\r\n",
        "import transformers\r\n",
        "!pip install livelossplot\r\n",
        "import livelossplot \r\n",
        "nltk.download(\"punkt\")\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL__ukKdEBn6"
      },
      "source": [
        "!mkdir /root/.kaggle/\r\n",
        "!cp -f ./kaggle.json /root/.kaggle/kaggle.json\r\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpbjKVdUDycQ"
      },
      "source": [
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjuY17sN8MNy"
      },
      "source": [
        "# Load in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlNgw3EOZ2wi"
      },
      "source": [
        "# HYPER PARAMETERS\n",
        "NUM_CORES = 8\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_ATT_HEADS = 4\n",
        "TEST_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4ScjcHP5flA"
      },
      "source": [
        "sample_submission = pd.read_csv(\"./sample_submission.csv\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4SevCl28Lxy"
      },
      "source": [
        "train_pd = pd.read_csv(\"./train.csv\")\r\n",
        "test_pd = pd.read_csv(\"./test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKIJnorOAAsf"
      },
      "source": [
        "train_tweets = [text for text in train_pd['text']]\r\n",
        "train_targets = [target for target in train_pd['target']]\r\n",
        "unique_tweets = []\r\n",
        "unique_targets = []\r\n",
        "for idx in range(len(train_tweets)):\r\n",
        "  if train_tweets[idx] not in unique_tweets:\r\n",
        "    unique_tweets += [train_tweets[idx]]\r\n",
        "    unique_targets += [train_targets[idx]]\r\n",
        "# Filter out not unique Tweets\r\n",
        "train_tweets = unique_tweets\r\n",
        "train_targets = unique_targets\r\n",
        "\r\n",
        "test_tweets = [text for text in test_pd['text']]\r\n",
        "test_ids = [id for id in test_pd['id']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQlbCchpInaw",
        "outputId": "9c7c74d3-ff18-45c7-cbd3-565495abe596"
      },
      "source": [
        "collections.Counter(train_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 4305, 1: 3198})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4hll-OXb1qJ"
      },
      "source": [
        "splitter = sklearn.model_selection.StratifiedShuffleSplit(n_splits = 1, test_size = 0.01, train_size = 0.99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmUmEkO-VPns"
      },
      "source": [
        "for train_idx, test_idx in splitter.split(train_tweets, train_targets):\n",
        "  continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk9P1C_N6fTa"
      },
      "source": [
        "count = 0\n",
        "training_tweets_tmp = []\n",
        "training_targets_tmp = []\n",
        "for idx in train_idx:\n",
        "  training_tweets_tmp += [train_tweets[idx]]\n",
        "  training_targets_tmp += [train_targets[idx]]\n",
        "val_tweets_tmp = []\n",
        "val_targets_tmp = []\n",
        "for idx in test_idx:\n",
        "  val_tweets_tmp += [train_tweets[idx]]\n",
        "  val_targets_tmp += [train_targets[idx]]\n",
        "val_tweets = val_tweets_tmp\n",
        "val_targets = val_targets_tmp\n",
        "train_tweets = training_tweets_tmp\n",
        "train_targets = training_targets_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJc3LESXMGy1"
      },
      "source": [
        "def process_tweets(corpus):\r\n",
        "  stopwords = nltk.corpus.stopwords.words('english')\r\n",
        "  tokenized_corpus = []\r\n",
        "  for tweets in tqdm.tqdm(corpus):\r\n",
        "    processed_tweets = re.sub(r'[^\\w\\s]', \"\", str.lower(tweets))\r\n",
        "    tokenized_corpus += [processed_tweets]\r\n",
        "  return tokenized_corpus\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grr-I_huM1NH"
      },
      "source": [
        "processed_train = process_tweets(train_tweets)\n",
        "processed_val = process_tweets(val_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "23e7fdbe9229422ba3eea4623f49d06f",
            "037dfe01cd83412e80d62a172c2f9f18",
            "adad298e2a734165b0fc010d65488997",
            "f030a6124aa7479b848b218aed55ee87",
            "e9dbbf8271d645ff8eac82fdafcd9d8c",
            "506d07e9cf9a46b7b4ef69478518bdf9",
            "1b9f938ea550448696937c3624735af0",
            "fa6fd25752374f978a66ff1f97d9106d"
          ]
        },
        "id": "pO7b1l684hsl",
        "outputId": "95d6ec41-5298-480e-dc49-4d621d9c9be4"
      },
      "source": [
        "processed_test = process_tweets(test_tweets)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23e7fdbe9229422ba3eea4623f49d06f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3263.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBocKJAEWQnW"
      },
      "source": [
        "class TrainDataset(keras.utils.Sequence):\n",
        "  def __init__(self, tweets, targets, batch_size):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets\n",
        "    self.batch_size = batch_size\n",
        "    self.cur_idx = 0\n",
        "  def __len__(self):\n",
        "    return len(self.tweets) // self.batch_size\n",
        "  def __getitem__(self, idx):\n",
        "    tweets = self.tweets[self.cur_idx * self.batch_size: (self.cur_idx + 1) * self.batch_size]\n",
        "    targets = np.array(self.targets[self.cur_idx * self.batch_size: (self.cur_idx + 1) * self.batch_size])\n",
        "    self.cur_idx += 1\n",
        "    if self.cur_idx >= self.__len__():\n",
        "      self.cur_idx = 0\n",
        "    return tweets, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dH555NDXoaA"
      },
      "source": [
        "class TestDataset(keras.utils.Sequence):\n",
        "  def __init__(self, tweets, ids, batch_size):\n",
        "    self.tweets = tweets\n",
        "    self.ids = ids\n",
        "    self.batch_size = batch_size\n",
        "    self.cur_idx = 0\n",
        "  def reset(self):\n",
        "    '''\n",
        "    Resets the current_index\n",
        "    '''\n",
        "    self.cur_idx = 0\n",
        "  def __len__(self):\n",
        "   return len(self.tweets) // self.batch_size + 1\n",
        "  def __getitem__(self, idx):\n",
        "    if self.cur_idx == self.__len__():\n",
        "      tweets = self.tweets[self.cur_idx * self.batch_size:]\n",
        "      ids = np.array(self.ids[self.cur_idx * self.batch_size: ])\n",
        "    else:  \n",
        "      tweets = self.tweets[self.cur_idx * self.batch_size: (self.cur_idx + 1) * self.batch_size]\n",
        "      ids = np.array(self.ids[self.cur_idx * self.batch_size: (self.cur_idx + 1) * self.batch_size])\n",
        "    self.cur_idx += 1\n",
        "    if self.cur_idx >= self.__len__():\n",
        "      print(\"Iterated through Test Dataset more than once. Uh oh.\")\n",
        "      self.cur_idx = 0\n",
        "      print(\"WARNING: Iterating again.\")\n",
        "    return tweets, ids\n",
        "    \n",
        "\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKcY7-mvZk5w"
      },
      "source": [
        "train_dataloader = TrainDataset(processed_train, train_targets, BATCH_SIZE)\n",
        "test_dataloader = TestDataset(processed_test, test_ids, BATCH_SIZE)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iYtWSsNNtgQ"
      },
      "source": [
        "# QANet Transformer From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN31gZvvn7e-"
      },
      "source": [
        "class QAConv(keras.layers.Layer):\n",
        "  def __init__(self, in_features, regularizer):\n",
        "    super().__init__()\n",
        "    self.regularizer = regularizer\n",
        "    self.in_features = in_features\n",
        "    self.conv = keras.layers.Conv1D(self.in_features, 7, padding = 'same', activation= 'relu', kernel_regularizer = tf.keras.regularizers.l2(self.regularizer))\n",
        "    self.layer_norm = keras.layers.LayerNormalization()\n",
        "  def call(self, x):\n",
        "    return self.conv(self.layer_norm(x)) + x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Ao8M49ervT"
      },
      "source": [
        "class MultiHeadAttention(keras.layers.Layer):\n",
        "  def __init__(self, in_dim, inner_dim, num_heads, regularizer):\n",
        "    super().__init__()\n",
        "    self.regularizer = regularizer\n",
        "    self.in_dim = in_dim\n",
        "    self.inner_dim = inner_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.K = keras.layers.Dense(self.inner_dim * self.num_heads, kernel_regularizer = tf.keras.regularizers.l2(self.regularizer)) \n",
        "    self.V = keras.layers.Dense(self.inner_dim * self.num_heads, kernel_regularizer = tf.keras.regularizers.l2(self.regularizer))\n",
        "    self.Q = keras.layers.Dense(self.inner_dim * self.num_heads, kernel_regularizer = tf.keras.regularizers.l2(self.regularizer))\n",
        "    self.Linear = keras.layers.Dense(self.in_dim, kernel_regularizer = tf.keras.regularizers.l2(self.regularizer))\n",
        "  def call(self, x):\n",
        "    B, L, _ = x.shape\n",
        "\n",
        "    Keys = self.K(x)\n",
        "    Values = self.V(x)\n",
        "    Queries = self.Q(x) # (B, L, self.inner_dim * self.num_heads)\n",
        "    # Reshape Tensors \n",
        "    Keys = tf.reshape(Keys, (B, L, self.num_heads, self.inner_dim))\n",
        "    Values = tf.reshape(Values, (B, L, self.num_heads, self.inner_dim))\n",
        "    Queries = tf.reshape(Queries, (B, L, self.num_heads, self.inner_dim))\n",
        "    # Transpose Tensors\n",
        "    Keys = tf.transpose(Keys, perm = (0, 2, 1, 3))\n",
        "    Values = tf.transpose(Values, perm = (0, 2, 1, 3))\n",
        "    Queries = tf.transpose(Queries, perm = (0, 2, 1, 3))\n",
        "    # Reshape Again\n",
        "    Keys = tf.reshape(Keys, (B * self.num_heads, L, self.inner_dim))\n",
        "    Values = tf.reshape(Values, (B * self.num_heads, L, self.inner_dim))\n",
        "    Queries = tf.reshape(Queries, (B * self.num_heads, L, self.inner_dim)) # (BH, L, I)\n",
        "    # Att Mat Dot Product\n",
        "    att_mat = tf.keras.activations.softmax(tf.matmul(Keys, tf.transpose(Queries, perm = (0, 2, 1))) / math.sqrt(self.inner_dim))\n",
        "    att_scores = tf.matmul(att_mat, Values) # (BH, L, I)\n",
        "    # Reshape Tensors \n",
        "    att_scores = tf.reshape(att_scores, (B, self.num_heads, L, self.inner_dim))\n",
        "    att_scores = tf.transpose(att_scores, perm = (0, 2, 1, 3))\n",
        "    att_scores = tf.reshape(att_scores, (B, L, self.num_heads * self.inner_dim))\n",
        "    return self.Linear(att_scores) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTsekqIke28U"
      },
      "source": [
        "class QANetEncoder(keras.layers.Layer):\n",
        "  def __init__(self, in_dim, inner_dim, num_heads, num_convs, regularizer, drop_prob = 0.1):\n",
        "    super().__init__()\n",
        "    self.regularizer = regularizer\n",
        "    self.drop_prob = drop_prob\n",
        "    self.in_dim = in_dim\n",
        "    self.inner_dim = inner_dim \n",
        "    self.num_heads = num_heads\n",
        "    self.num_convs = num_convs\n",
        "    # Prepare Convolution Layers \n",
        "    self.conv = keras.Sequential([\n",
        "        QAConv(self.in_dim, self.regularizer) for i in range(self.num_convs)\n",
        "    ])\n",
        "    # Prepare MultiHead Attentions\n",
        "    self.MHA = MultiHeadAttention(self.in_dim, self.inner_dim, self.num_heads, self.regularizer)\n",
        "    self.MHALayerNorm = keras.layers.LayerNormalization()\n",
        "    # Prepare Linear Layer\n",
        "    self.Linear = keras.layers.Dense(self.in_dim, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(self.regularizer))\n",
        "    self.Dropout = keras.layers.Dropout(self.drop_prob)\n",
        "    self.LinearLayerNorm = keras.layers.LayerNormalization()\n",
        "    \n",
        "  def call(self, x):\n",
        "    '''\n",
        "    Run through the attentiion mechanism\n",
        "    '''\n",
        "    pos_encoded = self._add_pos_embed(x)\n",
        "    # Convolve Features \n",
        "    convolved = self.conv(pos_encoded)\n",
        "    # MHA\n",
        "    attended = self.Dropout(self.MHA(self.MHALayerNorm(convolved)) + convolved)\n",
        "    # Linear \n",
        "    processed = self.Linear(self.LinearLayerNorm(attended)) + attended\n",
        "    return processed\n",
        "  def _add_pos_embed(self, x):\n",
        "    '''\n",
        "    Adds Positional embeddings to a given tensor\n",
        "    x: Tensor(B, L, C)\n",
        "    '''\n",
        "    B, L, C = x.shape\n",
        "    pos_embeddings = np.zeros((L, C), dtype = np.float32)\n",
        "    for pos in range(L):\n",
        "      for i in range(0, C, 2):\n",
        "        pos_embeddings[pos, i] = math.sin(pos / 10000 ** (2 * i / self.in_dim))\n",
        "        pos_embeddings[pos, i + 1] = math.cos(pos / 10000 ** (2 * (i + 1) / self.in_dim))\n",
        "    # Batch inputs\n",
        "    batch_pos = []\n",
        "    for b in range(B):\n",
        "      batch_pos += [pos_embeddings]\n",
        "    batch_pos = np.stack(batch_pos)\n",
        "    return batch_pos + x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1cX0D9GNx5I"
      },
      "source": [
        "class QANet(keras.Model):\n",
        "  def __init__(self, in_dim, inner_dim, num_heads, num_convs, num_enc, num_classes, drop_prob = 0.3, drop_att = 0.2, regularization = 1e-3):\n",
        "    super().__init__()\n",
        "    self.regularization = regularization\n",
        "    self.drop_prob = drop_prob\n",
        "    self.drop_att = drop_att\n",
        "    self.num_classes = num_classes\n",
        "    self.in_dim = in_dim\n",
        "    self.inner_dim = inner_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.num_convs = num_convs\n",
        "    self.num_enc = num_enc\n",
        "    self.tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "    self.embedding = keras.layers.Embedding(self.tokenizer.vocab_size, self.in_dim, embeddings_regularizer= tf.keras.regularizers.l2(self.regularization))\n",
        "    self.encoders = keras.Sequential([\n",
        "      QANetEncoder(self.in_dim, self.inner_dim, self.num_heads, self.num_convs, self.regularization, drop_prob = self.drop_att)  for i in range(self.num_enc)\n",
        "    ])\n",
        "    self.Dropout = keras.layers.Dropout(self.drop_prob)\n",
        "    self.Dense = keras.layers.Dense(self.num_classes, kernel_regularizer = tf.keras.regularizers.l2(self.regularization)) \n",
        "  def call(self, x):\n",
        "    tokenized = self.tokenizer(x, return_tensors = 'tf', padding = True, truncation = True, add_special_tokens = False)['input_ids']\n",
        "    embeddings = self.embedding(tokenized)\n",
        "    processed = self.encoders(embeddings)\n",
        "    # Average Logits\n",
        "    mean = self.Dropout(tf.reduce_mean(processed, axis = 1)) # (B, C)\n",
        "    return self.Dense(mean)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM2Es9pmr9lD"
      },
      "source": [
        "# Training the Model on GPU\r\n",
        "TPU training loop implemented below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZc72O7UyioD"
      },
      "source": [
        "model = QANet(256, 128, NUM_ATT_HEADS, 2, 4, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO3mLPt59VZk"
      },
      "source": [
        "def test_fn(tweets):\n",
        "  logits = model(tweets, training = False)\n",
        "  sigmoid = tf.squeeze(tf.keras.activations.sigmoid(logits)).numpy()\n",
        "  print(f\"Logits: {sigmoid}\")\n",
        "  ones = sigmoid >= 0.5\n",
        "  sigmoid[:] = 0\n",
        "  sigmoid[ones] = 1\n",
        "  return sigmoid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCWodtaVeXSV"
      },
      "source": [
        "def test_loss(tweets, labels):\n",
        "  logits = model(tweets, training = False)\n",
        "  return tf.keras.losses.binary_crossentropy(labels, tf.squeeze(logits), from_logits = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP_tZ3DvsIl6"
      },
      "source": [
        "def train_GPU(NUM_EPOCHS, NUM_STEPS):\r\n",
        "  best_val_loss = 9999\r\n",
        "  liveloss = livelossplot.PlotLosses()\r\n",
        "  optimizer = tf.keras.optimizers.Adam(tf.keras.optimizers.schedules.ExponentialDecay(1e-3, NUM_STEPS, 0.99, staircase = True))\r\n",
        "  for EPOCH in range(NUM_EPOCHS):\r\n",
        "    logs = {}\r\n",
        "    total_loss = 0 \r\n",
        "    for STEP in tqdm.tqdm(range(NUM_STEPS)):\r\n",
        "      for text, labels in train_dataloader:\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "          logits = tf.squeeze(model(text, training = True), axis = 1)\r\n",
        "          loss = tf.keras.losses.binary_crossentropy(labels, logits, from_logits = True)\r\n",
        "        grads = tape.gradient(loss, model.trainable_weights)\r\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n",
        "        total_loss = total_loss + loss\r\n",
        "        break\r\n",
        "    logs['loss'] = total_loss / NUM_STEPS\r\n",
        "    print(f\"EPOCH: {EPOCH}, total_loss: {total_loss / NUM_STEPS}\")\r\n",
        "    # Evaluate on Train Set(make sure the loss is at least matching.)\r\n",
        "    tweets = train_dataloader.tweets[0:TEST_SIZE]\r\n",
        "    targets = train_dataloader.targets[0: TEST_SIZE]\r\n",
        "    predicted = test_fn(tweets)\r\n",
        "    incorrect_train = np.sum((predicted != np.array(targets)).astype(np.int32))\r\n",
        "    logs['accuracy'] = incorrect_train\r\n",
        "    # Test on Validation Set\r\n",
        "    tweets = processed_val[0: TEST_SIZE]\r\n",
        "    targets = val_targets[0: TEST_SIZE]\r\n",
        "    predicted = test_fn(tweets)\r\n",
        "    incorrect = np.sum((predicted != np.array(targets)).astype(np.int32))\r\n",
        "    val_loss = test_loss(tweets, targets)\r\n",
        "    if val_loss < best_val_loss:\r\n",
        "      model.save_weights(\"./BestModel/model\")\r\n",
        "    logs['val_loss'] = val_loss\r\n",
        "    logs['val_accuracy'] = incorrect # We want this to decrease\r\n",
        "    liveloss.update(logs)\r\n",
        "    liveloss.send()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpde4mY0_kVi"
      },
      "source": [
        "Train the Model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX4WLJCmtXEW"
      },
      "source": [
        "train_GPU(100, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLYHBy3v38WX",
        "outputId": "9ab12fb4-4d99-4ad5-c5a6-d067648cb4e4"
      },
      "source": [
        "model.load_weights(\"./BestModel/model\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f96e0874e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnzipw9Z1Nzg"
      },
      "source": [
        "Evaluate and Predict using the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4eT6TFs1zG0"
      },
      "source": [
        "def predict(tweets):\r\n",
        "  logits = model(tweets, training = False)\r\n",
        "  sigmoid = tf.squeeze(tf.keras.activations.sigmoid(logits)).numpy()\r\n",
        "  ones = sigmoid >= 0.5\r\n",
        "  sigmoid[:] = 0\r\n",
        "  sigmoid[ones] = 1\r\n",
        "  return sigmoid.astype(np.int32)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAgm4hS43eKc"
      },
      "source": [
        "def make_predictions(test_dataloader):\r\n",
        "  predicted = {'id': [], 'target': []}\r\n",
        "  for tweets, ids in tqdm.tqdm(test_dataloader):\r\n",
        "    logits = predict(tweets)\r\n",
        "    predicted['id'] += ids.tolist()\r\n",
        "    predicted['target'] += logits.tolist()\r\n",
        "  return predicted"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "bfe49ee4249845da81021402a1aae895",
            "0389e2dde4b245758259655136f04b07",
            "8725763d75754d1fa6f3dd64fbeda6e8",
            "2b099e3cfcd1464facb3740d1c5ac983",
            "ee718cc06db0481f8f80efb0616d8e03",
            "851a4b9d0cfe4be0ae8ed2efcb3cae78",
            "7f327e97d75940aa93b58d580bbe003d",
            "038fea79aad04c8791ceb35933a7b587"
          ]
        },
        "id": "Q4e5lXcJ6QQJ",
        "outputId": "a1e07692-2bae-423a-9676-ea81ee6bbfab"
      },
      "source": [
        "predictions = make_predictions(test_dataloader)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfe49ee4249845da81021402a1aae895",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=204.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iterated through Test Dataset more than once. Uh oh.\n",
            "WARNING: Iterating again.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4iuYvBr65jn"
      },
      "source": [
        "dataframe = pd.DataFrame(predictions)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en-B5gHe-r92"
      },
      "source": [
        "dataframe.to_csv(\"./submission.csv\", index_label = 'id', index = False)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6V69ara68Gn",
        "outputId": "38d249be-7977-4d46-f0c9-318f07dc4906"
      },
      "source": [
        "len(test_dataloader.tweets)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ixFtuZ4CMDc"
      },
      "source": [
        "Train the Model on TPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N360MQv52FFO"
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu_cluster_resolver = tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhsI5lXiBItB"
      },
      "source": [
        "%%capture\n",
        "with strategy.scope():\n",
        "  model = DistilBert(1)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE)\n",
        "  training_loss = tf.keras.metrics.Mean(name = \"training_loop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J83QTV_bJ2w"
      },
      "source": [
        "@tf.function\n",
        "def training_step():\n",
        "  def step():\n",
        "    tweets = train_dataloader.tweets[0:32]\n",
        "    labels = train_dataloader.targets[0:32]\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(tweets, training = True)\n",
        "      loss = tf.keras.losses.binary_crossentropy(labels, tf.squeeze(logits), from_logits = True)\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return loss\n",
        "  return strategy.run(step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbIVDM8FmkcS"
      },
      "source": [
        "@tf.function\r\n",
        "def test_loss():\r\n",
        "  for tweets, labels in train_dataloader:\r\n",
        "    break\r\n",
        "  logits = model(tweets, training = False)\r\n",
        "  loss = tf.keras.losses.binary_crossentropy(labels, tf.squeeze(logits), from_logits = True)\r\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7mCROOd3ftE"
      },
      "source": [
        "def training_loop(NUM_EPOCHS, NUM_STEPS):\n",
        "  liveloss = livelossplot.PlotLosses()\n",
        "  for EPOCH in tqdm.tqdm(range(NUM_EPOCHS)):\n",
        "    logs = {}\n",
        "    total_loss = 0.0\n",
        "    for STEP in range(NUM_STEPS):\n",
        "      loss = training_step();\n",
        "      for i in loss.values:\n",
        "        total_loss = total_loss + i\n",
        "    # Test the Model on the training set\n",
        "    loss = strategy.run(test_loss)\n",
        "    print(f\"EPOCH: {EPOCH}, total_loss: {loss.values[0]}\")\n",
        "    logs['loss'] = loss.values[0]\n",
        "    # Evaluate Model on Validation\n",
        "    predicted_logits = test_fn(val_tweets)\n",
        "    # Compute AVG number of incorrect predictions\n",
        "    print(f\"Ground Truths: {np.array(val_targets)}\")\n",
        "    print(f\"Predicted Vals: {predicted_logits}\")\n",
        "    incorrect_predictions = np.sum((predicted_logits != np.array(val_targets)).astype(np.int32)) / predicted_logits.shape[0]\n",
        "    print(f\"incorrect_predictions: {incorrect_predictions}\")\n",
        "    logs['accuracy'] = incorrect_predictions # Not actually accuracy, but livelossplot only supports 2 keywords, so we want this value to go down.\n",
        "    liveloss.update(logs)\n",
        "    liveloss.send()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIKSrGmmXsxN"
      },
      "source": [
        "training_loop(200, 500)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "perfect-spelling",
   "metadata": {
    "id": "2BEYjgi_72iv",
    "papermill": {
     "duration": 0.030367,
     "end_time": "2021-06-22T20:18:34.732282",
     "exception": false,
     "start_time": "2021-06-22T20:18:34.701915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code below shows how to train a model for that purpose with the help of the `huggingface`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-registration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:18:34.801275Z",
     "iopub.status.busy": "2021-06-22T20:18:34.800667Z",
     "iopub.status.idle": "2021-06-22T20:18:42.430503Z",
     "shell.execute_reply": "2021-06-22T20:18:42.430967Z",
     "shell.execute_reply.started": "2021-06-22T19:16:04.909835Z"
    },
    "id": "XQWk1FN_yc0Y",
    "papermill": {
     "duration": 7.67026,
     "end_time": "2021-06-22T20:18:42.431293",
     "exception": false,
     "start_time": "2021-06-22T20:18:34.761033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_datasets import KaggleDatasets\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('coleridgetfrecs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-frontier",
   "metadata": {
    "id": "YgButBqP72ix",
    "papermill": {
     "duration": 0.028263,
     "end_time": "2021-06-22T20:18:42.488085",
     "exception": false,
     "start_time": "2021-06-22T20:18:42.459822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prospective-jones",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:18:42.556296Z",
     "iopub.status.busy": "2021-06-22T20:18:42.555595Z",
     "iopub.status.idle": "2021-06-22T20:19:13.019507Z",
     "shell.execute_reply": "2021-06-22T20:19:13.020068Z",
     "shell.execute_reply.started": "2021-06-22T19:16:08.490509Z"
    },
    "id": "iwNAU1ne72iy",
    "papermill": {
     "duration": 30.502468,
     "end_time": "2021-06-22T20:19:13.020277",
     "exception": false,
     "start_time": "2021-06-22T20:18:42.517809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import networkx as nx\n",
    "MAX_SAMPLE = None # set a small number (e.g. 50) for experimentation, set None for production.\n",
    "!pip install datasets --no-index --find-links=../input/coleridge-packages/packages/datasets\n",
    "!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n",
    "!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-judge",
   "metadata": {
    "id": "ViVZQibj72iz",
    "papermill": {
     "duration": 0.028383,
     "end_time": "2021-06-22T20:19:13.077511",
     "exception": false,
     "start_time": "2021-06-22T20:19:13.049128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "junior-roots",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:19:13.148854Z",
     "iopub.status.busy": "2021-06-22T20:19:13.147861Z",
     "iopub.status.idle": "2021-06-22T20:19:28.177127Z",
     "shell.execute_reply": "2021-06-22T20:19:28.177596Z",
     "shell.execute_reply.started": "2021-06-22T19:16:43.235478Z"
    },
    "id": "nUslQ2e272iz",
    "outputId": "f9374c4a-f6f7-4967-aafa-9f972fb4fc91",
    "papermill": {
     "duration": 15.071331,
     "end_time": "2021-06-22T20:19:28.177786",
     "exception": false,
     "start_time": "2021-06-22T20:19:13.106455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.7/site-packages (0.12.1)\r\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow_addons) (2.12.1)\r\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import random\n",
    "import glob\n",
    "import importlib\n",
    "#import nlpaug as A\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "!pip install tensorflow_addons\n",
    "import tensorflow_addons as tfa\n",
    "#from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, \\\n",
    "TFAutoModel, AutoConfig\n",
    "\n",
    "import transformers\n",
    "import nltk\n",
    "import pickle\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "  \n",
    "sns.set()\n",
    "random.seed(123)\n",
    "np.random.seed(456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exposed-thumbnail",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:19:28.309099Z",
     "iopub.status.busy": "2021-06-22T20:19:28.308023Z",
     "iopub.status.idle": "2021-06-22T20:19:34.031380Z",
     "shell.execute_reply": "2021-06-22T20:19:34.031835Z",
     "shell.execute_reply.started": "2021-06-22T19:17:00.206434Z"
    },
    "id": "fMxaPaMxs5Oc",
    "outputId": "83435deb-7364-4af2-de5d-2d1a9836dd6e",
    "papermill": {
     "duration": 5.824514,
     "end_time": "2021-06-22T20:19:34.032027",
     "exception": false,
     "start_time": "2021-06-22T20:19:28.207513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "    #tf.keras.mixed_precision.set_global_policy('mixed_bfloat16' if TPU else 'float32')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "except:\n",
    "    TPU = None\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "N_REPLICAS = strategy.num_replicas_in_sync\n",
    "bs = 2\n",
    "BATCH_SIZE = bs * N_REPLICAS\n",
    "TARGET_DTYPE = tf.float32#tf.bfloat16 if TPU else tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerous-blues",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:19:34.093852Z",
     "iopub.status.busy": "2021-06-22T20:19:34.093230Z",
     "iopub.status.idle": "2021-06-22T20:19:34.099458Z",
     "shell.execute_reply": "2021-06-22T20:19:34.098956Z",
     "shell.execute_reply.started": "2021-06-22T19:17:06.205017Z"
    },
    "id": "v3zofVj2WaMQ",
    "papermill": {
     "duration": 0.038209,
     "end_time": "2021-06-22T20:19:34.099610",
     "exception": false,
     "start_time": "2021-06-22T20:19:34.061401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "def seed_it_all(seed=7):\n",
    "    \"\"\" Attempt to be Reproducible \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "seed_it_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "black-penny",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:19:34.164152Z",
     "iopub.status.busy": "2021-06-22T20:19:34.163526Z",
     "iopub.status.idle": "2021-06-22T20:19:34.166610Z",
     "shell.execute_reply": "2021-06-22T20:19:34.166119Z",
     "shell.execute_reply.started": "2021-06-22T19:17:06.213741Z"
    },
    "id": "S0m9K2AT72i0",
    "papermill": {
     "duration": 0.038123,
     "end_time": "2021-06-22T20:19:34.166759",
     "exception": false,
     "start_time": "2021-06-22T20:19:34.128636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD_FROM_PREV = True\n",
    "SAVE_PATH = './'\n",
    "MAX_LENGTH = 512 # 500 is Max length of any bert model. after token padding 400 -> ~500\n",
    "\n",
    "\n",
    "train_corpus = None\n",
    "val_corpus = None\n",
    "\n",
    "DATASET_SYMBOL = '$' # this symbol represents a dataset name\n",
    "NONDATA_SYMBOL = '#' # this symbol represents a non-dataset name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-architecture",
   "metadata": {
    "id": "lKE6Xmbe72i0",
    "papermill": {
     "duration": 0.02883,
     "end_time": "2021-06-22T20:19:34.224645",
     "exception": false,
     "start_time": "2021-06-22T20:19:34.195815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-volleyball",
   "metadata": {
    "id": "vnDEYlXFNh9p",
    "papermill": {
     "duration": 0.028844,
     "end_time": "2021-06-22T20:19:34.282304",
     "exception": false,
     "start_time": "2021-06-22T20:19:34.253460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "manual-tattoo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:19:34.349333Z",
     "iopub.status.busy": "2021-06-22T20:19:34.348630Z",
     "iopub.status.idle": "2021-06-22T20:19:38.445462Z",
     "shell.execute_reply": "2021-06-22T20:19:38.444716Z",
     "shell.execute_reply.started": "2021-06-22T19:17:06.229474Z"
    },
    "id": "bGbVSrZ2FP5r",
    "outputId": "bc789a30-349f-4c23-f9bd-6457a6a8720a",
    "papermill": {
     "duration": 4.134462,
     "end_time": "2021-06-22T20:19:38.445636",
     "exception": false,
     "start_time": "2021-06-22T20:19:34.311174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7809ec86a0e4f378f3ca8d7fe80e1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5442a536d544792a5c13fdfbbb4cf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9db41f30974a2d9554de4d233137e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d286dd2ad0ab46b3b56581740a1eccbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ModelConfig:\n",
    "  model_checkpoint = 'roberta-base'\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True, return_token_type_ids = True, return_attention_masks = True)\n",
    "  \n",
    "  encoder_dim = 768 #if model_checkpoint == 'roberta-large' else 768\n",
    "  decoder_dim = 768 #if model_checkpoint == 'roberta-large' else 768\n",
    "  num_att_heads = 12 #if model_checkpoint == 'roberta-large' else 12\n",
    "  decoder_layers = 6 #if model_checkpoint == 'roberta-large' else 6\n",
    "  intermediate_dim = 3072 #if model_checkpoint == 'roberta-large' else 3072\n",
    "  dropout_rate = 0.1 \n",
    "  # Save Some Configs Immediately\n",
    "  config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "  tokenizer.save_pretrained(f'{SAVE_PATH}model_tokenizer')\n",
    "  config.save_pretrained(f'{SAVE_PATH}model_tokenizer')\n",
    "  config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "  config.save_pretrained(f'{SAVE_PATH}')\n",
    "  # CONFIG:\n",
    "  model_head = 'linear'\n",
    "  label_smoothing = 0.1\n",
    "  # SPECIAL TOKS\n",
    "  values = tokenizer.encode(\"<pad>\")\n",
    "  PAD_TOKEN = tf.constant(values[1], tf.int64)\n",
    "  PAD_TOKEN_INT = PAD_TOKEN.numpy().item()\n",
    "  START_TOKEN = tf.constant(values[0], tf.int64)\n",
    "  START_TOKEN_INT = START_TOKEN.numpy().item()\n",
    "  END_TOKEN = tf.constant(values[2], tf.int64)\n",
    "  END_TOKEN_INT = END_TOKEN.numpy().item()\n",
    "  SPLIT_TOKEN = tf.constant(tokenizer.encode(\" |\")[1], tf.int64)\n",
    "  SPLIT_TOKEN_INT = SPLIT_TOKEN.numpy().item()\n",
    "  del values\n",
    "  '''\n",
    "  ROBERTA-LARGE:\n",
    "  - 1024 Decoder Dim = 1024 // num_heads\n",
    "  - 4096 Intermediate Dim - Intermediate = FFN dim\n",
    "  - 16 Att Heads = Number of Att Heads\n",
    "  - 12 Decoder Layers = Number of Decoder Layers\n",
    "\n",
    "  ROBERTA-BASE:\n",
    "  - 3072 Intermediate Dim \n",
    "  - 6 Decoder Layers\n",
    "  - 12 att Heads\n",
    "  - 768 Decoder Dim\n",
    "  '''\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-cowboy",
   "metadata": {
    "id": "VbtXX3edJ5Fe",
    "papermill": {
     "duration": 0.032656,
     "end_time": "2021-06-22T20:19:38.511721",
     "exception": false,
     "start_time": "2021-06-22T20:19:38.479065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Larger Sentences:\n",
    "- No duplicates of Sentences, just all tokens at once.\n",
    "- We have multi class labels, why not use them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-search",
   "metadata": {
    "id": "aXcYOuDT3vkB",
    "papermill": {
     "duration": 0.031469,
     "end_time": "2021-06-22T20:19:38.575095",
     "exception": false,
     "start_time": "2021-06-22T20:19:38.543626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# load in the preprocessed datasets from TFRecordDatasets\n",
    "- Dataset is prepadded for the max length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "engaged-lobby",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:19:38.645615Z",
     "iopub.status.busy": "2021-06-22T20:19:38.644934Z",
     "iopub.status.idle": "2021-06-22T20:20:32.657730Z",
     "shell.execute_reply": "2021-06-22T20:20:32.657064Z"
    },
    "id": "RwsPuK2n3142",
    "papermill": {
     "duration": 54.051068,
     "end_time": "2021-06-22T20:20:32.657887",
     "exception": false,
     "start_time": "2021-06-22T20:19:38.606819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH_LABEL = 60\n",
    "MAX_NUM_WORDS = 12 # Smaller the number, the faster Val is Computed(O(NM)) Real Amount = 6.\n",
    "# Cannot Afford larger than 6(It's Quadratic in Graph Compilation.)\n",
    "MAX_LENGTH_WORD = 32  # Max Dataset Name Length(Real Amount = 22)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "val = tf.io.gfile.glob(f\"{GCS_PATH}/train_tfrecords/*\")\n",
    "fn = val[0]\n",
    "TRAIN_NUMBER = sum(1 for _ in tf.data.TFRecordDataset(fn))\n",
    "\n",
    "val = tf.io.gfile.glob(f\"{GCS_PATH}/test_tfrecords/*\")\n",
    "fn = val[0]\n",
    "VAL_NUMBER = sum(1 for _ in tf.data.TFRecordDataset(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mechanical-silly",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:32.732860Z",
     "iopub.status.busy": "2021-06-22T20:20:32.731917Z",
     "iopub.status.idle": "2021-06-22T20:20:32.734854Z",
     "shell.execute_reply": "2021-06-22T20:20:32.734384Z"
    },
    "id": "btiyDB1RZvvz",
    "papermill": {
     "duration": 0.044925,
     "end_time": "2021-06-22T20:20:32.735012",
     "exception": false,
     "start_time": "2021-06-22T20:20:32.690087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_file(example):\n",
    "  PAD_TOKEN = ModelConfig.tokenizer.pad_token_id\n",
    "  feature_dict = {\n",
    "        'attention_mask': tf.io.FixedLenFeature(shape = [MAX_LENGTH], dtype = tf.int64, default_value = [0] * MAX_LENGTH),\n",
    "        'input_ids': tf.io.FixedLenFeature(shape = [MAX_LENGTH], dtype = tf.int64, default_value = [PAD_TOKEN] * MAX_LENGTH),\n",
    "        'label': tf.io.FixedLenFeature(shape = [MAX_LENGTH_LABEL], dtype = tf.int64, default_value = [PAD_TOKEN] * MAX_LENGTH_LABEL),\n",
    "        'token_type_ids': tf.io.FixedLenFeature(shape = [MAX_LENGTH], dtype = tf.int64, default_value = [0] * MAX_LENGTH) \n",
    "  }\n",
    "  features = tf.io.parse_single_example(example, features=feature_dict)\n",
    "\n",
    "  attention_mask = features['attention_mask']\n",
    "  input_ids = features['input_ids']\n",
    "  label = features['label']\n",
    "  token_type_ids = features['token_type_ids']\n",
    "  return (input_ids, attention_mask, token_type_ids), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indian-certificate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:32.807903Z",
     "iopub.status.busy": "2021-06-22T20:20:32.807294Z",
     "iopub.status.idle": "2021-06-22T20:20:32.810538Z",
     "shell.execute_reply": "2021-06-22T20:20:32.809996Z"
    },
    "id": "e5lhskW8hdWB",
    "papermill": {
     "duration": 0.04387,
     "end_time": "2021-06-22T20:20:32.810705",
     "exception": false,
     "start_time": "2021-06-22T20:20:32.766835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tf_dataset(fold_idx):\n",
    "  # COLLECT THE TFRECORDS\n",
    "  ALL_TFRECS = tf.io.gfile.glob(f\"{GCS_PATH}/train_tfrecords/*\")\n",
    "  ALL_TFRECS = sorted(ALL_TFRECS, reverse = False)\n",
    "\n",
    "  VAL_TFRECS_PATH = tf.io.gfile.glob(f\"{GCS_PATH}/test_tfrecords/*\")[0]\n",
    "  TRAIN_TFRECS_PATH = ALL_TFRECS[0]\n",
    "  # Create TF Datasets \n",
    "  train_dataset = tf.data.TFRecordDataset(TRAIN_TFRECS_PATH, num_parallel_reads = AUTO)\n",
    "  val_dataset = tf.data.TFRecordDataset(VAL_TFRECS_PATH, num_parallel_reads = AUTO)\n",
    "  # Set Determinism to 0 For faster\n",
    "  options = tf.data.Options()\n",
    "  options.experimental_deterministic = False\n",
    "    \n",
    "  train_dataset = train_dataset.with_options(options)\n",
    "  val_dataset = val_dataset.with_options(options)\n",
    "\n",
    "  # Map the Values\n",
    "  train_dataset = train_dataset.map(lambda x: load_file(x), num_parallel_calls = AUTO, deterministic = False) \n",
    "  val_dataset = val_dataset.map(lambda x: load_file(x), num_parallel_calls = AUTO, deterministic = False)\n",
    "  \n",
    "  # batch and Shuffle \n",
    "  train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "  train_dataset = train_dataset.shuffle(4096)\n",
    "  train_dataset = train_dataset.repeat()\n",
    "\n",
    "\n",
    "  val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "  # Prefetch Dataset \n",
    "  train_dataset = train_dataset.prefetch(AUTO)\n",
    "  val_dataset = val_dataset.prefetch(AUTO)\n",
    "\n",
    "  return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-tsunami",
   "metadata": {
    "id": "418Vd5rk72jA",
    "papermill": {
     "duration": 0.031329,
     "end_time": "2021-06-22T20:20:32.873701",
     "exception": false,
     "start_time": "2021-06-22T20:20:32.842372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load pre-trained model and fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "constitutional-daisy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:32.948047Z",
     "iopub.status.busy": "2021-06-22T20:20:32.947077Z",
     "iopub.status.idle": "2021-06-22T20:20:32.950193Z",
     "shell.execute_reply": "2021-06-22T20:20:32.950711Z"
    },
    "id": "vlcN10gL72jA",
    "papermill": {
     "duration": 0.043544,
     "end_time": "2021-06-22T20:20:32.950893",
     "exception": false,
     "start_time": "2021-06-22T20:20:32.907349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "  model = TFAutoModel.from_pretrained(model_name) # 3 parts to a Roberta model\n",
    "  '''\n",
    "  1) Embeddings\n",
    "  2) RoBERTA Main layer\n",
    "  3) Pooler layer. - Can be skipped.\n",
    "  '''\n",
    "  # Freeze Half of the Layers in the Encoder - It's pretrained and already has decent embeddings.(Transfer Learning.)\n",
    "  model.roberta.embeddings.trainable = False \n",
    "  for i in range(len(model.roberta.encoder.layer) // 2):\n",
    "    model.roberta.encoder.layer[i].trainable = False\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-albert",
   "metadata": {
    "id": "SFnAajQ91K_J",
    "papermill": {
     "duration": 0.031489,
     "end_time": "2021-06-22T20:20:33.014227",
     "exception": false,
     "start_time": "2021-06-22T20:20:32.982738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "blank-separation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:33.084515Z",
     "iopub.status.busy": "2021-06-22T20:20:33.083899Z",
     "iopub.status.idle": "2021-06-22T20:20:33.089551Z",
     "shell.execute_reply": "2021-06-22T20:20:33.089072Z"
    },
    "id": "t9nUOqZS1NH8",
    "papermill": {
     "duration": 0.04367,
     "end_time": "2021-06-22T20:20:33.089708",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.046038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.model_checkpoint = ModelConfig.model_checkpoint\n",
    "    self.frozen_backbone = get_model(self.model_checkpoint)\n",
    "    self.frozen_backbone.roberta.pooler.trainable = False\n",
    "    #self.frozen_backbone.config.use_bfloat16 = True\n",
    "  def call(self, input_ids, attention_mask, token_type_ids, training):\n",
    "    # Just grabs the Embeddings from the Roberta Model\n",
    "    embeddings = self.frozen_backbone(input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids, training = training)\n",
    "    return embeddings['last_hidden_state'] # (1, 512, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-accessory",
   "metadata": {
    "id": "aRH4fZJA49Q0",
    "papermill": {
     "duration": 0.031257,
     "end_time": "2021-06-22T20:20:33.153379",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.122122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Decoder Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tamil-favorite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:33.233401Z",
     "iopub.status.busy": "2021-06-22T20:20:33.232765Z",
     "iopub.status.idle": "2021-06-22T20:20:33.236123Z",
     "shell.execute_reply": "2021-06-22T20:20:33.235554Z"
    },
    "id": "-9ouc7iNisde",
    "papermill": {
     "duration": 0.049808,
     "end_time": "2021-06-22T20:20:33.236272",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.186464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderMultiHeadAttention(keras.layers.Layer):\n",
    "  def __init__(self, encoder_dim, num_att_heads):\n",
    "    # x -> MAH + x -> LayerNorm -> Dropout\n",
    "    super().__init__()\n",
    "    self.encoder_dim = encoder_dim\n",
    "    self.num_att_heads = num_att_heads\n",
    "    self.drop_prob = ModelConfig.dropout_rate\n",
    "\n",
    "    self.MultiHeadAttention = keras.layers.MultiHeadAttention(num_heads = self.num_att_heads, \n",
    "      key_dim = self.encoder_dim // self.num_att_heads,\n",
    "      value_dim = self.encoder_dim // self.num_att_heads,\n",
    "      dropout = self.drop_prob\n",
    "    )\n",
    "    self.LayerNorm = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.Dropout = keras.layers.Dropout(self.drop_prob)\n",
    "  def call(self, x, attention_mask, training):\n",
    "    MAH = self.MultiHeadAttention(query = x, key = x, value = x, attention_mask = attention_mask, training = training)\n",
    "    norm = self.LayerNorm(MAH + x, training = training)\n",
    "    return self.Dropout(norm, training = training)\n",
    "\n",
    "class DecoderMultiHeadAttention(keras.layers.Layer):\n",
    "  def __init__(self, encoder_dim, decoder_dim, num_att_heads, drop_prob):\n",
    "    super().__init__()\n",
    "    self.encoder_dim = encoder_dim\n",
    "    self.decoder_dim = decoder_dim\n",
    "    assert self.encoder_dim == self.decoder_dim\n",
    "    self.num_att_heads = num_att_heads\n",
    "    self.drop_prob = drop_prob \n",
    "    \n",
    "    \n",
    "    self.dec_enc_attention = keras.layers.MultiHeadAttention(num_heads = self.num_att_heads,\n",
    "      key_dim = self.encoder_dim // self.num_att_heads, \n",
    "      value_dim = self.encoder_dim // self.num_att_heads,\n",
    "      dropout = self.drop_prob\n",
    "    )\n",
    "    self.LayerNorm = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.Dropout = keras.layers.Dropout(self.drop_prob)\n",
    "  \n",
    "  def call(self, encoder, decoder, padding_mask, training):\n",
    "    # Encoder: Tensor(B, L, C)\n",
    "    # Decoder: Tensor(B, L, C)\n",
    "    MAH = self.dec_enc_attention(query = decoder, key = encoder, value = encoder, attention_mask = padding_mask, training = training)\n",
    "    norm = self.LayerNorm(MAH + decoder, training = training)\n",
    "    return self.Dropout(norm, training = training)\n",
    "\n",
    "class FFN(keras.layers.Layer):\n",
    "  def __init__(self, decoder_dim, feedforward_dim, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.decoder_dim = decoder_dim\n",
    "    self.feedforward_dim = feedforward_dim\n",
    "    self.drop_prob = dropout_rate\n",
    "  \n",
    "    self.FFN = keras.Sequential([\n",
    "      keras.layers.Dense(self.feedforward_dim, activation = 'relu'),\n",
    "      keras.layers.Dense(self.decoder_dim)\n",
    "    ])\n",
    "    self.LayerNorm = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.Dropout = keras.layers.Dropout(self.drop_prob)\n",
    "\n",
    "  def call(self, x, training):\n",
    "    ffn = self.FFN(x, training = training)\n",
    "    norm = self.LayerNorm(ffn + x, training = training)\n",
    "    return self.Dropout(norm, training = training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "atlantic-penalty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:33.325464Z",
     "iopub.status.busy": "2021-06-22T20:20:33.319520Z",
     "iopub.status.idle": "2021-06-22T20:20:33.328756Z",
     "shell.execute_reply": "2021-06-22T20:20:33.328228Z"
    },
    "id": "F24sWvyXMJQs",
    "papermill": {
     "duration": 0.060017,
     "end_time": "2021-06-22T20:20:33.328901",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.268884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(keras.layers.Layer):\n",
    "  def __init__(self, encoder_dim, decoder_dim, feedforward_dim, num_att_heads, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.encoder_dim = encoder_dim\n",
    "    self.decoder_dim = decoder_dim\n",
    "    self.feedforward_dim = feedforward_dim\n",
    "    self.num_att_heads = num_att_heads\n",
    "    self.dropout_rate = dropout_rate\n",
    "\n",
    "    self.DecoderAttention = EncoderMultiHeadAttention(self.decoder_dim, self.num_att_heads)\n",
    "    self.EncoderDecoderAttention = DecoderMultiHeadAttention(self.encoder_dim, self.decoder_dim, self.num_att_heads, self.dropout_rate)\n",
    "    self.FFN = FFN(self.decoder_dim, self.feedforward_dim, self.dropout_rate)\n",
    "\n",
    "  def call(self, encoder, decoder, attention_mask, padding_mask, training):\n",
    "    decoder_values = self.DecoderAttention(decoder, attention_mask = attention_mask, training = training)\n",
    "    decoder_attended = self.EncoderDecoderAttention(encoder, decoder_values, padding_mask = padding_mask, training = training)\n",
    "    ffn = self.FFN(decoder_attended, training = training)\n",
    "    return ffn\n",
    "\n",
    "class TransformerDecoderModel(keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # ----------------------PROCESS---------------------\n",
    "    # 1) GET EMBEDDINGS\n",
    "    # 2) ADD POSITIONAL EMBEDDINGS\n",
    "    # 3) RUN THROUGH THE DECODERS\n",
    "    # 4) FINAL FFN\n",
    "    # ---------------------PRETRAINING PARTS------------------------------\n",
    "    # EMBEDDINGS\n",
    "    self.model_checkpoint = ModelConfig.model_checkpoint\n",
    "    # Load an Encoder Model\n",
    "    tmp_model = get_model(self.model_checkpoint)\n",
    "    # Steal embeddings(Pretrained Embeddings)\n",
    "    self.embeddings = tmp_model.roberta.embeddings # call(input_ids, token_type_ids)\n",
    "    self.vocab_size = self.embeddings.vocab_size\n",
    "    del tmp_model \n",
    "    # ------------------MODEL DEFINITIONS------------------------\n",
    "    self.max_len = MAX_LENGTH_LABEL - 1 \n",
    "    self.decoder_dim = ModelConfig.decoder_dim\n",
    "    self.encoder_dim = ModelConfig.encoder_dim\n",
    "    self.num_att_heads = ModelConfig.num_att_heads\n",
    "    self.decoder_layers = ModelConfig.decoder_layers\n",
    "    self.dropout_rate = ModelConfig.dropout_rate\n",
    "    self.feedforward_dim = ModelConfig.intermediate_dim\n",
    "\n",
    "    self.decoders = [TransformerDecoder(\n",
    "        self.encoder_dim,\n",
    "        self.decoder_dim,\n",
    "        self.feedforward_dim,\n",
    "        self.num_att_heads,\n",
    "        self.dropout_rate\n",
    "    ) for _ in range(self.decoder_layers)]\n",
    "    \n",
    "    \n",
    "    # PRECOMPUTE CAUSAL Attention MASKS\n",
    "    self.batch_size = bs\n",
    "    self.attention_mask = self.causal_attention_mask(self.batch_size, self.max_len, self.max_len, tf.uint8)\n",
    "    # PRECOMPUTE Positional Embeddings\n",
    "    self.pos_enc = self.positional_embeddings(self.max_len, self.decoder_dim) # (1, L, C) \n",
    "    self.pos_enc = tf.repeat(tf.expand_dims(self.pos_enc, axis = 0), self.batch_size, axis = 0)\n",
    "  def positional_embeddings(self, max_length, dim):\n",
    "    L, C = (max_length, dim) \n",
    "    positional_encodings = np.zeros((L, C), np.float32)\n",
    "    for pos in range(L):\n",
    "      for i in range(0, C  + 2, 2):\n",
    "        if i >= C:\n",
    "          continue\n",
    "        positional_encodings[pos, i] = math.sin(pos / 10000 ** (i / self.decoder_dim))\n",
    "        if i + 1 >= C:\n",
    "          continue \n",
    "        positional_encodings[pos, i + 1] = math.cos(pos / 10000 ** ((i + 1) / self.decoder_dim))\n",
    "    return tf.identity(positional_encodings) \n",
    "\n",
    "\n",
    "  def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "    \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "    This prevents flow of information from future tokens to current token.\n",
    "    1's in the lower triangle, counting from the lower right corner.\n",
    "    \"\"\"\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "    )\n",
    "    return tf.tile(mask, mult) # Diagonal Mask \n",
    "\n",
    "  def compute_padding_mask(self, decoder_ids, dtype):\n",
    "    # Returns an Attention Mask to mask all padding tokens\n",
    "    PAD_TOKEN_ID = ModelConfig.tokenizer.pad_token_id\n",
    "    # Create a Mask over token ids.\n",
    "    mask = tf.not_equal(decoder_ids, PAD_TOKEN_ID)\n",
    "    return tf.cast(mask, dtype)\n",
    "  def call_val(self, encoder, decoder, training):\n",
    "    B, L, C = encoder.shape \n",
    "    _, Dec_Len = decoder.shape \n",
    "\n",
    "    padding_mask = self.compute_padding_mask(decoder, tf.uint8)\n",
    "    padding_mask = tf.expand_dims(padding_mask, axis = -1) # (B, Dec_Len, 1) \n",
    "\n",
    "    attention_mask = self.causal_attention_mask(B, Dec_Len, Dec_Len, tf.uint8) # (B, Dec_Len, Dec_Len)\n",
    "    attention_mask = attention_mask * padding_mask # (B, Dec_Len, Dec_Len) \n",
    "\n",
    "    padding_mask = tf.repeat(padding_mask, L, axis = -1) # (B, Dec_Len, L)\n",
    "\n",
    "    decoder_embeddings = self.embeddings(decoder, training = training) # (B, L, C)\n",
    "    # Pos Enc\n",
    "    pos_enc = tf.identity(self.pos_enc)[:, :Dec_Len, :] # (B, L, C)\n",
    "    decoder_embeddings = decoder_embeddings + pos_enc\n",
    "\n",
    "    for DECODER in self.decoders:\n",
    "      decoder_embeddings = DECODER(encoder, decoder_embeddings, attention_mask, padding_mask, training = training)\n",
    "    return decoder_embeddings \n",
    "  def call(self, encoder, decoder, training):\n",
    "    '''\n",
    "    Encoder: Encoder Embeddings: Tensor(B, L, C)\n",
    "    Decoder: Decoder Input Ids: Tensor(B, L')\n",
    "    training: in training mode?\n",
    "    Unfortuately, you cannot precompute attention masks, since the padding mask depends on the decoder_ids\n",
    "    '''\n",
    "    # NO NEED For TOKEN TYPE IDs, as they are always 0(Always 1 Sentence)\n",
    "    B, L, C = encoder.shape\n",
    "    _, Dec_Len = decoder.shape\n",
    "\n",
    "    # GENERATE MASKS\n",
    "    padding_mask = self.compute_padding_mask(decoder, tf.uint8) # (B, L)\n",
    "    padding_mask = tf.expand_dims(padding_mask, axis = -1)\n",
    "    attention_mask = tf.identity(self.attention_mask) # (B, L, L) - Used only in Decoder Attention\n",
    "    attention_mask = attention_mask * padding_mask # (B, L, L)\n",
    "    \n",
    "    padding_mask = tf.repeat(padding_mask, L, axis = -1)\n",
    "    \n",
    "    \n",
    "    # Convert Tokens to Embeddings\n",
    "    decoder_embeddings = self.embeddings(decoder, training = training) # (B, L', C)\n",
    "    # ----------------GET POS ENC FOR DECODER INPUTS(Encoder already got them) -------------------\n",
    "    pos_enc = tf.identity(self.pos_enc) # (1, L, C)\n",
    "\n",
    "    decoder_embeddings = decoder_embeddings + pos_enc\n",
    "    # Run through the Decoders:\n",
    "    for DECODER in self.decoders:\n",
    "      decoder_embeddings = DECODER(encoder, decoder_embeddings, attention_mask, padding_mask, training = training)\n",
    "    # FINAL HEAD\n",
    "    return decoder_embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-mining",
   "metadata": {
    "id": "fkcbAieK82KP",
    "papermill": {
     "duration": 0.033015,
     "end_time": "2021-06-22T20:20:33.394584",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.361569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "southeast-event",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:33.465655Z",
     "iopub.status.busy": "2021-06-22T20:20:33.465029Z",
     "iopub.status.idle": "2021-06-22T20:20:33.467684Z",
     "shell.execute_reply": "2021-06-22T20:20:33.468164Z"
    },
    "id": "r6EJ7v528awI",
    "papermill": {
     "duration": 0.041809,
     "end_time": "2021-06-22T20:20:33.468371",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.426562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DenseHead(keras.Model):\n",
    "  def __init__(self, vocab_size, pad_token):\n",
    "    super().__init__()\n",
    "    self.vocab_size = vocab_size\n",
    "    self.pad_token = pad_token\n",
    "    self.batch_size = bs\n",
    "    self.head = keras.layers.Dense(self.vocab_size)\n",
    "    \n",
    "    \n",
    "    self.label_smoothing = ModelConfig.label_smoothing\n",
    "    \n",
    "\n",
    "  def call(self, x, training):\n",
    "    # Does the logic of Argmax and prediction in one swoop\n",
    "    pred = self.head(x, training = training) # (B, C)\n",
    "    return pred\n",
    "  def call_val(self, x, training):\n",
    "    pred = self.head(x[:, -1], training = training)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-champion",
   "metadata": {
    "id": "0StjSL3rhuQL",
    "papermill": {
     "duration": 0.032932,
     "end_time": "2021-06-22T20:20:33.533425",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.500493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "accuracy FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "negative-diabetes",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:33.602467Z",
     "iopub.status.busy": "2021-06-22T20:20:33.601854Z",
     "iopub.status.idle": "2021-06-22T20:20:33.604633Z",
     "shell.execute_reply": "2021-06-22T20:20:33.604060Z"
    },
    "id": "OLjxC6kVhvCp",
    "papermill": {
     "duration": 0.039269,
     "end_time": "2021-06-22T20:20:33.604766",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.565497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_accuracy(outputs, GT, metric_name):\n",
    "  metrics[metric_name].update_state(outputs, GT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-kitty",
   "metadata": {
    "id": "jjdlYsDY8wzG",
    "papermill": {
     "duration": 0.033742,
     "end_time": "2021-06-22T20:20:33.670711",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.636969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FULL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "north-enclosure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:33.748909Z",
     "iopub.status.busy": "2021-06-22T20:20:33.747567Z",
     "iopub.status.idle": "2021-06-22T20:20:33.751220Z",
     "shell.execute_reply": "2021-06-22T20:20:33.750563Z"
    },
    "id": "CxtnOaK8NOKn",
    "papermill": {
     "duration": 0.048006,
     "end_time": "2021-06-22T20:20:33.751387",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.703381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FullModel(keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder()\n",
    "    self.START_TOKEN = ModelConfig.START_TOKEN\n",
    "    self.END_TOKEN = ModelConfig.END_TOKEN # Default Special tokens for HuggingFace Tokenizers\n",
    "    self.MAX_LEN = MAX_LENGTH_LABEL\n",
    "    self.vocab_length = ModelConfig.tokenizer.vocab_size \n",
    "    self.decoder = TransformerDecoderModel()\n",
    "    self.model_head = DenseHead(self.decoder.vocab_size, ModelConfig.tokenizer.pad_token_id)\n",
    "  \n",
    "  def call_train(self, input_ids, attention_mask, token_type_ids, decoder_input_ids, training):\n",
    "    # decoder_input_ids: Tensor(B, L)\n",
    "    encoded_embeddings = self.encoder(input_ids, attention_mask, token_type_ids, training = training) # (B, L, C)\n",
    "    decoded_values = self.decoder(encoded_embeddings, decoder_input_ids, training = training)\n",
    "    preds = self.model_head.call(decoded_values, training = training)\n",
    "    return preds # (B, L, C)\n",
    "  def call_val(self, input_ids, attention_mask, token_type_ids, training):\n",
    "    # Inference Loop: \n",
    "    encoded_embeddings = self.encoder(input_ids, attention_mask, token_type_ids, training = training)\n",
    "    # create Starter token\n",
    "    B, _, _ = encoded_embeddings.shape\n",
    "    sentence_tokens = tf.ones((B, 1), tf.int64) * tf.cast(self.START_TOKEN, tf.int64)\n",
    "    pred_logits = tf.ones((B, 0, self.vocab_length), encoded_embeddings.dtype)\n",
    "    for i in range(self.MAX_LEN - 1):\n",
    "      embeddings = self.decoder.call_val(encoded_embeddings, sentence_tokens, training = training) # (B, L, C)\n",
    "      pred = self.model_head.call_val(embeddings, training = training) # (B, C)\n",
    "      # Add the logits \n",
    "      TMP_LOGITS = tf.expand_dims(pred, axis = 1) # (B, 1, C)\n",
    "      \n",
    "      pred_logits = tf.concat([pred_logits, TMP_LOGITS], axis = 1) # (B, 1, C)\n",
    "\n",
    "      pred = keras.activations.softmax(pred) # (B, C)\n",
    "      pred = tf.argmax(pred, axis = -1) # (B, )\n",
    "      pred = tf.expand_dims(pred, axis = 1)\n",
    "      # Just append the values, should predict <END> and then just random garbage(We filter it out)\n",
    "      sentence_tokens = tf.concat([sentence_tokens, tf.cast(pred, sentence_tokens.dtype)], axis = 1)\n",
    "    return pred_logits, sentence_tokens    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-progress",
   "metadata": {
    "id": "nGJDln5_XU_G",
    "papermill": {
     "duration": 0.033906,
     "end_time": "2021-06-22T20:20:33.819694",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.785788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LR SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "split-promotion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:33.899089Z",
     "iopub.status.busy": "2021-06-22T20:20:33.898086Z",
     "iopub.status.idle": "2021-06-22T20:20:33.906702Z",
     "shell.execute_reply": "2021-06-22T20:20:33.906175Z"
    },
    "id": "01lEF3xDXWTq",
    "papermill": {
     "duration": 0.053873,
     "end_time": "2021-06-22T20:20:33.906852",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.852979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParamScheduler:\n",
    "    def __init__(self, start, end, num_iter):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.num_iter = num_iter\n",
    "        self.idx = -1\n",
    "        \n",
    "        \n",
    "    def step(self):\n",
    "        self.idx+=1\n",
    "        return self.func(self.start, self.end, self.idx/self.num_iter)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.idx=-1\n",
    "        \n",
    "    def is_complete(self):\n",
    "        return self.idx >= self.num_iter\n",
    "\n",
    "class CosineScheduler(ParamScheduler):\n",
    "    def func(self, start_val, end_val, pct):\n",
    "        cos_out = np.cos(np.pi * pct) + 1\n",
    "        return end_val + (start_val - end_val)/2 * cos_out\n",
    "class ConstantScheduler(ParamScheduler):\n",
    "    def __init__(self, init_lr, num_steps):\n",
    "        self.init_lr = init_lr\n",
    "        self.num_steps = num_steps\n",
    "        self.steps = -1\n",
    "    def step(self):\n",
    "        self.steps += 1\n",
    "        return self.init_lr\n",
    "    def reset(self):\n",
    "        self.steps = -1\n",
    "    def is_complete(self):\n",
    "        return self.steps >= self.num_steps\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, init_lr, max_lr, min_lr, warm_steps, peak_steps, total_steps):\n",
    "        momentums=(0.95,0.85)\n",
    "        start_div=25.\n",
    "        pct_start=warm_steps\n",
    "        pct_climax = peak_steps# Stay at the peak for 0.1 of training.\n",
    "        verbose=True\n",
    "        sched=CosineScheduler\n",
    "        end_div=None\n",
    "        self.pct_climax = pct_climax\n",
    "        self.max_lr, self.momentums, self.start_div, self.pct_start, self.verbose, self.sched, self.end_div = max_lr, momentums, start_div, pct_start, verbose, sched, end_div\n",
    "        if self.end_div is None:\n",
    "            self.end_div = start_div * 1e4\n",
    "        self.logs = {}\n",
    "        self.min_lr = min_lr\n",
    "        self.init_lr = init_lr\n",
    "  \n",
    "        self.start_lr = self.max_lr/self.start_div\n",
    "        self.end_lr = self.max_lr/self.end_div \n",
    "        self.num_iter = int(total_steps * 1.2) # Pad the Steps a bit to make sure no overflow.\n",
    "        self.num_iter_1 = int(self.pct_start*self.num_iter)\n",
    "        self.num_iter_2 = int(self.pct_climax * self.num_iter)\n",
    "        self.num_iter_3 = self.num_iter - self.num_iter_1 - self.num_iter_2\n",
    "        \n",
    "        self.lr_scheds = (self.sched(self.start_lr, self.max_lr, self.num_iter_1), ConstantScheduler(self.max_lr, self.num_iter_2), self.sched(self.max_lr, self.end_lr, self.num_iter_3))\n",
    "        self.sched_idx = 0 \n",
    "        \n",
    "    def optimizer_params_step(self):\n",
    "        try:\n",
    "          next_lr = self.lr_scheds[self.sched_idx].step()\n",
    "        except:\n",
    "          next_lr = self.min_lr\n",
    "        next_lr = tf.maximum(next_lr, self.min_lr)\n",
    "        next_lr = tf.cast(next_lr, tf.float32)\n",
    "        # update optimizer params\n",
    "        optimizer.optimizer.learning_rate.assign(next_lr)\n",
    "        \n",
    "    def step(self):\n",
    "        self.optimizer_params_step()\n",
    "        try:\n",
    "          if self.lr_scheds[self.sched_idx].is_complete():\n",
    "              self.sched_idx += 1\n",
    "        except:\n",
    "          pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-confusion",
   "metadata": {
    "id": "qLGyL0jqXOAM",
    "papermill": {
     "duration": 0.033044,
     "end_time": "2021-06-22T20:20:33.973560",
     "exception": false,
     "start_time": "2021-06-22T20:20:33.940516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "consolidated-romantic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:34.050759Z",
     "iopub.status.busy": "2021-06-22T20:20:34.049871Z",
     "iopub.status.idle": "2021-06-22T20:20:34.052877Z",
     "shell.execute_reply": "2021-06-22T20:20:34.053276Z"
    },
    "id": "JHPVPyC3XPlj",
    "papermill": {
     "duration": 0.046611,
     "end_time": "2021-06-22T20:20:34.053445",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.006834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GradAccAdam():\n",
    "    # Just a Wrapper to Accumulate Gradients and Send them to Adam\n",
    "    def __init__(self, model, learning_rate, grad_acc_steps, prev_optim_path = None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.grad_acc_steps = grad_acc_steps\n",
    "        \n",
    "        self.weight_decay = TrainingConfig.weight_decay\n",
    "        self.optimizer = tfa.optimizers.AdamW(learning_rate = self.learning_rate, weight_decay = self.weight_decay)\n",
    "        \n",
    "        self.PrevModelPath = prev_optim_path\n",
    "        if self.PrevModelPath:\n",
    "            self.opt_weights = np.load(f'{self.PrevModelPath}optimizer_last.npy', allow_pickle = True)\n",
    "        \n",
    "            trainable_weights = model.trainable_weights\n",
    "            \n",
    "            zero_grads = [tf.zeros_like(w) for w in trainable_weights]\n",
    "            @tf.function\n",
    "            def f():\n",
    "                self.optimizer.apply_gradients(zip(zero_grads, trainable_weights))\n",
    "            strategy.run(f)\n",
    "            self.optimizer.set_weights(self.opt_weights)\n",
    "            print(\"Loaded Weights\")\n",
    "        \n",
    "        self.gradients = None\n",
    "        self.cur_grad_acc = 0\n",
    "    def apply_gradients(self, gradients, variables):\n",
    "        if self.gradients is None:\n",
    "            self.gradients = [g / tf.constant(float(self.grad_acc_steps)) for g in gradients]\n",
    "            self.cur_grad_acc += 1\n",
    "        else:\n",
    "            for i in range(len(gradients)):\n",
    "                self.gradients[i] += gradients[i] / tf.constant(float(self.grad_acc_steps))\n",
    "            self.cur_grad_acc += 1\n",
    "        if self.cur_grad_acc == self.grad_acc_steps:\n",
    "            self.optimizer.apply_gradients(zip(self.gradients, variables))\n",
    "            self.gradients = None\n",
    "            self.cur_grad_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-optimization",
   "metadata": {
    "id": "vO5YuAzybL6I",
    "papermill": {
     "duration": 0.032326,
     "end_time": "2021-06-22T20:20:34.118337",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.086011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "several-gross",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:34.191127Z",
     "iopub.status.busy": "2021-06-22T20:20:34.190241Z",
     "iopub.status.idle": "2021-06-22T20:20:34.193644Z",
     "shell.execute_reply": "2021-06-22T20:20:34.193026Z"
    },
    "id": "Hr67_hlRbNPM",
    "papermill": {
     "duration": 0.042348,
     "end_time": "2021-06-22T20:20:34.193788",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.151440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "  learning_rate = 2e-5\n",
    "  max_lr = 5e-5\n",
    "  min_lr = 1e-13\n",
    "  warm_steps = 0.05\n",
    "  peak_steps = 0.05\n",
    "\n",
    "  NUM_EPOCHS = 100\n",
    "  STEPS = TRAIN_NUMBER // BATCH_SIZE\n",
    "  TOTAL_STEPS = STEPS * NUM_EPOCHS\n",
    "  STEPS_PER = 100\n",
    "  weight_decay = 0\n",
    "  PREV_MODEL_PATH = None#f'{SAVE_PATH}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-lotus",
   "metadata": {
    "id": "sfoNzbMwWP5v",
    "papermill": {
     "duration": 0.033524,
     "end_time": "2021-06-22T20:20:34.259930",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.226406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "finnish-birthday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:34.334567Z",
     "iopub.status.busy": "2021-06-22T20:20:34.333772Z",
     "iopub.status.idle": "2021-06-22T20:20:34.337611Z",
     "shell.execute_reply": "2021-06-22T20:20:34.337003Z"
    },
    "id": "sbjV1gpAYs40",
    "papermill": {
     "duration": 0.043798,
     "end_time": "2021-06-22T20:20:34.337758",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.293960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_states(path_name):\n",
    "  # Saves Optimizer, Model, Scheduler \n",
    "  # optimizer, model, scheduler\n",
    "  print(\"SAVING STATES\")\n",
    "  optimizer_path = f'{SAVE_PATH}{path_name}_optimizer.npy'\n",
    "  with open(optimizer_path, 'w') as file:\n",
    "    pass\n",
    "  \n",
    "  np.save(optimizer_path, optimizer.optimizer.get_weights())\n",
    "  model_path = f\"{SAVE_PATH}{path_name}_model.h5\"\n",
    "  with open(model_path, 'w') as file:\n",
    "    pass\n",
    "  model.save_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-detective",
   "metadata": {
    "id": "qdttv8NmPNB5",
    "papermill": {
     "duration": 0.032636,
     "end_time": "2021-06-22T20:20:34.403927",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.371291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "class ValF1Score(keras.metrics.Metric):\n",
    "  def __init__(self, name = 'f1score', **kwargs):\n",
    "    super().__init__(name = name, **kwargs)\n",
    "    self.tp = 0.0\n",
    "    self.fp = 0.0\n",
    "    self.fn = 0.0\n",
    "    self.tokenizer = ModelConfig.tokenizer\n",
    "    self.start_token_id = ModelConfig.START_TOKEN_INT\n",
    "    self.pad_token_id = ModelConfig.PAD_TOKEN_INT\n",
    "    self.end_token_id = ModelConfig.END_TOKEN_INT\n",
    "    self.split_token_id = ModelConfig.SPLIT_TOKEN_INT\n",
    "    self.MAX_LEN = MAX_LENGTH_LABEL\n",
    "    self.MAX_NUM_WORDS = MAX_NUM_WORDS\n",
    "    self.MAX_LENGTH_WORD = MAX_LENGTH_WORD\n",
    "    self.beta = 0.5\n",
    "  def jaccard_similarity_score(self, GT, pred):\n",
    "    intersection = tf.sets.intersection(tf.expand_dims(GT, axis = 0), tf.expand_dims(pred, axis = 0))\n",
    "    intersection = tf.sparse.to_dense(intersection)\n",
    "    intersection = tf.reshape(intersection, (-1, ))\n",
    "\n",
    "    if len(intersection) + len(GT) + len(pred) == 0:\n",
    "      return tf.constant(1.0, dtype = TARGET_DTYPE)\n",
    "    else:\n",
    "      jaccard_score = len(intersection) / (len(GT) + len(pred) - len(intersection))\n",
    "      return tf.cast(jaccard_score, dtype = TARGET_DTYPE)\n",
    "  \n",
    "  def split_based_on_id(self, text):\n",
    "    indices = tf.ones((self.MAX_NUM_WORDS), dtype = tf.int64) * tf.constant(-1, dtype = tf.int64)\n",
    "    cur_idx = tf.constant(0, dtype = tf.int32)\n",
    "    L = min(text.shape[0], self.MAX_NUM_WORDS)\n",
    "\n",
    "    # Find the Indices Manually\n",
    "    for i in range(self.MAX_LEN - 1):\n",
    "      if text[i] == self.end_token_id:\n",
    "        begin = indices[:cur_idx]\n",
    "        end = indices[cur_idx + 1:]\n",
    "        middle = tf.expand_dims(tf.constant(i + 1, indices.dtype), axis = 0)\n",
    "        indices = tf.concat([begin, middle, end], axis = 0)\n",
    "        indices = tf.reshape(indices, (self.MAX_NUM_WORDS, ))\n",
    "        cur_idx = tf.minimum(L - 1, cur_idx + 1)\n",
    "\n",
    "      elif text[i] == self.split_token_id:\n",
    "        begin = indices[:cur_idx]\n",
    "        end = indices[cur_idx + 1:]\n",
    "        middle = tf.expand_dims(tf.constant(i, indices.dtype), axis = 0)\n",
    "        indices = tf.concat([begin, middle, end], axis = 0)\n",
    "        indices = tf.reshape(indices, (self.MAX_NUM_WORDS, ))\n",
    "        cur_idx = tf.minimum(L - 1, cur_idx + 1)\n",
    "    all_words = tf.ones((self.MAX_NUM_WORDS, self.MAX_LENGTH_WORD), dtype = text.dtype) * tf.constant(-1, dtype = text.dtype)\n",
    "    word_idx = tf.constant(0, dtype = tf.int32)\n",
    "    num_indices = len(indices)\n",
    "\n",
    "    for split_idx in range(self.MAX_NUM_WORDS - 1):\n",
    "      if indices[split_idx] == -1:\n",
    "        continue\n",
    "      elif split_idx == 0:\n",
    "        word = text[:indices[split_idx]]\n",
    "        # pad/truncate to max len\n",
    "        length = tf.maximum(0, self.MAX_LENGTH_WORD - len(word))\n",
    "        # Truncate\n",
    "        word = word[:self.MAX_LENGTH_WORD]\n",
    "        word = tf.pad(tf.expand_dims(word, axis = 0), [[0, 0], [0, length]],  constant_values = self.pad_token_id)    \n",
    "        \n",
    "        begin = all_words[:word_idx]\n",
    "        end = all_words[word_idx + 1:]\n",
    "        middle = word\n",
    "        all_words = tf.concat([begin, middle, end], axis = 0)\n",
    "        all_words = tf.reshape(all_words, (self.MAX_NUM_WORDS, self.MAX_LENGTH_WORD))\n",
    "        word_idx = word_idx + 1\n",
    "      else:\n",
    "        word = text[indices[split_idx] + 1: indices[split_idx + 1]]\n",
    "        length = tf.maximum(0, self.MAX_LENGTH_WORD - len(word))\n",
    "        # Truncate \n",
    "        word = word[:self.MAX_LENGTH_WORD]\n",
    "        word = tf.pad(tf.expand_dims(word, axis = 0), [[0, 0], [0, length]],  constant_values = self.pad_token_id)\n",
    "        \n",
    "        begin = all_words[:word_idx]\n",
    "        end = all_words[word_idx + 1:]\n",
    "        middle = word\n",
    "        all_words = tf.concat([begin, middle, end], axis = 0)\n",
    "        all_words = tf.reshape(all_words, (self.MAX_NUM_WORDS, self.MAX_LENGTH_WORD))\n",
    "        word_idx = word_idx + 1\n",
    "  \n",
    "    return all_words\n",
    "  def constant_to_tensor(self, idx):\n",
    "    return tf.expand_dims(tf.identity(idx), axis = 0)\n",
    "  def is_in(self, idx, total):\n",
    "    total = tf.expand_dims(total, axis = 0)\n",
    "    idx = tf.expand_dims(idx, axis = 0)\n",
    "\n",
    "    intersection = tf.sparse.to_dense(tf.sets.intersection(idx, total))\n",
    "    intersection = tf.reshape(intersection, (-1, ))\n",
    "    return len(intersection) > 0\n",
    "  def update_state(self, GT, pred_tokens):\n",
    "    # pred tokens: Tensor(B, L)\n",
    "    # GT: Tensor(B, L)\n",
    "    B, L = GT.shape\n",
    "    # Convert to int\n",
    "    pred_tokens= tf.cast(pred_tokens, tf.int64)\n",
    "    GT = tf.cast(GT, tf.int64)\n",
    " \n",
    "    for b in range(B):\n",
    "      \n",
    "      ground_truth = GT[b][1:] # Cut off Start Tokens\n",
    "      predicted_text = pred_tokens[b][1:] # cut off start tokens # (MAX_LEN)\n",
    "      split_ground_truth = self.split_based_on_id(ground_truth) # (MAX_NUM_WORDS, MAX_LENGTH_WORD)\n",
    "      split_predicted_text = self.split_based_on_id(predicted_text) # (MAX_NUM_WORDS, MAX_LENGTH_WORD)\n",
    "      removed = tf.ones((self.MAX_NUM_WORDS, ), dtype = tf.int32) * tf.constant(-1, dtype = tf.int32)  \n",
    "      cur_removed_idx = tf.constant(0, dtype = tf.int32)\n",
    "      for i in range(self.MAX_NUM_WORDS):   \n",
    "        if split_ground_truth[i, 0] == -1:\n",
    "          continue # Filter out bad Sentences\n",
    "        predicted_dataset = split_ground_truth[i] # Padded to (60)\n",
    "        #print(predicted_dataset)\n",
    "        index = tf.argmax(tf.equal(predicted_dataset, self.pad_token_id))\n",
    "        ground_truth = predicted_dataset[:index]\n",
    "       \n",
    "        best_score = tf.constant(0.0, dtype = TARGET_DTYPE)\n",
    "        best_idx = tf.constant(0, dtype = tf.int32)\n",
    "        for j in range(self.MAX_NUM_WORDS):\n",
    "          #print(i, j)\n",
    "          if self.is_in(self.constant_to_tensor(j), removed):\n",
    "            continue\n",
    "          if split_predicted_text[j, 0] == -1:\n",
    "            begin = removed[:cur_removed_idx]\n",
    "            end = removed[cur_removed_idx + 1:]\n",
    "            middle = self.constant_to_tensor(j)\n",
    "            removed = tf.concat([begin, middle, end], axis = 0)\n",
    "            removed = tf.reshape(removed, (self.MAX_NUM_WORDS, ))\n",
    "            cur_removed_idx = cur_removed_idx + 1\n",
    "            continue\n",
    "          model_pred = split_predicted_text[j]\n",
    "          model_index = tf.argmax(tf.equal(model_pred, self.pad_token_id))\n",
    "          predicted_text = model_pred[:model_index]\n",
    "          jaccard_score = self.jaccard_similarity_score(ground_truth, predicted_text)\n",
    "          if jaccard_score > best_score:\n",
    "            best_score = jaccard_score\n",
    "            best_idx = j\n",
    "        \n",
    "        if best_score >= 0.5:\n",
    "          self.tp += 1\n",
    "          begin = removed[:cur_removed_idx]\n",
    "          end = removed[cur_removed_idx + 1:]\n",
    "          middle = self.constant_to_tensor(best_idx)\n",
    "          removed = tf.concat([begin, middle, end], axis = 0)\n",
    "          removed = tf.reshape(removed, (self.MAX_NUM_WORDS, ))\n",
    "          cur_removed_idx = cur_removed_idx + 1\n",
    "\n",
    "        else:\n",
    "          self.fn += 1\n",
    "      # compute How many removed indices weren't used.\n",
    "      count = tf.where(tf.equal(removed, tf.constant(-1, dtype = removed.dtype)))\n",
    "      count = tf.reshape(count, (-1, ))\n",
    "      for _ in range(len(count)):\n",
    "        self.fp += 1\n",
    "  def reset_states(self):\n",
    "    self.tp = 0.0\n",
    "    self.fp = 0.0\n",
    "    self.fn = 0.0\n",
    "  def result(self):\n",
    "    # Compute BETA score\n",
    "    tp = self.tp * (1 + self.beta ** 2)\n",
    "    fn = self.fn * (self.beta ** 2)\n",
    "    fp = self.fp\n",
    "    eps = 1e-8\n",
    "    fbeta = (tp + eps) / (tp + fp + fn + eps)\n",
    "    return fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "liked-vehicle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:34.483142Z",
     "iopub.status.busy": "2021-06-22T20:20:34.482307Z",
     "iopub.status.idle": "2021-06-22T20:20:34.485726Z",
     "shell.execute_reply": "2021-06-22T20:20:34.485164Z"
    },
    "id": "xc8S4Np1sTEq",
    "papermill": {
     "duration": 0.048252,
     "end_time": "2021-06-22T20:20:34.485862",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.437610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ValF1Score(keras.metrics.Metric):\n",
    "  def __init__(self, name = 'f1score', **kwargs):\n",
    "    super().__init__(name = name, **kwargs)\n",
    "    \n",
    "    self.inter = tf.Variable(0.0, TARGET_DTYPE)\n",
    "    self.union = tf.Variable(0.0, TARGET_DTYPE)\n",
    "\n",
    "  def reset_states(self):\n",
    "    self.inter.assign(tf.cast(0.0, TARGET_DTYPE))\n",
    "    self.union.assign(tf.cast(0.0, TARGET_DTYPE))\n",
    "    \n",
    "  @tf.function\n",
    "  def update_state(self, GT, y_pred):\n",
    "    # GT: Tensor(B, MAX_LEN)\n",
    "    # Y_PRED: Tensor(B, MAX_LEN)\n",
    "\n",
    "    # Compute the larger of the two indices\n",
    "    END_TOKEN = ModelConfig.END_TOKEN_INT\n",
    "    # Find the END token \n",
    "    end_tok_GT = tf.argmax(tf.equal(GT, END_TOKEN), axis = -1) # (B, )\n",
    "    end_tok_pred = tf.argmax(tf.equal(y_pred, END_TOKEN), axis = -1) # (B, ) \n",
    "    # Take the ARGMAX\n",
    "    end_toks = tf.maximum(end_tok_GT, end_tok_pred) # (B, )\n",
    "    B, L = GT.shape\n",
    "    for b in range(B):\n",
    "      # Index into the Tensors\n",
    "      ground_truth = GT[b]\n",
    "      ground_truth = ground_truth[:end_toks[b]]\n",
    "      preds = y_pred[b]\n",
    "      preds = preds[:end_toks[b]]\n",
    "  \n",
    "      # Comparison\n",
    "      tp = tf.cast(tf.equal(ground_truth, preds), dtype = TARGET_DTYPE)\n",
    "      inter = tf.reduce_sum(tp)\n",
    "      union = tf.cast(len(tf.reshape(ground_truth, (-1, ))) + len(tf.reshape(preds, (-1, ))), TARGET_DTYPE) - inter\n",
    "\n",
    "      self.inter.assign_add(inter)\n",
    "      self.union.assign_add(union)\n",
    "\n",
    "\n",
    "\n",
    "  def result(self):\n",
    "    eps = 1e-10\n",
    "    return (self.inter + eps) / (self.union + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-geology",
   "metadata": {
    "id": "_7MUNOepmtvz",
    "papermill": {
     "duration": 0.034235,
     "end_time": "2021-06-22T20:20:34.554027",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.519792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test all Splits after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sound-asthma",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:20:34.631705Z",
     "iopub.status.busy": "2021-06-22T20:20:34.630710Z",
     "iopub.status.idle": "2021-06-22T20:21:45.740441Z",
     "shell.execute_reply": "2021-06-22T20:21:45.740986Z"
    },
    "id": "PvtmJHTiAyui",
    "outputId": "da3108e3-aa00-4777-9bdd-abdd92492d77",
    "papermill": {
     "duration": 71.15327,
     "end_time": "2021-06-22T20:21:45.741212",
     "exception": false,
     "start_time": "2021-06-22T20:20:34.587942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------CREATE METRICS-------------------\n",
      "-------------CREATE LOSS FUNCTION---------------\n",
      "------------------CREATE MODEL--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b435e97b6bf41dea5c13f5c987d61b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------CREATE OPTIMIZER----------------\n",
      "------------------CREATE SCHEDULER----------------\n"
     ]
    }
   ],
   "source": [
    "def prep_training():\n",
    "  with strategy.scope():\n",
    "    print(f'----------------CREATE METRICS-------------------')\n",
    "    # ----------------Create METRICS-------------------\n",
    "    metrics = {\n",
    "        'train_loss': keras.metrics.Mean(),\n",
    "        'val_loss': keras.metrics.Mean(),\n",
    "        'train_acc': keras.metrics.Accuracy(),\n",
    "        'val_acc': keras.metrics.Accuracy(),\n",
    "        'val_f1': ValF1Score()# F1 Only Computed at Val Time, Since no Use to compute it at Train time.\n",
    "    }\n",
    "    print(f\"-------------CREATE LOSS FUNCTION---------------\")\n",
    "    label_smoothing = ModelConfig.label_smoothing\n",
    "    loss_obj = keras.losses.CategoricalCrossentropy(\n",
    "        from_logits = True,\n",
    "        label_smoothing = label_smoothing,\n",
    "        reduction = tf.keras.losses.Reduction.NONE   \n",
    "    )\n",
    "  \n",
    "    def loss_fn(GT, x):\n",
    "      # Computes loss, ignoring the <PAD> tokens.\n",
    "      \n",
    "      PAD_TOKEN = ModelConfig.tokenizer.pad_token_id\n",
    "      vocab_size = ModelConfig.tokenizer.vocab_size\n",
    "      mask = tf.not_equal(GT, PAD_TOKEN)\n",
    "\n",
    "      one_hot = tf.one_hot(GT, vocab_size)\n",
    "      loss = loss_obj(one_hot, x) # (B, L)\n",
    "      loss = loss * tf.cast(mask, loss.dtype)\n",
    "      # REDUCE AVG\n",
    "      loss = tf.nn.compute_average_loss(loss, global_batch_size= bs)\n",
    "      return loss\n",
    "    print(f\"------------------CREATE MODEL--------------------\")\n",
    "    # ---------------CREATE MODEL----------------(AND LOAD IT?)\n",
    "    model = FullModel()\n",
    "    print(f\"------------------CREATE OPTIMIZER----------------\")\n",
    "    # ---------------CREATE OPTIMIZER-----------------(AND LOAD IT?)\n",
    "    prev_optim_path = TrainingConfig.PREV_MODEL_PATH\n",
    "    if prev_optim_path is not None:\n",
    "      prev_optim_path = f\"{prev_optim_path}optimizer.npy\"\n",
    "    optimizer = GradAccAdam(model, TrainingConfig.learning_rate, 1, prev_optim_path = prev_optim_path)\n",
    "    print(f\"------------------CREATE SCHEDULER----------------\")\n",
    "    # ---------------CREATE SCHEDULER-----------------\n",
    "    scheduler = OneCycleScheduler(\n",
    "        TrainingConfig.learning_rate,\n",
    "        TrainingConfig.max_lr, \n",
    "        TrainingConfig.min_lr,\n",
    "        TrainingConfig.warm_steps,\n",
    "        TrainingConfig.peak_steps,\n",
    "        TrainingConfig.TOTAL_STEPS\n",
    "      )\n",
    "    return model, optimizer, metrics, loss_fn, scheduler\n",
    "model, optimizer, metrics, loss_fn, scheduler = prep_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-breed",
   "metadata": {
    "id": "OA2PZV-jNVk3",
    "papermill": {
     "duration": 0.038127,
     "end_time": "2021-06-22T20:21:45.817560",
     "exception": false,
     "start_time": "2021-06-22T20:21:45.779433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Training Steps(elementwise Loss, remove loss from PAD token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "featured-hearts",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:21:45.900883Z",
     "iopub.status.busy": "2021-06-22T20:21:45.900150Z",
     "iopub.status.idle": "2021-06-22T20:21:45.904512Z",
     "shell.execute_reply": "2021-06-22T20:21:45.903636Z"
    },
    "id": "VlbceCv8NaNJ",
    "papermill": {
     "duration": 0.050144,
     "end_time": "2021-06-22T20:21:45.904677",
     "exception": false,
     "start_time": "2021-06-22T20:21:45.854533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(input_ids, attention_mask, token_type_ids, labels):\n",
    "  training = True\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    predictions = model.call_train(input_ids, attention_mask, token_type_ids, labels[:, :-1], training = training)\n",
    "    loss = loss_fn(labels[:, 1:], predictions)\n",
    "\n",
    "    # Softmax and Compute Accuracy\n",
    "    predictions = keras.activations.softmax(predictions, axis = -1)\n",
    "    predictions = tf.argmax(predictions, axis = -1) # (B, L)\n",
    "\n",
    "    metrics['train_acc'].update_state(labels[:, 1:], predictions, sample_weight = \n",
    "          tf.where(tf.not_equal(labels[:, 1:], ModelConfig.PAD_TOKEN), 1.0, 0.0))\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  \n",
    "  loss = loss / (MAX_LENGTH_LABEL - 1)\n",
    "  metrics['train_loss'].update_state(loss)\n",
    "\n",
    "  optimizer.apply_gradients(gradients, model.trainable_variables)\n",
    "\n",
    "@tf.function\n",
    "def dist_train_step(iterator, num_steps):\n",
    "  for i in tf.range(num_steps):\n",
    "   (input_ids, attention_mask, token_type_ids), labels = next(iterator)\n",
    "   strategy.run(train_step, args = (input_ids, attention_mask, token_type_ids, labels)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-connecticut",
   "metadata": {
    "id": "LJwxew9yGetV",
    "papermill": {
     "duration": 0.03792,
     "end_time": "2021-06-22T20:21:45.980145",
     "exception": false,
     "start_time": "2021-06-22T20:21:45.942225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "egyptian-sigma",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:21:46.063832Z",
     "iopub.status.busy": "2021-06-22T20:21:46.063004Z",
     "iopub.status.idle": "2021-06-22T20:21:46.065709Z",
     "shell.execute_reply": "2021-06-22T20:21:46.065221Z"
    },
    "id": "nJIkzApAT7Uh",
    "papermill": {
     "duration": 0.047693,
     "end_time": "2021-06-22T20:21:46.065860",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.018167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_step(input_ids, attention_mask, token_type_ids, labels):\n",
    "  # Greedy Decoding Method\n",
    "  training = False\n",
    "  preds, pred_tokens = model.call_val(input_ids, attention_mask, token_type_ids, training = training)\n",
    "  # take the elementwise lossfn\n",
    "  loss = loss_fn(labels[:, 1:], preds)\n",
    "  loss = loss / (MAX_LENGTH_LABEL - 1)\n",
    "  metrics['val_loss'].update_state(loss)\n",
    "\n",
    "  # Compute the Accuracy of LM \n",
    "  metrics['val_acc'].update_state(labels[:, 1:], pred_tokens[:, 1:], sample_weight=\n",
    "    tf.where(tf.not_equal(labels[:, 1:], ModelConfig.PAD_TOKEN), 1.0, 0.0))\n",
    "  # Decode the predictions and accumulate the Val F1 Score\n",
    "  return labels[:, 1:], pred_tokens[:, 1:]\n",
    "\n",
    "@tf.function\n",
    "def dist_val_step(input_ids, attention_mask, token_type_ids, labels):\n",
    "  labels, pred_tokens = strategy.run(val_step, args = (input_ids, attention_mask, token_type_ids, labels))\n",
    "  labels = strategy.gather(labels, axis = 0)\n",
    "  pred_tokens = strategy.gather(pred_tokens, axis = 0)\n",
    "  return labels, pred_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-timer",
   "metadata": {
    "id": "EltnLR5fzeet",
    "papermill": {
     "duration": 0.036592,
     "end_time": "2021-06-22T20:21:46.137933",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.101341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stat Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "british-thunder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:21:46.214916Z",
     "iopub.status.busy": "2021-06-22T20:21:46.214193Z",
     "iopub.status.idle": "2021-06-22T20:21:46.223929Z",
     "shell.execute_reply": "2021-06-22T20:21:46.224408Z"
    },
    "id": "1swVegFpzgLU",
    "papermill": {
     "duration": 0.048995,
     "end_time": "2021-06-22T20:21:46.224602",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.175607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StatLogger():\n",
    "  def __init__(self):\n",
    "    self.EPOCHS = 0\n",
    "    self.STEPS = 0\n",
    "    \n",
    "    self.best_f1 = tf.Variable(tf.constant(0.0, dtype = TARGET_DTYPE))\n",
    "    self.best_acc = tf.Variable(tf.constant(0.0, dtype = TARGET_DTYPE))\n",
    "    self.best_loss = tf.Variable(1e6, dtype = TARGET_DTYPE)\n",
    "  def update_train(self):\n",
    "    # Grab the Current LR and other Stat, called every TrainingConfig.STEPS_PER\n",
    "    lr = optimizer.optimizer.learning_rate.numpy().item()\n",
    "    train_acc = metrics['train_acc'].result().numpy().item()\n",
    "    train_loss = metrics['train_loss'].result().numpy().item()\n",
    "\n",
    "    print(f\"E: {self.EPOCHS}, S: {self.STEPS}, TA: {train_acc}, TL: {train_loss}, LR: {lr}\")\n",
    "    self.STEPS += TrainingConfig.STEPS_PER\n",
    "    # Reset the States\n",
    "    metrics['train_acc'].reset_states()\n",
    "    metrics['train_loss'].reset_states()\n",
    "\n",
    "  def update_val(self):\n",
    "    val_acc = metrics['val_acc'].result().numpy().item()\n",
    "    val_loss = metrics['val_loss'].result().numpy().item()\n",
    "    #val_f1 = metrics['val_f1'].result().numpy().item()\n",
    "\n",
    "    #if val_f1 >= self.best_f1:\n",
    "    #  self.best_f1.assign(val_f1)\n",
    "    #  save_states('f1')\n",
    "    if val_loss <= self.best_loss:\n",
    "      self.best_loss.assign(val_loss)\n",
    "      save_states('loss')\n",
    "    if val_acc >= self.best_acc:\n",
    "      self.best_acc.assign(val_acc)\n",
    "      save_states('acc')\n",
    "    \n",
    "    print(f\"E: {self.EPOCHS}, BA: {self.best_acc}, BL: {self.best_loss}, VA: {val_acc}, VL: {val_loss}\")\n",
    "    self.EPOCHS += 1\n",
    "    for m in metrics:\n",
    "      metrics[m].reset_states()\n",
    "  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-turkey",
   "metadata": {
    "id": "ACSLtFHJNeLZ",
    "papermill": {
     "duration": 0.035548,
     "end_time": "2021-06-22T20:21:46.295904",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.260356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# train the model\n",
    "- FIX F1 Score\n",
    "- Val Loss is Broken too.\n",
    "- Problem with LR Scheduler too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-dairy",
   "metadata": {
    "id": "L5ist4xv24nW",
    "papermill": {
     "duration": 0.035035,
     "end_time": "2021-06-22T20:21:46.366750",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.331715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Change Metric to F1 in BMS\n",
    "- Or just use Accuracy as metric.\n",
    "- Consider Changing the tokenizer method(Subword? BPE?)\n",
    "- Try Larger ROBERTA model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-corruption",
   "metadata": {
    "id": "TdnArMYeAwm5",
    "papermill": {
     "duration": 0.035508,
     "end_time": "2021-06-22T20:21:46.438210",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.402702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRaining Rapidly\n",
    "1) ROBERTA BASE on LM - TPU Colab\n",
    "\n",
    "2) XLNET BASE on LM - TPU Kaggle\n",
    "\n",
    "3) DistilROBERTA on LM - GPU Kaggle\n",
    "\n",
    "4) XLNET LARGE - TPU Kaggle\n",
    "# Then, Inference using the ROBERTA sets, while doing this:\n",
    "1) Best XLNET on NER\n",
    "\n",
    "2) Best XLNEt on QA\n",
    "\n",
    "3) Best ROBERTA on NER\n",
    "\n",
    "4) Best ROBERTA on QA\n",
    "\n",
    "- Ensemble while waiting for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "artistic-engineering",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:21:46.513713Z",
     "iopub.status.busy": "2021-06-22T20:21:46.512735Z",
     "iopub.status.idle": "2021-06-22T20:21:46.516543Z",
     "shell.execute_reply": "2021-06-22T20:21:46.517071Z"
    },
    "id": "fuCF_yLRF5h7",
    "papermill": {
     "duration": 0.043441,
     "end_time": "2021-06-22T20:21:46.517385",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.473944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nonprofit-organic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:21:46.593061Z",
     "iopub.status.busy": "2021-06-22T20:21:46.592405Z",
     "iopub.status.idle": "2021-06-22T20:21:46.596083Z",
     "shell.execute_reply": "2021-06-22T20:21:46.596643Z"
    },
    "papermill": {
     "duration": 0.043772,
     "end_time": "2021-06-22T20:21:46.596842",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.553070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "portable-romania",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:21:46.674204Z",
     "iopub.status.busy": "2021-06-22T20:21:46.673624Z",
     "iopub.status.idle": "2021-06-22T20:21:46.677794Z",
     "shell.execute_reply": "2021-06-22T20:21:46.678294Z"
    },
    "id": "HHsPIXuW3MkN",
    "papermill": {
     "duration": 0.044361,
     "end_time": "2021-06-22T20:21:46.678697",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.634336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_LOOPS_EVERY_VAL = 1 # Val is super slow, so we eval every 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "boxed-eight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:21:46.754341Z",
     "iopub.status.busy": "2021-06-22T20:21:46.753730Z",
     "iopub.status.idle": "2021-06-22T21:29:49.370001Z",
     "shell.execute_reply": "2021-06-22T21:29:49.369462Z"
    },
    "id": "yStVoIdCy8HO",
    "outputId": "ea25d846-3a5f-4744-cec8-575243d2ca50",
    "papermill": {
     "duration": 4082.655518,
     "end_time": "2021-06-22T21:29:49.370163",
     "exception": false,
     "start_time": "2021-06-22T20:21:46.714645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "E: 0, S: 0, TA: 0.21552331745624542, TL: 0.7022749185562134, LR: 2.0025686353619676e-06\n",
      "E: 0, S: 100, TA: 0.22265516221523285, TL: 0.6121121644973755, LR: 2.010378011618741e-06\n",
      "E: 0, S: 200, TA: 0.23111367225646973, TL: 0.5746179223060608, LR: 2.023426532105077e-06\n",
      "E: 0, S: 300, TA: 0.2209639549255371, TL: 0.586740255355835, LR: 2.041711468336871e-06\n",
      "E: 0, S: 400, TA: 0.22704696655273438, TL: 0.5550917983055115, LR: 2.06522895496164e-06\n",
      "E: 0, S: 500, TA: 0.21747994422912598, TL: 0.5661287903785706, LR: 2.0939737623848487e-06\n",
      "E: 0, S: 600, TA: 0.23869909346103668, TL: 0.4964577555656433, LR: 2.1279392967699096e-06\n",
      "E: 0, S: 700, TA: 0.21840022504329681, TL: 0.53590989112854, LR: 2.167118736906559e-06\n",
      "E: 0, S: 800, TA: 0.22650057077407837, TL: 0.5024697184562683, LR: 2.21150298784778e-06\n",
      "E: 0, S: 900, TA: 0.21222974359989166, TL: 0.526620626449585, LR: 2.2610827272728784e-06\n",
      "E: 0, S: 1000, TA: 0.21508267521858215, TL: 0.4958970546722412, LR: 2.3158470412454335e-06\n",
      "E: 0, S: 1100, TA: 0.23598097264766693, TL: 0.4440345764160156, LR: 2.3757836515869712e-06\n",
      "E: 0, S: 1200, TA: 0.26650574803352356, TL: 0.4364520311355591, LR: 2.440879825371667e-06\n",
      "E: 0, S: 1300, TA: 0.27964553236961365, TL: 0.43469956517219543, LR: 2.5111214654316427e-06\n",
      "E: 0, S: 1400, TA: 0.3049716055393219, TL: 0.4063694477081299, LR: 2.586492655609618e-06\n",
      "E: 0, S: 1500, TA: 0.3075234293937683, TL: 0.38896143436431885, LR: 2.6669774797483115e-06\n",
      "E: 0, S: 1600, TA: 0.28678199648857117, TL: 0.4163942039012909, LR: 2.7525582027010387e-06\n",
      "E: 0, S: 1700, TA: 0.303064227104187, TL: 0.39893680810928345, LR: 2.8432161798264133e-06\n",
      "E: 0, S: 1800, TA: 0.3283904492855072, TL: 0.37661752104759216, LR: 2.9389314022409962e-06\n",
      "E: 0, S: 1900, TA: 0.31036806106567383, TL: 0.406648725271225, LR: 3.039682951566647e-06\n",
      "E: 0, S: 2000, TA: 0.3457159101963043, TL: 0.3650517165660858, LR: 3.145449227304198e-06\n",
      "E: 0, S: 2100, TA: 0.3439176380634308, TL: 0.35223984718322754, LR: 3.2562068099650787e-06\n",
      "E: 0, S: 2200, TA: 0.3257216811180115, TL: 0.36240309476852417, LR: 3.371931370566017e-06\n",
      "E: 0, S: 2300, TA: 0.3566208779811859, TL: 0.3322320878505707, LR: 3.4925981253763894e-06\n",
      "E: 0, S: 2400, TA: 0.3299543261528015, TL: 0.34659191966056824, LR: 3.6181802443024935e-06\n",
      "E: 0, S: 2500, TA: 0.3735581040382385, TL: 0.31247201561927795, LR: 3.7486506698769517e-06\n",
      "E: 0, S: 2600, TA: 0.406627357006073, TL: 0.32175061106681824, LR: 3.883980298269307e-06\n",
      "E: 0, S: 2700, TA: 0.4233403205871582, TL: 0.32938921451568604, LR: 4.02414070777013e-06\n",
      "E: 0, S: 2800, TA: 0.462240993976593, TL: 0.33340099453926086, LR: 4.169100066064857e-06\n",
      "E: 0, S: 2900, TA: 0.5321203470230103, TL: 0.3031376600265503, LR: 4.318827450333629e-06\n",
      "E: 0, S: 3000, TA: 0.4854432940483093, TL: 0.3372371792793274, LR: 4.4732896640198305e-06\n",
      "E: 0, S: 3100, TA: 0.49871882796287537, TL: 0.3211117684841156, LR: 4.632453510566847e-06\n",
      "E: 0, S: 3200, TA: 0.5041608810424805, TL: 0.3094123601913452, LR: 4.796283974428661e-06\n",
      "E: 0, S: 3300, TA: 0.5225905776023865, TL: 0.29488471150398254, LR: 4.964745130564552e-06\n",
      "E: 0, S: 3400, TA: 0.5542992949485779, TL: 0.27983853220939636, LR: 5.1378001444390975e-06\n",
      "VALIDATION LOOP\n",
      "SAVING STATES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING STATES\n",
      "E: 0, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.21830986>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5233979>, VA: 0.21830986440181732, VL: 0.5233979225158691\n",
      "EPOCH: 1\n",
      "E: 1, S: 3500, TA: 0.5673118233680725, TL: 0.2683919668197632, LR: 5.3154117267695256e-06\n",
      "E: 1, S: 3600, TA: 0.5033743381500244, TL: 0.30196383595466614, LR: 5.49754076928366e-06\n",
      "E: 1, S: 3700, TA: 0.5742615461349487, TL: 0.2672550678253174, LR: 5.684147254214622e-06\n",
      "E: 1, S: 3800, TA: 0.543166995048523, TL: 0.2741634249687195, LR: 5.8751911637955345e-06\n",
      "E: 1, S: 3900, TA: 0.6217756867408752, TL: 0.24449342489242554, LR: 6.070629751775414e-06\n",
      "E: 1, S: 4000, TA: 0.6459279656410217, TL: 0.2212294638156891, LR: 6.270421181397978e-06\n",
      "E: 1, S: 4100, TA: 0.6461604237556458, TL: 0.24033623933792114, LR: 6.474521342170192e-06\n",
      "E: 1, S: 4200, TA: 0.6280891299247742, TL: 0.25889381766319275, LR: 6.682885668851668e-06\n",
      "E: 1, S: 4300, TA: 0.6273812651634216, TL: 0.23640255630016327, LR: 6.895468686707318e-06\n",
      "E: 1, S: 4400, TA: 0.6398445963859558, TL: 0.23889805376529694, LR: 7.112224466254702e-06\n",
      "E: 1, S: 4500, TA: 0.684461236000061, TL: 0.22810307145118713, LR: 7.333105259021977e-06\n",
      "E: 1, S: 4600, TA: 0.6918652653694153, TL: 0.22901292145252228, LR: 7.558062861789949e-06\n",
      "E: 1, S: 4700, TA: 0.7235055565834045, TL: 0.21285505592823029, LR: 7.787048161844723e-06\n",
      "E: 1, S: 4800, TA: 0.7539756894111633, TL: 0.21974889934062958, LR: 8.02001068223035e-06\n",
      "E: 1, S: 4900, TA: 0.7366417646408081, TL: 0.21837402880191803, LR: 8.256900400738232e-06\n",
      "E: 1, S: 5000, TA: 0.7717287540435791, TL: 0.2082158327102661, LR: 8.497664566675667e-06\n",
      "E: 1, S: 5100, TA: 0.7431694269180298, TL: 0.21050018072128296, LR: 8.742252248339355e-06\n",
      "E: 1, S: 5200, TA: 0.7777622938156128, TL: 0.19829994440078735, LR: 8.990607966552489e-06\n",
      "E: 1, S: 5300, TA: 0.7828444242477417, TL: 0.19836679100990295, LR: 9.242678970622364e-06\n",
      "E: 1, S: 5400, TA: 0.7707006335258484, TL: 0.20913738012313843, LR: 9.498409781372175e-06\n",
      "E: 1, S: 5500, TA: 0.811947226524353, TL: 0.18478932976722717, LR: 9.757744010130409e-06\n",
      "E: 1, S: 5600, TA: 0.830547571182251, TL: 0.17602702975273132, LR: 1.002062617772026e-05\n",
      "E: 1, S: 5700, TA: 0.8214696049690247, TL: 0.1791227161884308, LR: 1.0286998076480813e-05\n",
      "E: 1, S: 5800, TA: 0.8186651468276978, TL: 0.18291181325912476, LR: 1.0556801498751156e-05\n",
      "E: 1, S: 5900, TA: 0.8580816388130188, TL: 0.1690502017736435, LR: 1.0829977327375673e-05\n",
      "E: 1, S: 6000, TA: 0.8648571968078613, TL: 0.16479596495628357, LR: 1.1106466445198748e-05\n",
      "E: 1, S: 6100, TA: 0.8387405872344971, TL: 0.17679542303085327, LR: 1.1386208825570066e-05\n",
      "E: 1, S: 6200, TA: 0.8577598929405212, TL: 0.15474791824817657, LR: 1.1669141713355202e-05\n",
      "E: 1, S: 6300, TA: 0.8629668354988098, TL: 0.15026623010635376, LR: 1.1955205081903841e-05\n",
      "E: 1, S: 6400, TA: 0.8747206926345825, TL: 0.15982404351234436, LR: 1.224433617608156e-05\n",
      "E: 1, S: 6500, TA: 0.8285115957260132, TL: 0.18193940818309784, LR: 1.2536471331259236e-05\n",
      "E: 1, S: 6600, TA: 0.874643862247467, TL: 0.14501366019248962, LR: 1.2831545973313041e-05\n",
      "E: 1, S: 6700, TA: 0.9001981616020203, TL: 0.1440286785364151, LR: 1.3129497347108554e-05\n",
      "E: 1, S: 6800, TA: 0.8701095581054688, TL: 0.15185898542404175, LR: 1.3430259969027247e-05\n",
      "E: 1, S: 6900, TA: 0.9056122303009033, TL: 0.14345146715641022, LR: 1.3733767445955891e-05\n",
      "VALIDATION LOOP\n",
      "SAVING STATES\n",
      "E: 1, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.21830986>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.504813>, VA: 0.11549295485019684, VL: 0.504813015460968\n",
      "EPOCH: 2\n",
      "E: 2, S: 7000, TA: 0.8969029784202576, TL: 0.15013666450977325, LR: 1.4039953384781256e-05\n",
      "E: 2, S: 7100, TA: 0.8899986147880554, TL: 0.14702072739601135, LR: 1.4348751392390113e-05\n",
      "E: 2, S: 7200, TA: 0.8893963098526001, TL: 0.14616289734840393, LR: 1.4660094166174531e-05\n",
      "E: 2, S: 7300, TA: 0.9083106517791748, TL: 0.14692524075508118, LR: 1.4973914403526578e-05\n",
      "E: 2, S: 7400, TA: 0.9092184901237488, TL: 0.14148388803005219, LR: 1.5290141163859516e-05\n",
      "E: 2, S: 7500, TA: 0.8984830975532532, TL: 0.13637959957122803, LR: 1.5608708054060116e-05\n",
      "E: 2, S: 7600, TA: 0.9201020002365112, TL: 0.13544204831123352, LR: 1.5929543224046938e-05\n",
      "E: 2, S: 7700, TA: 0.9264811873435974, TL: 0.13041608035564423, LR: 1.625257937121205e-05\n",
      "E: 2, S: 7800, TA: 0.921562910079956, TL: 0.13052457571029663, LR: 1.657774373597931e-05\n",
      "E: 2, S: 7900, TA: 0.9278980493545532, TL: 0.1406107395887375, LR: 1.6904965377761982e-05\n",
      "E: 2, S: 8000, TA: 0.9130851626396179, TL: 0.1413993239402771, LR: 1.7234173355973326e-05\n",
      "E: 2, S: 8100, TA: 0.9197907447814941, TL: 0.12745356559753418, LR: 1.7565296730026603e-05\n",
      "E: 2, S: 8200, TA: 0.9382504224777222, TL: 0.125519260764122, LR: 1.7898260921356268e-05\n",
      "E: 2, S: 8300, TA: 0.9276057481765747, TL: 0.12489154189825058, LR: 1.8232994989375584e-05\n",
      "E: 2, S: 8400, TA: 0.9251598715782166, TL: 0.1358715295791626, LR: 1.8569426174508408e-05\n",
      "E: 2, S: 8500, TA: 0.9405954480171204, TL: 0.12671637535095215, LR: 1.8907479898189195e-05\n",
      "E: 2, S: 8600, TA: 0.9179051518440247, TL: 0.13114586472511292, LR: 1.92470815818524e-05\n",
      "E: 2, S: 8700, TA: 0.923733651638031, TL: 0.13231569528579712, LR: 1.958815846592188e-05\n",
      "E: 2, S: 8800, TA: 0.9227241277694702, TL: 0.13554805517196655, LR: 1.993063597183209e-05\n",
      "E: 2, S: 8900, TA: 0.9423349499702454, TL: 0.12622849643230438, LR: 2.0274439521017484e-05\n",
      "E: 2, S: 9000, TA: 0.9430450797080994, TL: 0.12559251487255096, LR: 2.0619492715923116e-05\n",
      "E: 2, S: 9100, TA: 0.9392842650413513, TL: 0.13324613869190216, LR: 2.0965720977983437e-05\n",
      "E: 2, S: 9200, TA: 0.9308400750160217, TL: 0.13229520618915558, LR: 2.1313049728632905e-05\n",
      "E: 2, S: 9300, TA: 0.957031786441803, TL: 0.1219894215464592, LR: 2.1661400751327164e-05\n",
      "E: 2, S: 9400, TA: 0.9124478101730347, TL: 0.144993856549263, LR: 2.2010699467500672e-05\n",
      "E: 2, S: 9500, TA: 0.9526181221008301, TL: 0.12121875584125519, LR: 2.2360869479598477e-05\n",
      "E: 2, S: 9600, TA: 0.9576966762542725, TL: 0.11908130347728729, LR: 2.2711836209055036e-05\n",
      "E: 2, S: 9700, TA: 0.9504626393318176, TL: 0.1208888590335846, LR: 2.3063519620336592e-05\n",
      "E: 2, S: 9800, TA: 0.9535256624221802, TL: 0.11696872115135193, LR: 2.3415843315888196e-05\n",
      "E: 2, S: 9900, TA: 0.9644801020622253, TL: 0.11695102602243423, LR: 2.3768732717144303e-05\n",
      "E: 2, S: 10000, TA: 0.9537187814712524, TL: 0.12728969752788544, LR: 2.412210960756056e-05\n",
      "E: 2, S: 10100, TA: 0.9577221870422363, TL: 0.11706449836492538, LR: 2.4475895770592615e-05\n",
      "E: 2, S: 10200, TA: 0.9693167805671692, TL: 0.12008196860551834, LR: 2.483001480868552e-05\n",
      "E: 2, S: 10300, TA: 0.9644246101379395, TL: 0.11516990512609482, LR: 2.518438850529492e-05\n",
      "E: 2, S: 10400, TA: 0.9645448327064514, TL: 0.12135070562362671, LR: 2.553894228185527e-05\n",
      "VALIDATION LOOP\n",
      "SAVING STATES\n",
      "SAVING STATES\n",
      "E: 2, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.35211268067359924, VL: 0.4839719235897064\n",
      "EPOCH: 3\n",
      "E: 3, S: 10500, TA: 0.9667383432388306, TL: 0.11442578583955765, LR: 2.5893596102832817e-05\n",
      "E: 3, S: 10600, TA: 0.9622177481651306, TL: 0.11543624103069305, LR: 2.624827357067261e-05\n",
      "E: 3, S: 10700, TA: 0.9683677554130554, TL: 0.11667466908693314, LR: 2.660289464984089e-05\n",
      "E: 3, S: 10800, TA: 0.9717596173286438, TL: 0.11223513633012772, LR: 2.6957386580761522e-05\n",
      "E: 3, S: 10900, TA: 0.9640752077102661, TL: 0.11827820539474487, LR: 2.731166750891134e-05\n",
      "E: 3, S: 11000, TA: 0.9577858448028564, TL: 0.12035325169563293, LR: 2.7665662855724804e-05\n",
      "E: 3, S: 11100, TA: 0.9565454125404358, TL: 0.12319020926952362, LR: 2.8019294404657558e-05\n",
      "E: 3, S: 11200, TA: 0.9731610417366028, TL: 0.11390705406665802, LR: 2.8372485758154653e-05\n",
      "E: 3, S: 11300, TA: 0.9658792614936829, TL: 0.11196514219045639, LR: 2.8725158699671738e-05\n",
      "E: 3, S: 11400, TA: 0.9522683024406433, TL: 0.12257297337055206, LR: 2.907723501266446e-05\n",
      "E: 3, S: 11500, TA: 0.9658889174461365, TL: 0.12053296715021133, LR: 2.9428640118567273e-05\n",
      "E: 3, S: 11600, TA: 0.9694492220878601, TL: 0.11351829767227173, LR: 2.977929761982523e-05\n",
      "E: 3, S: 11700, TA: 0.969576895236969, TL: 0.1149676963686943, LR: 3.0129129299893975e-05\n",
      "E: 3, S: 11800, TA: 0.9684455394744873, TL: 0.11226633936166763, LR: 3.047805694222916e-05\n",
      "E: 3, S: 11900, TA: 0.970921516418457, TL: 0.11959962546825409, LR: 3.082600960624404e-05\n",
      "E: 3, S: 12000, TA: 0.9703036546707153, TL: 0.12006264925003052, LR: 3.1172905437415466e-05\n",
      "E: 3, S: 12100, TA: 0.9699582457542419, TL: 0.11596692353487015, LR: 3.151867349515669e-05\n",
      "E: 3, S: 12200, TA: 0.9577211141586304, TL: 0.12101446837186813, LR: 3.186323738191277e-05\n",
      "E: 3, S: 12300, TA: 0.961002767086029, TL: 0.12495370209217072, LR: 3.220651706214994e-05\n",
      "E: 3, S: 12400, TA: 0.9670842289924622, TL: 0.12233415246009827, LR: 3.254844341427088e-05\n",
      "E: 3, S: 12500, TA: 0.9707461595535278, TL: 0.11461205780506134, LR: 3.288894004072063e-05\n",
      "E: 3, S: 12600, TA: 0.966303288936615, TL: 0.11508562415838242, LR: 3.322793054394424e-05\n",
      "E: 3, S: 12700, TA: 0.9694557189941406, TL: 0.1115584447979927, LR: 3.356534580234438e-05\n",
      "E: 3, S: 12800, TA: 0.941451370716095, TL: 0.1271757185459137, LR: 3.39011057803873e-05\n",
      "E: 3, S: 12900, TA: 0.969196617603302, TL: 0.11666122078895569, LR: 3.423514135647565e-05\n",
      "E: 3, S: 13000, TA: 0.9626092910766602, TL: 0.12226390093564987, LR: 3.4567376133054495e-05\n",
      "E: 3, S: 13100, TA: 0.969764232635498, TL: 0.1164618507027626, LR: 3.48977446265053e-05\n",
      "E: 3, S: 13200, TA: 0.9653835296630859, TL: 0.11387216299772263, LR: 3.522616680129431e-05\n",
      "E: 3, S: 13300, TA: 0.9704990386962891, TL: 0.1157623752951622, LR: 3.5552573535824195e-05\n",
      "E: 3, S: 13400, TA: 0.9730753898620605, TL: 0.11792340129613876, LR: 3.5876895708497614e-05\n",
      "E: 3, S: 13500, TA: 0.9692572951316833, TL: 0.11242131888866425, LR: 3.619905692175962e-05\n",
      "E: 3, S: 13600, TA: 0.970370352268219, TL: 0.11363431811332703, LR: 3.6518995329970494e-05\n",
      "E: 3, S: 13700, TA: 0.9667708277702332, TL: 0.11389681696891785, LR: 3.6836634535575286e-05\n",
      "E: 3, S: 13800, TA: 0.9720556139945984, TL: 0.1103348508477211, LR: 3.715190541697666e-05\n",
      "E: 3, S: 13900, TA: 0.9732950329780579, TL: 0.11139252036809921, LR: 3.746474249055609e-05\n",
      "VALIDATION LOOP\n",
      "E: 3, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.13239437341690063, VL: 0.5809769630432129\n",
      "EPOCH: 4\n",
      "E: 4, S: 14000, TA: 0.9632532000541687, TL: 0.11856535822153091, LR: 3.777507663471624e-05\n",
      "E: 4, S: 14100, TA: 0.9808444976806641, TL: 0.11212807893753052, LR: 3.808283872785978e-05\n",
      "E: 4, S: 14200, TA: 0.9732561111450195, TL: 0.11649226397275925, LR: 3.838795964838937e-05\n",
      "E: 4, S: 14300, TA: 0.9810897707939148, TL: 0.11212489008903503, LR: 3.869037755066529e-05\n",
      "E: 4, S: 14400, TA: 0.9521085619926453, TL: 0.12496352195739746, LR: 3.8990023313090205e-05\n",
      "E: 4, S: 14500, TA: 0.9733703136444092, TL: 0.1148536428809166, LR: 3.928683145204559e-05\n",
      "E: 4, S: 14600, TA: 0.9729583263397217, TL: 0.1186487004160881, LR: 3.958074012189172e-05\n",
      "E: 4, S: 14700, TA: 0.9705610275268555, TL: 0.12288553267717361, LR: 3.987168020103127e-05\n",
      "E: 4, S: 14800, TA: 0.9727966785430908, TL: 0.11617744714021683, LR: 4.0159589843824506e-05\n",
      "E: 4, S: 14900, TA: 0.9756205081939697, TL: 0.10863128304481506, LR: 4.044441084261052e-05\n",
      "E: 4, S: 15000, TA: 0.9764337539672852, TL: 0.11583396792411804, LR: 4.0726074075791985e-05\n",
      "E: 4, S: 15100, TA: 0.9746249914169312, TL: 0.11333537101745605, LR: 4.100452133570798e-05\n",
      "E: 4, S: 15200, TA: 0.9684462547302246, TL: 0.11414462327957153, LR: 4.127969441469759e-05\n",
      "E: 4, S: 15300, TA: 0.966690719127655, TL: 0.11193526536226273, LR: 4.155152782914229e-05\n",
      "E: 4, S: 15400, TA: 0.9710511565208435, TL: 0.11351241171360016, LR: 4.181996700935997e-05\n",
      "E: 4, S: 15500, TA: 0.979600191116333, TL: 0.11477190256118774, LR: 4.208495010971092e-05\n",
      "E: 4, S: 15600, TA: 0.9687545299530029, TL: 0.1111408993601799, LR: 4.234641892253421e-05\n",
      "E: 4, S: 15700, TA: 0.9683481454849243, TL: 0.11441318690776825, LR: 4.260431887814775e-05\n",
      "E: 4, S: 15800, TA: 0.9773821830749512, TL: 0.10844466835260391, LR: 4.285859176889062e-05\n",
      "E: 4, S: 15900, TA: 0.9662589430809021, TL: 0.1151408925652504, LR: 4.310918302508071e-05\n",
      "E: 4, S: 16000, TA: 0.9759498834609985, TL: 0.11195609718561172, LR: 4.335603807703592e-05\n",
      "E: 4, S: 16100, TA: 0.9775914549827576, TL: 0.10986310988664627, LR: 4.359910235507414e-05\n",
      "E: 4, S: 16200, TA: 0.9687802195549011, TL: 0.11769932508468628, LR: 4.383832492749207e-05\n",
      "E: 4, S: 16300, TA: 0.9770668148994446, TL: 0.11206650733947754, LR: 4.4073647586628795e-05\n",
      "E: 4, S: 16400, TA: 0.9805954694747925, TL: 0.10571754723787308, LR: 4.4305026676738635e-05\n",
      "E: 4, S: 16500, TA: 0.9809339642524719, TL: 0.11342205852270126, LR: 4.453240762813948e-05\n",
      "E: 4, S: 16600, TA: 0.9735127687454224, TL: 0.11267825216054916, LR: 4.4755739509128034e-05\n",
      "E: 4, S: 16700, TA: 0.9724453091621399, TL: 0.11513171344995499, LR: 4.49749750259798e-05\n",
      "E: 4, S: 16800, TA: 0.9796206951141357, TL: 0.1108333021402359, LR: 4.519006688497029e-05\n",
      "E: 4, S: 16900, TA: 0.9658389091491699, TL: 0.11836492270231247, LR: 4.540096779237501e-05\n",
      "E: 4, S: 17000, TA: 0.9749966859817505, TL: 0.11964426934719086, LR: 4.560763409244828e-05\n",
      "E: 4, S: 17100, TA: 0.9692614078521729, TL: 0.11305630952119827, LR: 4.581001485348679e-05\n",
      "E: 4, S: 17200, TA: 0.9774360656738281, TL: 0.11054649949073792, LR: 4.600807005772367e-05\n",
      "E: 4, S: 17300, TA: 0.967872679233551, TL: 0.10663876682519913, LR: 4.6201756049413234e-05\n",
      "E: 4, S: 17400, TA: 0.97015780210495, TL: 0.11215086281299591, LR: 4.6391029172809795e-05\n",
      "VALIDATION LOOP\n",
      "E: 4, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.10845070332288742, VL: 0.5696233510971069\n",
      "EPOCH: 5\n",
      "E: 5, S: 17500, TA: 0.9839761853218079, TL: 0.10965932160615921, LR: 4.6575849410146475e-05\n",
      "E: 5, S: 17600, TA: 0.9782089591026306, TL: 0.10556098818778992, LR: 4.67561767436564e-05\n",
      "E: 5, S: 17700, TA: 0.9631379842758179, TL: 0.12129399925470352, LR: 4.693197115557268e-05\n",
      "E: 5, S: 17800, TA: 0.9684104919433594, TL: 0.11254604160785675, LR: 4.7103192628128454e-05\n",
      "E: 5, S: 17900, TA: 0.9809091091156006, TL: 0.10293985158205032, LR: 4.726980478153564e-05\n",
      "E: 5, S: 18000, TA: 0.9819193482398987, TL: 0.11201862245798111, LR: 4.743177487398498e-05\n",
      "E: 5, S: 18100, TA: 0.9555031657218933, TL: 0.1214248463511467, LR: 4.758906288770959e-05\n",
      "E: 5, S: 18200, TA: 0.9741845726966858, TL: 0.11477382481098175, LR: 4.77416324429214e-05\n",
      "E: 5, S: 18300, TA: 0.9782927632331848, TL: 0.10747265815734863, LR: 4.7889458073768765e-05\n",
      "E: 5, S: 18400, TA: 0.9724069833755493, TL: 0.11298101395368576, LR: 4.8032499762484804e-05\n",
      "E: 5, S: 18500, TA: 0.9807530045509338, TL: 0.11154443025588989, LR: 4.817073204321787e-05\n",
      "E: 5, S: 18600, TA: 0.969243586063385, TL: 0.1151454746723175, LR: 4.830412217415869e-05\n",
      "E: 5, S: 18700, TA: 0.9831187129020691, TL: 0.10827766358852386, LR: 4.843264105147682e-05\n",
      "E: 5, S: 18800, TA: 0.9680451154708862, TL: 0.11932334303855896, LR: 4.85562595713418e-05\n",
      "E: 5, S: 18900, TA: 0.9778592586517334, TL: 0.11150359362363815, LR: 4.867495226790197e-05\n",
      "E: 5, S: 19000, TA: 0.9737061858177185, TL: 0.11532218009233475, LR: 4.8788693675305694e-05\n",
      "E: 5, S: 19100, TA: 0.9715813398361206, TL: 0.1134379580616951, LR: 4.8897458327701315e-05\n",
      "E: 5, S: 19200, TA: 0.9661623239517212, TL: 0.1180935651063919, LR: 4.9001220759237185e-05\n",
      "E: 5, S: 19300, TA: 0.9732834696769714, TL: 0.1156981885433197, LR: 4.909995914204046e-05\n",
      "E: 5, S: 19400, TA: 0.9799363613128662, TL: 0.11339068412780762, LR: 4.919365528621711e-05\n",
      "E: 5, S: 19500, TA: 0.9716349840164185, TL: 0.11903262138366699, LR: 4.928228372591548e-05\n",
      "E: 5, S: 19600, TA: 0.979434072971344, TL: 0.11351783573627472, LR: 4.936582990922034e-05\n",
      "E: 5, S: 19700, TA: 0.9800862073898315, TL: 0.10518212616443634, LR: 4.944427200825885e-05\n",
      "E: 5, S: 19800, TA: 0.962178111076355, TL: 0.12238059937953949, LR: 4.9517591833136976e-05\n",
      "E: 5, S: 19900, TA: 0.9744687080383301, TL: 0.11148976534605026, LR: 4.9585778469918296e-05\n",
      "E: 5, S: 20000, TA: 0.9824638366699219, TL: 0.10755462944507599, LR: 4.964881009072997e-05\n",
      "E: 5, S: 20100, TA: 0.9803250432014465, TL: 0.10957995057106018, LR: 4.9706679419614375e-05\n",
      "E: 5, S: 20200, TA: 0.9782460927963257, TL: 0.11520429700613022, LR: 4.975937190465629e-05\n",
      "E: 5, S: 20300, TA: 0.979519248008728, TL: 0.11044175922870636, LR: 4.980687299394049e-05\n",
      "E: 5, S: 20400, TA: 0.9833146333694458, TL: 0.11089331656694412, LR: 4.984917904948816e-05\n",
      "E: 5, S: 20500, TA: 0.981665313243866, TL: 0.11306213587522507, LR: 4.9886271881405264e-05\n",
      "E: 5, S: 20600, TA: 0.9761459827423096, TL: 0.10939492285251617, LR: 4.991815148969181e-05\n",
      "E: 5, S: 20700, TA: 0.9757711887359619, TL: 0.11867332458496094, LR: 4.994480696041137e-05\n",
      "E: 5, S: 20800, TA: 0.9823625683784485, TL: 0.11415410786867142, LR: 4.996623101760633e-05\n",
      "E: 5, S: 20900, TA: 0.9825630784034729, TL: 0.1097656786441803, LR: 4.998242002329789e-05\n",
      "VALIDATION LOOP\n",
      "E: 5, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.14084507524967194, VL: 0.6340643167495728\n",
      "EPOCH: 6\n",
      "E: 6, S: 21000, TA: 0.9810912013053894, TL: 0.10781495273113251, LR: 4.9993373977486044e-05\n",
      "E: 6, S: 21100, TA: 0.9862937331199646, TL: 0.11077217757701874, LR: 4.9999089242191985e-05\n",
      "E: 6, S: 21200, TA: 0.9811345934867859, TL: 0.11736273765563965, LR: 4.999999873689376e-05\n",
      "E: 6, S: 21300, TA: 0.9831401705741882, TL: 0.10387437045574188, LR: 4.999999873689376e-05\n",
      "E: 6, S: 21400, TA: 0.9723003506660461, TL: 0.11273052543401718, LR: 4.999999873689376e-05\n",
      "E: 6, S: 21500, TA: 0.9689650535583496, TL: 0.11464398354291916, LR: 4.999999873689376e-05\n",
      "E: 6, S: 21600, TA: 0.9657127261161804, TL: 0.11622218042612076, LR: 4.999999873689376e-05\n",
      "E: 6, S: 21700, TA: 0.9711551666259766, TL: 0.11664919555187225, LR: 4.999999873689376e-05\n",
      "E: 6, S: 21800, TA: 0.9848037362098694, TL: 0.11022622883319855, LR: 4.999999873689376e-05\n",
      "E: 6, S: 21900, TA: 0.971716582775116, TL: 0.11446166038513184, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22000, TA: 0.9718419909477234, TL: 0.12165025621652603, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22100, TA: 0.9876205325126648, TL: 0.10700158029794693, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22200, TA: 0.9794701337814331, TL: 0.1133170798420906, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22300, TA: 0.9817783236503601, TL: 0.11417679488658905, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22400, TA: 0.9832959175109863, TL: 0.11049599945545197, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22500, TA: 0.9845762252807617, TL: 0.10943461209535599, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22600, TA: 0.9820654392242432, TL: 0.10426098108291626, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22700, TA: 0.9773218035697937, TL: 0.1166825070977211, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22800, TA: 0.985093891620636, TL: 0.10845741629600525, LR: 4.999999873689376e-05\n",
      "E: 6, S: 22900, TA: 0.977671205997467, TL: 0.11394692212343216, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23000, TA: 0.9821656346321106, TL: 0.11004944890737534, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23100, TA: 0.9794900417327881, TL: 0.11335138231515884, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23200, TA: 0.979056179523468, TL: 0.1179673969745636, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23300, TA: 0.9787473678588867, TL: 0.11176052689552307, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23400, TA: 0.9832776188850403, TL: 0.10679000616073608, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23500, TA: 0.9795325398445129, TL: 0.11323533207178116, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23600, TA: 0.9839556813240051, TL: 0.10939941555261612, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23700, TA: 0.9822930693626404, TL: 0.10578512400388718, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23800, TA: 0.9794031381607056, TL: 0.11116031557321548, LR: 4.999999873689376e-05\n",
      "E: 6, S: 23900, TA: 0.9805073738098145, TL: 0.10865919291973114, LR: 4.999999873689376e-05\n",
      "E: 6, S: 24000, TA: 0.980195164680481, TL: 0.10880876332521439, LR: 4.999999873689376e-05\n",
      "E: 6, S: 24100, TA: 0.9775184988975525, TL: 0.11095257103443146, LR: 4.999999873689376e-05\n",
      "E: 6, S: 24200, TA: 0.9818105697631836, TL: 0.110842265188694, LR: 4.999999873689376e-05\n",
      "E: 6, S: 24300, TA: 0.9827749729156494, TL: 0.11466735601425171, LR: 4.999999873689376e-05\n",
      "E: 6, S: 24400, TA: 0.9833656549453735, TL: 0.11284860968589783, LR: 4.999999873689376e-05\n",
      "VALIDATION LOOP\n",
      "E: 6, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.17605634033679962, VL: 0.5938645601272583\n",
      "EPOCH: 7\n",
      "E: 7, S: 24500, TA: 0.971843421459198, TL: 0.12614692747592926, LR: 4.999999873689376e-05\n",
      "E: 7, S: 24600, TA: 0.9829453229904175, TL: 0.1150921881198883, LR: 4.999999873689376e-05\n",
      "E: 7, S: 24700, TA: 0.9813998341560364, TL: 0.11333141475915909, LR: 4.999999873689376e-05\n",
      "E: 7, S: 24800, TA: 0.9802179932594299, TL: 0.11598086357116699, LR: 4.999999873689376e-05\n",
      "E: 7, S: 24900, TA: 0.9817150831222534, TL: 0.10959549993276596, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25000, TA: 0.9802435636520386, TL: 0.11551877111196518, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25100, TA: 0.9863466620445251, TL: 0.10777555406093597, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25200, TA: 0.9834335446357727, TL: 0.1162780374288559, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25300, TA: 0.9825664758682251, TL: 0.10926255583763123, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25400, TA: 0.9787688851356506, TL: 0.11052237451076508, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25500, TA: 0.984794020652771, TL: 0.112391397356987, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25600, TA: 0.9852367639541626, TL: 0.11122254282236099, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25700, TA: 0.980103075504303, TL: 0.11038052290678024, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25800, TA: 0.9832305908203125, TL: 0.10872364044189453, LR: 4.999999873689376e-05\n",
      "E: 7, S: 25900, TA: 0.9737944006919861, TL: 0.11737571656703949, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26000, TA: 0.9785875678062439, TL: 0.11774712800979614, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26100, TA: 0.9849238991737366, TL: 0.1089610606431961, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26200, TA: 0.9829361438751221, TL: 0.10987468808889389, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26300, TA: 0.9849281907081604, TL: 0.10888642072677612, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26400, TA: 0.9848881363868713, TL: 0.10610253363847733, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26500, TA: 0.9785492420196533, TL: 0.11108022928237915, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26600, TA: 0.9839260578155518, TL: 0.10932217538356781, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26700, TA: 0.9833706021308899, TL: 0.11131425946950912, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26800, TA: 0.9876279830932617, TL: 0.1082620918750763, LR: 4.999999873689376e-05\n",
      "E: 7, S: 26900, TA: 0.9841452836990356, TL: 0.10745259374380112, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27000, TA: 0.9718092679977417, TL: 0.11433199048042297, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27100, TA: 0.9758052825927734, TL: 0.11018037796020508, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27200, TA: 0.9805839657783508, TL: 0.10761239379644394, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27300, TA: 0.9829553365707397, TL: 0.11316829919815063, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27400, TA: 0.9885458946228027, TL: 0.11002689599990845, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27500, TA: 0.9779482483863831, TL: 0.11424612253904343, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27600, TA: 0.9838210344314575, TL: 0.1105460450053215, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27700, TA: 0.9861910343170166, TL: 0.10775511711835861, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27800, TA: 0.9845447540283203, TL: 0.10128919780254364, LR: 4.999999873689376e-05\n",
      "E: 7, S: 27900, TA: 0.9803447127342224, TL: 0.10275397449731827, LR: 4.999999873689376e-05\n",
      "VALIDATION LOOP\n",
      "E: 7, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.1267605572938919, VL: 0.5846554040908813\n",
      "EPOCH: 8\n",
      "E: 8, S: 28000, TA: 0.9865553379058838, TL: 0.10892541706562042, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28100, TA: 0.9812656044960022, TL: 0.11199802160263062, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28200, TA: 0.983810544013977, TL: 0.11567333340644836, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28300, TA: 0.9786628484725952, TL: 0.11026005446910858, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28400, TA: 0.9815872311592102, TL: 0.10913710296154022, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28500, TA: 0.9831331968307495, TL: 0.10858132690191269, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28600, TA: 0.9743486046791077, TL: 0.11752043664455414, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28700, TA: 0.9835126399993896, TL: 0.110549695789814, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28800, TA: 0.9876610040664673, TL: 0.11381593346595764, LR: 4.999999873689376e-05\n",
      "E: 8, S: 28900, TA: 0.9825717210769653, TL: 0.11328563094139099, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29000, TA: 0.9846308827400208, TL: 0.10783538967370987, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29100, TA: 0.9831395149230957, TL: 0.1070953831076622, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29200, TA: 0.9870344996452332, TL: 0.1023113951086998, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29300, TA: 0.9844223856925964, TL: 0.11231429129838943, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29400, TA: 0.9841357469558716, TL: 0.11244674772024155, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29500, TA: 0.9849845767021179, TL: 0.11007849872112274, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29600, TA: 0.9777621626853943, TL: 0.11068067699670792, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29700, TA: 0.9823800325393677, TL: 0.11509977281093597, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29800, TA: 0.9861263632774353, TL: 0.11219510436058044, LR: 4.999999873689376e-05\n",
      "E: 8, S: 29900, TA: 0.9823976755142212, TL: 0.11699309200048447, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30000, TA: 0.9873599410057068, TL: 0.1070006862282753, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30100, TA: 0.9836665987968445, TL: 0.10990903526544571, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30200, TA: 0.9893085956573486, TL: 0.10784441977739334, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30300, TA: 0.9842798709869385, TL: 0.10947690159082413, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30400, TA: 0.9817658066749573, TL: 0.11310115456581116, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30500, TA: 0.9809536933898926, TL: 0.11254871636629105, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30600, TA: 0.9789623022079468, TL: 0.11061610281467438, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30700, TA: 0.9840345978736877, TL: 0.10378772020339966, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30800, TA: 0.9814191460609436, TL: 0.11556338518857956, LR: 4.999999873689376e-05\n",
      "E: 8, S: 30900, TA: 0.9749414920806885, TL: 0.11391805857419968, LR: 4.999999873689376e-05\n",
      "E: 8, S: 31000, TA: 0.9811785221099854, TL: 0.10712990909814835, LR: 4.999999873689376e-05\n",
      "E: 8, S: 31100, TA: 0.9866064786911011, TL: 0.10579270124435425, LR: 4.999999873689376e-05\n",
      "E: 8, S: 31200, TA: 0.98365318775177, TL: 0.10949718207120895, LR: 4.999999873689376e-05\n",
      "E: 8, S: 31300, TA: 0.9854635000228882, TL: 0.11250096559524536, LR: 4.999999873689376e-05\n",
      "E: 8, S: 31400, TA: 0.9832752346992493, TL: 0.1113707572221756, LR: 4.999999873689376e-05\n",
      "VALIDATION LOOP\n",
      "E: 8, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.10845070332288742, VL: 0.6564761400222778\n",
      "EPOCH: 9\n",
      "E: 9, S: 31500, TA: 0.983770489692688, TL: 0.10636749863624573, LR: 4.999999873689376e-05\n",
      "E: 9, S: 31600, TA: 0.9888355135917664, TL: 0.10837604850530624, LR: 4.999999873689376e-05\n",
      "E: 9, S: 31700, TA: 0.9842396974563599, TL: 0.1088423952460289, LR: 4.999999873689376e-05\n",
      "E: 9, S: 31800, TA: 0.9854214787483215, TL: 0.10699982941150665, LR: 4.999999873689376e-05\n",
      "E: 9, S: 31900, TA: 0.9869950413703918, TL: 0.11182519793510437, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32000, TA: 0.9803116321563721, TL: 0.11000645905733109, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32100, TA: 0.9869064688682556, TL: 0.10690897703170776, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32200, TA: 0.9838842749595642, TL: 0.11227376013994217, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32300, TA: 0.9756622314453125, TL: 0.11753164231777191, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32400, TA: 0.9796492457389832, TL: 0.11715241521596909, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32500, TA: 0.9832935333251953, TL: 0.11013224720954895, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32600, TA: 0.9830151200294495, TL: 0.11760983616113663, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32700, TA: 0.9803839921951294, TL: 0.11182866990566254, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32800, TA: 0.9877889156341553, TL: 0.10535174608230591, LR: 4.999999873689376e-05\n",
      "E: 9, S: 32900, TA: 0.9785540699958801, TL: 0.11562756448984146, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33000, TA: 0.9840282797813416, TL: 0.10921082645654678, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33100, TA: 0.9824678897857666, TL: 0.11586176604032516, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33200, TA: 0.9817981123924255, TL: 0.11357052624225616, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33300, TA: 0.9858676195144653, TL: 0.11363435536623001, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33400, TA: 0.9824267625808716, TL: 0.11158647388219833, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33500, TA: 0.984551727771759, TL: 0.11178570985794067, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33600, TA: 0.9802998900413513, TL: 0.10594842582941055, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33700, TA: 0.983256995677948, TL: 0.10755304992198944, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33800, TA: 0.9863810539245605, TL: 0.10876423120498657, LR: 4.999999873689376e-05\n",
      "E: 9, S: 33900, TA: 0.9889994263648987, TL: 0.1015833392739296, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34000, TA: 0.9880089163780212, TL: 0.11014199256896973, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34100, TA: 0.9864240884780884, TL: 0.10949880629777908, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34200, TA: 0.9843642711639404, TL: 0.1126871109008789, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34300, TA: 0.9893903136253357, TL: 0.10806844383478165, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34400, TA: 0.9858723878860474, TL: 0.10621350258588791, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34500, TA: 0.983601987361908, TL: 0.1124241054058075, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34600, TA: 0.9824798107147217, TL: 0.11553151160478592, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34700, TA: 0.9866235256195068, TL: 0.10495951771736145, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34800, TA: 0.982616126537323, TL: 0.1092304140329361, LR: 4.999999873689376e-05\n",
      "E: 9, S: 34900, TA: 0.9862542748451233, TL: 0.11242231726646423, LR: 4.999999873689376e-05\n",
      "VALIDATION LOOP\n",
      "E: 9, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.10845070332288742, VL: 0.6372302770614624\n",
      "EPOCH: 10\n",
      "E: 10, S: 35000, TA: 0.9832515120506287, TL: 0.10699786245822906, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35100, TA: 0.9874319434165955, TL: 0.11002881824970245, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35200, TA: 0.9847729802131653, TL: 0.11207801103591919, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35300, TA: 0.9870166182518005, TL: 0.10990799963474274, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35400, TA: 0.9878489971160889, TL: 0.10597384721040726, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35500, TA: 0.9881070256233215, TL: 0.10831143707036972, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35600, TA: 0.9889324903488159, TL: 0.10928839445114136, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35700, TA: 0.9815629124641418, TL: 0.10963954776525497, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35800, TA: 0.9875830411911011, TL: 0.10635903477668762, LR: 4.999999873689376e-05\n",
      "E: 10, S: 35900, TA: 0.9832708835601807, TL: 0.11623515188694, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36000, TA: 0.9841180443763733, TL: 0.11037857085466385, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36100, TA: 0.983011782169342, TL: 0.10737363994121552, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36200, TA: 0.986588180065155, TL: 0.11257583647966385, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36300, TA: 0.9806146025657654, TL: 0.10846491158008575, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36400, TA: 0.982470691204071, TL: 0.11241619288921356, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36500, TA: 0.9861596822738647, TL: 0.11013106256723404, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36600, TA: 0.9862837791442871, TL: 0.10790815949440002, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36700, TA: 0.9876493811607361, TL: 0.11590123176574707, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36800, TA: 0.9835856556892395, TL: 0.10932789742946625, LR: 4.999999873689376e-05\n",
      "E: 10, S: 36900, TA: 0.9818155765533447, TL: 0.10820653289556503, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37000, TA: 0.9849087595939636, TL: 0.112677201628685, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37100, TA: 0.9899240732192993, TL: 0.11136026680469513, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37200, TA: 0.9841980338096619, TL: 0.11091924458742142, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37300, TA: 0.9857264161109924, TL: 0.10925105214118958, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37400, TA: 0.9839670658111572, TL: 0.10879494994878769, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37500, TA: 0.983812689781189, TL: 0.10702259093523026, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37600, TA: 0.9844545722007751, TL: 0.11541621387004852, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37700, TA: 0.9869289994239807, TL: 0.10908675938844681, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37800, TA: 0.9874231815338135, TL: 0.10725805163383484, LR: 4.999999873689376e-05\n",
      "E: 10, S: 37900, TA: 0.9875149130821228, TL: 0.11611227691173553, LR: 4.999999873689376e-05\n",
      "E: 10, S: 38000, TA: 0.979519248008728, TL: 0.11006398499011993, LR: 4.999999873689376e-05\n",
      "E: 10, S: 38100, TA: 0.9886554479598999, TL: 0.10960611701011658, LR: 4.999999873689376e-05\n",
      "E: 10, S: 38200, TA: 0.9834815859794617, TL: 0.1094566360116005, LR: 4.999999873689376e-05\n",
      "E: 10, S: 38300, TA: 0.9866148829460144, TL: 0.10681769996881485, LR: 4.999999873689376e-05\n",
      "E: 10, S: 38400, TA: 0.9880322813987732, TL: 0.11044356971979141, LR: 4.999999873689376e-05\n",
      "VALIDATION LOOP\n",
      "E: 10, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.10845070332288742, VL: 0.6946998834609985\n",
      "EPOCH: 11\n",
      "E: 11, S: 38500, TA: 0.9877589344978333, TL: 0.11387471109628677, LR: 4.999999873689376e-05\n",
      "E: 11, S: 38600, TA: 0.9891899824142456, TL: 0.10634617507457733, LR: 4.999999873689376e-05\n",
      "E: 11, S: 38700, TA: 0.9891485571861267, TL: 0.11007887870073318, LR: 4.999999873689376e-05\n",
      "E: 11, S: 38800, TA: 0.9894534945487976, TL: 0.11196881532669067, LR: 4.999999873689376e-05\n",
      "E: 11, S: 38900, TA: 0.9786551594734192, TL: 0.11178014427423477, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39000, TA: 0.9894649386405945, TL: 0.11027391254901886, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39100, TA: 0.9796158075332642, TL: 0.10730543732643127, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39200, TA: 0.9806499481201172, TL: 0.10590148717164993, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39300, TA: 0.9871543049812317, TL: 0.10181701928377151, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39400, TA: 0.9842615127563477, TL: 0.11513280868530273, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39500, TA: 0.9863882660865784, TL: 0.11703595519065857, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39600, TA: 0.9889399409294128, TL: 0.10663166642189026, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39700, TA: 0.9819004535675049, TL: 0.11632294952869415, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39800, TA: 0.9869381785392761, TL: 0.10951278358697891, LR: 4.999999873689376e-05\n",
      "E: 11, S: 39900, TA: 0.9832804799079895, TL: 0.10731764137744904, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40000, TA: 0.9842042922973633, TL: 0.10445208847522736, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40100, TA: 0.9896616339683533, TL: 0.11407169699668884, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40200, TA: 0.9846651554107666, TL: 0.10933733731508255, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40300, TA: 0.985377311706543, TL: 0.11159493774175644, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40400, TA: 0.9872260093688965, TL: 0.11372982710599899, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40500, TA: 0.9875442385673523, TL: 0.10873489081859589, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40600, TA: 0.9908483624458313, TL: 0.10477060079574585, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40700, TA: 0.990313708782196, TL: 0.10559225082397461, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40800, TA: 0.9884309768676758, TL: 0.10617232322692871, LR: 4.999999873689376e-05\n",
      "E: 11, S: 40900, TA: 0.9857590198516846, TL: 0.10823347419500351, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41000, TA: 0.9935799241065979, TL: 0.10898977518081665, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41100, TA: 0.98490971326828, TL: 0.11485385149717331, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41200, TA: 0.9849505424499512, TL: 0.1091432198882103, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41300, TA: 0.9888677597045898, TL: 0.10475286841392517, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41400, TA: 0.9855519533157349, TL: 0.10988926142454147, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41500, TA: 0.9852383136749268, TL: 0.10990535467863083, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41600, TA: 0.9846587181091309, TL: 0.10955017060041428, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41700, TA: 0.9833575487136841, TL: 0.11739195883274078, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41800, TA: 0.9783122539520264, TL: 0.11315489560365677, LR: 4.999999873689376e-05\n",
      "E: 11, S: 41900, TA: 0.9776200652122498, TL: 0.11462216079235077, LR: 4.999999873689376e-05\n",
      "VALIDATION LOOP\n",
      "E: 11, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.12253521382808685, VL: 0.6857070922851562\n",
      "EPOCH: 12\n",
      "E: 12, S: 42000, TA: 0.9802795052528381, TL: 0.11878523230552673, LR: 4.999999873689376e-05\n",
      "E: 12, S: 42100, TA: 0.9868714809417725, TL: 0.11007686704397202, LR: 4.999999873689376e-05\n",
      "E: 12, S: 42200, TA: 0.9847862720489502, TL: 0.10133570432662964, LR: 4.999999873689376e-05\n",
      "E: 12, S: 42300, TA: 0.9899556636810303, TL: 0.1036103367805481, LR: 4.999999873689376e-05\n",
      "E: 12, S: 42400, TA: 0.9870072603225708, TL: 0.10397814959287643, LR: 4.999999873689376e-05\n",
      "E: 12, S: 42500, TA: 0.9880634546279907, TL: 0.10909420996904373, LR: 4.999999509891495e-05\n",
      "E: 12, S: 42600, TA: 0.9839908480644226, TL: 0.10827189683914185, LR: 4.999997327104211e-05\n",
      "E: 12, S: 42700, TA: 0.9857672452926636, TL: 0.10356578975915909, LR: 4.999993325327523e-05\n",
      "E: 12, S: 42800, TA: 0.9909407496452332, TL: 0.10978226363658905, LR: 4.9999878683593124e-05\n",
      "E: 12, S: 42900, TA: 0.984054684638977, TL: 0.11470185965299606, LR: 4.999980592401698e-05\n",
      "E: 12, S: 43000, TA: 0.9831363558769226, TL: 0.11702930182218552, LR: 4.9999714974546805e-05\n",
      "E: 12, S: 43100, TA: 0.9821056723594666, TL: 0.11213415861129761, LR: 4.99996094731614e-05\n",
      "E: 12, S: 43200, TA: 0.9884889721870422, TL: 0.10501053929328918, LR: 4.999948578188196e-05\n",
      "E: 12, S: 43300, TA: 0.9882785677909851, TL: 0.11223431676626205, LR: 4.999934753868729e-05\n",
      "E: 12, S: 43400, TA: 0.9872199892997742, TL: 0.11197108030319214, LR: 4.999918746761978e-05\n",
      "E: 12, S: 43500, TA: 0.9871091842651367, TL: 0.11194035410881042, LR: 4.9999016482615843e-05\n",
      "E: 12, S: 43600, TA: 0.988798201084137, TL: 0.11115598678588867, LR: 4.999882366973907e-05\n",
      "E: 12, S: 43700, TA: 0.9841433167457581, TL: 0.10491087287664413, LR: 4.999861630494706e-05\n",
      "E: 12, S: 43800, TA: 0.9838709831237793, TL: 0.11443199217319489, LR: 4.999839438823983e-05\n",
      "E: 12, S: 43900, TA: 0.9787912368774414, TL: 0.11245999485254288, LR: 4.9998150643659756e-05\n",
      "E: 12, S: 44000, TA: 0.9881906509399414, TL: 0.10942026227712631, LR: 4.999789234716445e-05\n",
      "E: 12, S: 44100, TA: 0.9774416089057922, TL: 0.11966189742088318, LR: 4.999761949875392e-05\n",
      "E: 12, S: 44200, TA: 0.9881038665771484, TL: 0.10578175634145737, LR: 4.999732846044935e-05\n",
      "E: 12, S: 44300, TA: 0.985797107219696, TL: 0.1058323010802269, LR: 4.999701923225075e-05\n",
      "E: 12, S: 44400, TA: 0.9869496822357178, TL: 0.10701989382505417, LR: 4.999669181415811e-05\n",
      "E: 12, S: 44500, TA: 0.9887914657592773, TL: 0.10695712268352509, LR: 4.9996349844150245e-05\n",
      "E: 12, S: 44600, TA: 0.9893348217010498, TL: 0.10883937031030655, LR: 4.999599332222715e-05\n",
      "E: 12, S: 44700, TA: 0.9869521856307983, TL: 0.10815267264842987, LR: 4.999561497243121e-05\n",
      "E: 12, S: 44800, TA: 0.9892428517341614, TL: 0.11084546148777008, LR: 4.999522207072005e-05\n",
      "E: 12, S: 44900, TA: 0.9870532155036926, TL: 0.10929055511951447, LR: 4.999481461709365e-05\n",
      "E: 12, S: 45000, TA: 0.9870958924293518, TL: 0.11035075038671494, LR: 4.999438897357322e-05\n",
      "E: 12, S: 45100, TA: 0.991812527179718, TL: 0.10838113725185394, LR: 4.999394514015876e-05\n",
      "E: 12, S: 45200, TA: 0.9856047630310059, TL: 0.11493154615163803, LR: 4.999348311685026e-05\n",
      "E: 12, S: 45300, TA: 0.9865152835845947, TL: 0.10791564732789993, LR: 4.999300654162653e-05\n",
      "E: 12, S: 45400, TA: 0.9876970052719116, TL: 0.11098865419626236, LR: 4.9992511776508763e-05\n",
      "VALIDATION LOOP\n",
      "E: 12, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.10422535240650177, VL: 0.6540867686271667\n",
      "EPOCH: 13\n",
      "E: 13, S: 45500, TA: 0.9887489676475525, TL: 0.11457405239343643, LR: 4.999200245947577e-05\n",
      "E: 13, S: 45600, TA: 0.9884058237075806, TL: 0.11169466376304626, LR: 4.999147495254874e-05\n",
      "E: 13, S: 45700, TA: 0.9839255213737488, TL: 0.10918337851762772, LR: 4.999092925572768e-05\n",
      "E: 13, S: 45800, TA: 0.987730085849762, TL: 0.11002539843320847, LR: 4.9990369006991386e-05\n",
      "E: 13, S: 45900, TA: 0.9901108741760254, TL: 0.1017441675066948, LR: 4.998979056836106e-05\n",
      "E: 13, S: 46000, TA: 0.9841028451919556, TL: 0.11149579286575317, LR: 4.9989193939836696e-05\n",
      "E: 13, S: 46100, TA: 0.985460638999939, TL: 0.1102723777294159, LR: 4.9988582759397104e-05\n",
      "E: 13, S: 46200, TA: 0.9854881167411804, TL: 0.10523755848407745, LR: 4.9987957027042285e-05\n",
      "E: 13, S: 46300, TA: 0.9873540997505188, TL: 0.11123499274253845, LR: 4.998730946681462e-05\n",
      "E: 13, S: 46400, TA: 0.9879118204116821, TL: 0.11573784798383713, LR: 4.998664735467173e-05\n",
      "E: 13, S: 46500, TA: 0.9870019555091858, TL: 0.10818471759557724, LR: 4.9985967052634805e-05\n",
      "E: 13, S: 46600, TA: 0.9884706139564514, TL: 0.11011934280395508, LR: 4.998527219868265e-05\n",
      "E: 13, S: 46700, TA: 0.9843925833702087, TL: 0.11031851172447205, LR: 4.998455915483646e-05\n",
      "E: 13, S: 46800, TA: 0.9891525506973267, TL: 0.11312820762395859, LR: 4.9983827921096236e-05\n",
      "E: 13, S: 46900, TA: 0.9888101816177368, TL: 0.10858424007892609, LR: 4.998308213544078e-05\n",
      "E: 13, S: 47000, TA: 0.9899929761886597, TL: 0.10851270705461502, LR: 4.998231815989129e-05\n",
      "E: 13, S: 47100, TA: 0.987707257270813, TL: 0.10743852704763412, LR: 4.9981539632426575e-05\n",
      "E: 13, S: 47200, TA: 0.9855590462684631, TL: 0.1082703098654747, LR: 4.998074291506782e-05\n",
      "E: 13, S: 47300, TA: 0.9865339398384094, TL: 0.10561127960681915, LR: 4.997992800781503e-05\n",
      "E: 13, S: 47400, TA: 0.9832364320755005, TL: 0.11511234939098358, LR: 4.9979098548647016e-05\n",
      "E: 13, S: 47500, TA: 0.9889107346534729, TL: 0.10926257073879242, LR: 4.9978250899584964e-05\n",
      "E: 13, S: 47600, TA: 0.9894091486930847, TL: 0.10970915108919144, LR: 4.9977385060628876e-05\n",
      "E: 13, S: 47700, TA: 0.9871063828468323, TL: 0.11346037685871124, LR: 4.997650466975756e-05\n",
      "E: 13, S: 47800, TA: 0.985962450504303, TL: 0.11048433184623718, LR: 4.997560608899221e-05\n",
      "E: 13, S: 47900, TA: 0.9901823401451111, TL: 0.10892056673765182, LR: 4.997469295631163e-05\n",
      "E: 13, S: 48000, TA: 0.9851506948471069, TL: 0.10564759373664856, LR: 4.997376163373701e-05\n",
      "E: 13, S: 48100, TA: 0.9877037405967712, TL: 0.10716357827186584, LR: 4.997281212126836e-05\n",
      "E: 13, S: 48200, TA: 0.9857926368713379, TL: 0.10980543494224548, LR: 4.9971844418905675e-05\n",
      "E: 13, S: 48300, TA: 0.9868344068527222, TL: 0.1049780398607254, LR: 4.997086216462776e-05\n",
      "E: 13, S: 48400, TA: 0.9853577017784119, TL: 0.11043193936347961, LR: 4.996986535843462e-05\n",
      "E: 13, S: 48500, TA: 0.9795526266098022, TL: 0.11407522857189178, LR: 4.996885036234744e-05\n",
      "E: 13, S: 48600, TA: 0.9853611588478088, TL: 0.1120498850941658, LR: 4.9967817176366225e-05\n",
      "E: 13, S: 48700, TA: 0.9878232479095459, TL: 0.11240256577730179, LR: 4.9966765800490975e-05\n",
      "E: 13, S: 48800, TA: 0.9863074421882629, TL: 0.10469017177820206, LR: 4.99656998727005e-05\n",
      "E: 13, S: 48900, TA: 0.9854143857955933, TL: 0.11297319084405899, LR: 4.9964615755015984e-05\n",
      "VALIDATION LOOP\n",
      "E: 13, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.13802817463874817, VL: 0.6965936422348022\n",
      "EPOCH: 14\n",
      "E: 14, S: 49000, TA: 0.9894958138465881, TL: 0.10263299196958542, LR: 4.996351708541624e-05\n",
      "E: 14, S: 49100, TA: 0.9816276431083679, TL: 0.11356721818447113, LR: 4.9962400225922465e-05\n",
      "E: 14, S: 49200, TA: 0.9923203587532043, TL: 0.11105015128850937, LR: 4.996126517653465e-05\n",
      "E: 14, S: 49300, TA: 0.9912011027336121, TL: 0.10922761261463165, LR: 4.996011557523161e-05\n",
      "E: 14, S: 49400, TA: 0.9898831844329834, TL: 0.1074909046292305, LR: 4.9958947784034535e-05\n",
      "E: 14, S: 49500, TA: 0.9838709831237793, TL: 0.11241268366575241, LR: 4.995776544092223e-05\n",
      "E: 14, S: 49600, TA: 0.9858244061470032, TL: 0.11187121272087097, LR: 4.995656126993708e-05\n",
      "E: 14, S: 49700, TA: 0.9860557913780212, TL: 0.10790199041366577, LR: 4.9955346185015514e-05\n",
      "E: 14, S: 49800, TA: 0.9906657338142395, TL: 0.1112443283200264, LR: 4.99541092722211e-05\n",
      "E: 14, S: 49900, TA: 0.9889037609100342, TL: 0.11477620899677277, LR: 4.9952857807511464e-05\n",
      "E: 14, S: 50000, TA: 0.9855011105537415, TL: 0.10943935066461563, LR: 4.9951591790886596e-05\n",
      "E: 14, S: 50100, TA: 0.9875389337539673, TL: 0.11288104951381683, LR: 4.9950303946388885e-05\n",
      "E: 14, S: 50200, TA: 0.9911577701568604, TL: 0.11041297763586044, LR: 4.9949005187954754e-05\n",
      "E: 14, S: 50300, TA: 0.9902804493904114, TL: 0.11016817390918732, LR: 4.994768460164778e-05\n",
      "E: 14, S: 50400, TA: 0.9826075434684753, TL: 0.11429747939109802, LR: 4.994634946342558e-05\n",
      "E: 14, S: 50500, TA: 0.9867706298828125, TL: 0.11041967570781708, LR: 4.994499613530934e-05\n",
      "E: 14, S: 50600, TA: 0.9918009042739868, TL: 0.10580949485301971, LR: 4.994362825527787e-05\n",
      "E: 14, S: 50700, TA: 0.9935318827629089, TL: 0.10091909766197205, LR: 4.994224218535237e-05\n",
      "E: 14, S: 50800, TA: 0.9878469705581665, TL: 0.11107464879751205, LR: 4.994083792553283e-05\n",
      "E: 14, S: 50900, TA: 0.9895028471946716, TL: 0.10493358969688416, LR: 4.993941911379807e-05\n",
      "E: 14, S: 51000, TA: 0.9805413484573364, TL: 0.10703422874212265, LR: 4.9937982112169266e-05\n",
      "E: 14, S: 51100, TA: 0.9873107671737671, TL: 0.10715878754854202, LR: 4.9936530558625236e-05\n",
      "E: 14, S: 51200, TA: 0.9865559339523315, TL: 0.11632583290338516, LR: 4.993506081518717e-05\n",
      "E: 14, S: 51300, TA: 0.9867540001869202, TL: 0.10788179188966751, LR: 4.993357288185507e-05\n",
      "E: 14, S: 51400, TA: 0.9843077063560486, TL: 0.1107325330376625, LR: 4.9932066758628935e-05\n",
      "E: 14, S: 51500, TA: 0.9829108715057373, TL: 0.10860109329223633, LR: 4.993054972146638e-05\n",
      "E: 14, S: 51600, TA: 0.981752336025238, TL: 0.11583386361598969, LR: 4.992901085643098e-05\n",
      "E: 14, S: 51700, TA: 0.9865425825119019, TL: 0.10717740654945374, LR: 4.992745743948035e-05\n",
      "E: 14, S: 51800, TA: 0.983359158039093, TL: 0.10989001393318176, LR: 4.9925885832635686e-05\n",
      "E: 14, S: 51900, TA: 0.9834882616996765, TL: 0.11127190291881561, LR: 4.9924299673875794e-05\n",
      "E: 14, S: 52000, TA: 0.9883787631988525, TL: 0.10719791054725647, LR: 4.9922695325221866e-05\n",
      "E: 14, S: 52100, TA: 0.9816463589668274, TL: 0.1133863553404808, LR: 4.9921072786673903e-05\n",
      "E: 14, S: 52200, TA: 0.9846243262290955, TL: 0.10696100443601608, LR: 4.991943569621071e-05\n",
      "E: 14, S: 52300, TA: 0.9859275221824646, TL: 0.10848397016525269, LR: 4.9917780415853485e-05\n",
      "E: 14, S: 52400, TA: 0.9885442852973938, TL: 0.10930844396352768, LR: 4.991610694560222e-05\n",
      "VALIDATION LOOP\n",
      "E: 14, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.11971831321716309, VL: 0.7139706611633301\n",
      "EPOCH: 15\n",
      "E: 15, S: 52500, TA: 0.983729362487793, TL: 0.11986412107944489, LR: 4.991441892343573e-05\n",
      "E: 15, S: 52600, TA: 0.9882387518882751, TL: 0.1041569784283638, LR: 4.991271271137521e-05\n",
      "E: 15, S: 52700, TA: 0.9867280125617981, TL: 0.11677367240190506, LR: 4.991099194739945e-05\n",
      "E: 15, S: 52800, TA: 0.98716139793396, TL: 0.1084902212023735, LR: 4.990925299352966e-05\n",
      "E: 15, S: 52900, TA: 0.9892852306365967, TL: 0.10816917568445206, LR: 4.990749584976584e-05\n",
      "E: 15, S: 53000, TA: 0.9880689382553101, TL: 0.1038849726319313, LR: 4.9905724154086784e-05\n",
      "E: 15, S: 53100, TA: 0.9908206462860107, TL: 0.11127366870641708, LR: 4.9903934268513694e-05\n",
      "E: 15, S: 53200, TA: 0.9915784001350403, TL: 0.11189994215965271, LR: 4.990212983102538e-05\n",
      "E: 15, S: 53300, TA: 0.9871737957000732, TL: 0.1044578105211258, LR: 4.9900307203643024e-05\n",
      "E: 15, S: 53400, TA: 0.9846392273902893, TL: 0.10927649587392807, LR: 4.9898466386366636e-05\n",
      "E: 15, S: 53500, TA: 0.9892129302024841, TL: 0.11485368013381958, LR: 4.989661101717502e-05\n",
      "E: 15, S: 53600, TA: 0.9865400791168213, TL: 0.10855643451213837, LR: 4.9894737458089367e-05\n",
      "E: 15, S: 53700, TA: 0.9850853085517883, TL: 0.10760460048913956, LR: 4.989284570910968e-05\n",
      "E: 15, S: 53800, TA: 0.9888855814933777, TL: 0.10327016562223434, LR: 4.989093940821476e-05\n",
      "E: 15, S: 53900, TA: 0.9854435324668884, TL: 0.11211255192756653, LR: 4.988901855540462e-05\n",
      "E: 15, S: 54000, TA: 0.9883424639701843, TL: 0.11418867111206055, LR: 4.988707587472163e-05\n",
      "E: 15, S: 54100, TA: 0.9902833104133606, TL: 0.1115010678768158, LR: 4.9885118642123416e-05\n",
      "E: 15, S: 54200, TA: 0.9844285845756531, TL: 0.10787756741046906, LR: 4.988314685760997e-05\n",
      "E: 15, S: 54300, TA: 0.9876992106437683, TL: 0.10940827429294586, LR: 4.988115688320249e-05\n",
      "E: 15, S: 54400, TA: 0.9899173974990845, TL: 0.10909135639667511, LR: 4.987914871890098e-05\n",
      "E: 15, S: 54500, TA: 0.9910765886306763, TL: 0.10605821013450623, LR: 4.987712236470543e-05\n",
      "E: 15, S: 54600, TA: 0.9896169304847717, TL: 0.10894941538572311, LR: 4.987508145859465e-05\n",
      "E: 15, S: 54700, TA: 0.9875354170799255, TL: 0.10856246203184128, LR: 4.987302600056864e-05\n",
      "E: 15, S: 54800, TA: 0.9839580059051514, TL: 0.10913138091564178, LR: 4.98709523526486e-05\n",
      "E: 15, S: 54900, TA: 0.9903367757797241, TL: 0.10748621821403503, LR: 4.986886051483452e-05\n",
      "E: 15, S: 55000, TA: 0.9821239113807678, TL: 0.11649207025766373, LR: 4.986675048712641e-05\n",
      "E: 15, S: 55100, TA: 0.9848307967185974, TL: 0.10609854012727737, LR: 4.986462590750307e-05\n",
      "E: 15, S: 55200, TA: 0.9879703521728516, TL: 0.10981464385986328, LR: 4.98624867759645e-05\n",
      "E: 15, S: 55300, TA: 0.9896953701972961, TL: 0.10235416144132614, LR: 4.9860325816553086e-05\n",
      "E: 15, S: 55400, TA: 0.9904391765594482, TL: 0.10229472070932388, LR: 4.9858150305226445e-05\n",
      "E: 15, S: 55500, TA: 0.9858913421630859, TL: 0.1171162873506546, LR: 4.9855960241984576e-05\n",
      "E: 15, S: 55600, TA: 0.9915966391563416, TL: 0.10875816643238068, LR: 4.985375198884867e-05\n",
      "E: 15, S: 55700, TA: 0.9891929626464844, TL: 0.10933757573366165, LR: 4.985152554581873e-05\n",
      "E: 15, S: 55800, TA: 0.9862020611763, TL: 0.11052966862916946, LR: 4.984928455087356e-05\n",
      "E: 15, S: 55900, TA: 0.9845062494277954, TL: 0.10662627965211868, LR: 4.984702536603436e-05\n",
      "VALIDATION LOOP\n",
      "E: 15, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.23943662643432617, VL: 0.5866640210151672\n",
      "EPOCH: 16\n",
      "E: 16, S: 56000, TA: 0.984886646270752, TL: 0.11033088713884354, LR: 4.9844751629279926e-05\n",
      "E: 16, S: 56100, TA: 0.9888641238212585, TL: 0.11714469641447067, LR: 4.984245606465265e-05\n",
      "E: 16, S: 56200, TA: 0.990526020526886, TL: 0.10781290382146835, LR: 4.9840149586088955e-05\n",
      "E: 16, S: 56300, TA: 0.9880803823471069, TL: 0.11073058843612671, LR: 4.983782127965242e-05\n",
      "E: 16, S: 56400, TA: 0.9901171922683716, TL: 0.10802263021469116, LR: 4.983548205927946e-05\n",
      "E: 16, S: 56500, TA: 0.9892341494560242, TL: 0.11212463676929474, LR: 4.9833121011033654e-05\n",
      "E: 16, S: 56600, TA: 0.9873183369636536, TL: 0.11644227057695389, LR: 4.983074541087262e-05\n",
      "E: 16, S: 56700, TA: 0.9825960993766785, TL: 0.106903575360775, LR: 4.982835162081756e-05\n",
      "E: 16, S: 56800, TA: 0.9879153966903687, TL: 0.11143139749765396, LR: 4.982594327884726e-05\n",
      "E: 16, S: 56900, TA: 0.9901975393295288, TL: 0.10124672949314117, LR: 4.982351674698293e-05\n",
      "E: 16, S: 57000, TA: 0.9893659949302673, TL: 0.113615483045578, LR: 4.9821072025224566e-05\n",
      "E: 16, S: 57100, TA: 0.9880768656730652, TL: 0.10893712937831879, LR: 4.981861275155097e-05\n",
      "E: 16, S: 57200, TA: 0.9857305884361267, TL: 0.10783925652503967, LR: 4.981613892596215e-05\n",
      "E: 16, S: 57300, TA: 0.9892533421516418, TL: 0.10989665240049362, LR: 4.9813643272500485e-05\n",
      "E: 16, S: 57400, TA: 0.9852842092514038, TL: 0.11416218429803848, LR: 4.981113306712359e-05\n",
      "E: 16, S: 57500, TA: 0.9870413541793823, TL: 0.1128401979804039, LR: 4.980860830983147e-05\n",
      "E: 16, S: 57600, TA: 0.9920079708099365, TL: 0.10656917840242386, LR: 4.980606536264531e-05\n",
      "E: 16, S: 57700, TA: 0.9887856245040894, TL: 0.10397747904062271, LR: 4.980350422556512e-05\n",
      "E: 16, S: 57800, TA: 0.9910128116607666, TL: 0.10725463181734085, LR: 4.98009285365697e-05\n",
      "E: 16, S: 57900, TA: 0.9909167289733887, TL: 0.10910432040691376, LR: 4.979833465768024e-05\n",
      "E: 16, S: 58000, TA: 0.9912139177322388, TL: 0.10389982908964157, LR: 4.979572258889675e-05\n",
      "E: 16, S: 58100, TA: 0.9846827387809753, TL: 0.10608454793691635, LR: 4.979309596819803e-05\n",
      "E: 16, S: 58200, TA: 0.979857325553894, TL: 0.11102543026208878, LR: 4.979045479558408e-05\n",
      "E: 16, S: 58300, TA: 0.98717200756073, TL: 0.10551043599843979, LR: 4.978779179509729e-05\n",
      "E: 16, S: 58400, TA: 0.9895016551017761, TL: 0.10916934907436371, LR: 4.978511788067408e-05\n",
      "E: 16, S: 58500, TA: 0.9874661564826965, TL: 0.10752183198928833, LR: 4.9782422138378024e-05\n",
      "E: 16, S: 58600, TA: 0.9856885075569153, TL: 0.11030253767967224, LR: 4.977971184416674e-05\n",
      "E: 16, S: 58700, TA: 0.9854161143302917, TL: 0.115064337849617, LR: 4.977698699804023e-05\n",
      "E: 16, S: 58800, TA: 0.9898653626441956, TL: 0.10983215272426605, LR: 4.9774240324040875e-05\n",
      "E: 16, S: 58900, TA: 0.9907084703445435, TL: 0.10531149059534073, LR: 4.977147909812629e-05\n",
      "E: 16, S: 59000, TA: 0.985832691192627, TL: 0.1151055246591568, LR: 4.976870332029648e-05\n",
      "E: 16, S: 59100, TA: 0.9838964939117432, TL: 0.11720559000968933, LR: 4.9765909352572635e-05\n",
      "E: 16, S: 59200, TA: 0.9791882038116455, TL: 0.10662402957677841, LR: 4.976310083293356e-05\n",
      "E: 16, S: 59300, TA: 0.9808090329170227, TL: 0.11286511272192001, LR: 4.976027048542164e-05\n",
      "E: 16, S: 59400, TA: 0.9883228540420532, TL: 0.10539130121469498, LR: 4.9757429223973304e-05\n",
      "VALIDATION LOOP\n",
      "E: 16, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.12394366413354874, VL: 0.6659113764762878\n",
      "EPOCH: 17\n",
      "E: 17, S: 59500, TA: 0.9861339926719666, TL: 0.11170975863933563, LR: 4.975456613465212e-05\n",
      "E: 17, S: 59600, TA: 0.9895638227462769, TL: 0.1141049936413765, LR: 4.975168849341571e-05\n",
      "E: 17, S: 59700, TA: 0.9905965328216553, TL: 0.10401225090026855, LR: 4.9748796300264075e-05\n",
      "E: 17, S: 59800, TA: 0.9862416386604309, TL: 0.11255767196416855, LR: 4.97458859172184e-05\n",
      "E: 17, S: 59900, TA: 0.9896697402000427, TL: 0.10489578545093536, LR: 4.974295734427869e-05\n",
      "E: 17, S: 60000, TA: 0.9872827529907227, TL: 0.10813451558351517, LR: 4.9740014219423756e-05\n",
      "E: 17, S: 60100, TA: 0.9896085262298584, TL: 0.10697152465581894, LR: 4.973705290467478e-05\n",
      "E: 17, S: 60200, TA: 0.9897190928459167, TL: 0.10558649152517319, LR: 4.9734073400031775e-05\n",
      "E: 17, S: 60300, TA: 0.9870407581329346, TL: 0.10808021575212479, LR: 4.973107934347354e-05\n",
      "E: 17, S: 60400, TA: 0.988669753074646, TL: 0.10916317999362946, LR: 4.9728070735000074e-05\n",
      "E: 17, S: 60500, TA: 0.988103449344635, TL: 0.1105741485953331, LR: 4.9725043936632574e-05\n",
      "E: 17, S: 60600, TA: 0.9882681369781494, TL: 0.11000923812389374, LR: 4.972199894837104e-05\n",
      "E: 17, S: 60700, TA: 0.9878415465354919, TL: 0.11234933882951736, LR: 4.9718939408194274e-05\n",
      "E: 17, S: 60800, TA: 0.9898208379745483, TL: 0.11265189945697784, LR: 4.9715861678123474e-05\n",
      "E: 17, S: 60900, TA: 0.9870750308036804, TL: 0.10978113114833832, LR: 4.971276575815864e-05\n",
      "E: 17, S: 61000, TA: 0.9802560210227966, TL: 0.114387646317482, LR: 4.9709655286278576e-05\n",
      "E: 17, S: 61100, TA: 0.9878410696983337, TL: 0.10852480679750443, LR: 4.970652662450448e-05\n",
      "E: 17, S: 61200, TA: 0.9920970797538757, TL: 0.10778024792671204, LR: 4.970338341081515e-05\n",
      "E: 17, S: 61300, TA: 0.9911068677902222, TL: 0.1111816018819809, LR: 4.970022200723179e-05\n",
      "E: 17, S: 61400, TA: 0.9864939451217651, TL: 0.11131280660629272, LR: 4.9697046051733196e-05\n",
      "E: 17, S: 61500, TA: 0.9897096157073975, TL: 0.10825815796852112, LR: 4.969385190634057e-05\n",
      "E: 17, S: 61600, TA: 0.9862721562385559, TL: 0.11509516835212708, LR: 4.969063957105391e-05\n",
      "E: 17, S: 61700, TA: 0.9902337789535522, TL: 0.1031058207154274, LR: 4.968741268385202e-05\n",
      "E: 17, S: 61800, TA: 0.9841269850730896, TL: 0.12016167491674423, LR: 4.96841712447349e-05\n",
      "E: 17, S: 61900, TA: 0.9874051809310913, TL: 0.1068836972117424, LR: 4.968090797774494e-05\n",
      "E: 17, S: 62000, TA: 0.9872584342956543, TL: 0.10757751762866974, LR: 4.967763015883975e-05\n",
      "E: 17, S: 62100, TA: 0.9877180457115173, TL: 0.10992011427879333, LR: 4.967433778801933e-05\n",
      "E: 17, S: 62200, TA: 0.9893189072608948, TL: 0.11010894179344177, LR: 4.9671027227304876e-05\n",
      "E: 17, S: 62300, TA: 0.9901031851768494, TL: 0.10812173783779144, LR: 4.966769847669639e-05\n",
      "E: 17, S: 62400, TA: 0.9872334003448486, TL: 0.10250557959079742, LR: 4.966435517417267e-05\n",
      "E: 17, S: 62500, TA: 0.9826955795288086, TL: 0.11000104248523712, LR: 4.9660997319733724e-05\n",
      "E: 17, S: 62600, TA: 0.9883585572242737, TL: 0.10524173080921173, LR: 4.9657617637421936e-05\n",
      "E: 17, S: 62700, TA: 0.9860098958015442, TL: 0.10535798221826553, LR: 4.9654227041173726e-05\n",
      "E: 17, S: 62800, TA: 0.9857609272003174, TL: 0.10400170087814331, LR: 4.9650814617052674e-05\n",
      "E: 17, S: 62900, TA: 0.987007737159729, TL: 0.11346245557069778, LR: 4.9647387641016394e-05\n",
      "VALIDATION LOOP\n",
      "E: 17, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.19295774400234222, VL: 0.6608371734619141\n",
      "EPOCH: 18\n",
      "E: 18, S: 63000, TA: 0.985636830329895, TL: 0.10495998710393906, LR: 4.9643946113064885e-05\n",
      "E: 18, S: 63100, TA: 0.983619749546051, TL: 0.11543416976928711, LR: 4.9640482757240534e-05\n",
      "E: 18, S: 63200, TA: 0.9866382479667664, TL: 0.10850696265697479, LR: 4.963700848747976e-05\n",
      "E: 18, S: 63300, TA: 0.9883823394775391, TL: 0.10433728992938995, LR: 4.963351602782495e-05\n",
      "E: 18, S: 63400, TA: 0.9915990829467773, TL: 0.10534854978322983, LR: 4.963000537827611e-05\n",
      "E: 18, S: 63500, TA: 0.9835619926452637, TL: 0.11406555026769638, LR: 4.962647653883323e-05\n",
      "E: 18, S: 63600, TA: 0.9869487285614014, TL: 0.1113111600279808, LR: 4.9622933147475123e-05\n",
      "E: 18, S: 63700, TA: 0.985505223274231, TL: 0.11133407801389694, LR: 4.961937520420179e-05\n",
      "E: 18, S: 63800, TA: 0.9877602458000183, TL: 0.10901600867509842, LR: 4.9615799071034417e-05\n",
      "E: 18, S: 63900, TA: 0.9865133166313171, TL: 0.10844369977712631, LR: 4.961220474797301e-05\n",
      "E: 18, S: 64000, TA: 0.9828464388847351, TL: 0.1157161220908165, LR: 4.9608595872996375e-05\n",
      "E: 18, S: 64100, TA: 0.9919837117195129, TL: 0.11238448321819305, LR: 4.9604968808125705e-05\n",
      "E: 18, S: 64200, TA: 0.985702395439148, TL: 0.11144120246171951, LR: 4.9601327191339806e-05\n",
      "E: 18, S: 64300, TA: 0.990439236164093, TL: 0.11020991951227188, LR: 4.959766738465987e-05\n",
      "E: 18, S: 64400, TA: 0.988425612449646, TL: 0.1096791923046112, LR: 4.959399302606471e-05\n",
      "E: 18, S: 64500, TA: 0.9893017411231995, TL: 0.10579898208379745, LR: 4.959030047757551e-05\n",
      "E: 18, S: 64600, TA: 0.9863925576210022, TL: 0.10376361757516861, LR: 4.958658973919228e-05\n",
      "E: 18, S: 64700, TA: 0.9844392538070679, TL: 0.10483033955097198, LR: 4.9582864448893815e-05\n",
      "E: 18, S: 64800, TA: 0.9904817938804626, TL: 0.10441810637712479, LR: 4.9579124606680125e-05\n",
      "E: 18, S: 64900, TA: 0.9845658540725708, TL: 0.11472602188587189, LR: 4.957536293659359e-05\n",
      "E: 18, S: 65000, TA: 0.9902737140655518, TL: 0.1095750704407692, LR: 4.957159035257064e-05\n",
      "E: 18, S: 65100, TA: 0.9878621697425842, TL: 0.11762435734272003, LR: 4.956779594067484e-05\n",
      "E: 18, S: 65200, TA: 0.9904046654701233, TL: 0.10963725298643112, LR: 4.9563990614842623e-05\n",
      "E: 18, S: 65300, TA: 0.9870421886444092, TL: 0.11538808047771454, LR: 4.956016346113756e-05\n",
      "E: 18, S: 65400, TA: 0.9870445132255554, TL: 0.11349067091941833, LR: 4.9556321755517274e-05\n",
      "E: 18, S: 65500, TA: 0.9903995394706726, TL: 0.1077442467212677, LR: 4.955246549798176e-05\n",
      "E: 18, S: 65600, TA: 0.9894645810127258, TL: 0.10576221346855164, LR: 4.9548591050552204e-05\n",
      "E: 18, S: 65700, TA: 0.9883381724357605, TL: 0.11018555611371994, LR: 4.9544698413228616e-05\n",
      "E: 18, S: 65800, TA: 0.9854429364204407, TL: 0.1106877326965332, LR: 4.95407912239898e-05\n",
      "E: 18, S: 65900, TA: 0.9891743659973145, TL: 0.10591073334217072, LR: 4.953686584485695e-05\n",
      "E: 18, S: 66000, TA: 0.9910714030265808, TL: 0.10597378015518188, LR: 4.953292591380887e-05\n",
      "E: 18, S: 66100, TA: 0.9875034093856812, TL: 0.11243191361427307, LR: 4.952896779286675e-05\n",
      "E: 18, S: 66200, TA: 0.9923250675201416, TL: 0.10081169009208679, LR: 4.952499512000941e-05\n",
      "E: 18, S: 66300, TA: 0.9918132424354553, TL: 0.10027838498353958, LR: 4.952100425725803e-05\n",
      "E: 18, S: 66400, TA: 0.9892812967300415, TL: 0.11132819205522537, LR: 4.951699884259142e-05\n",
      "VALIDATION LOOP\n",
      "E: 18, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.1281690150499344, VL: 0.7081847190856934\n",
      "EPOCH: 19\n",
      "E: 19, S: 66500, TA: 0.9891795516014099, TL: 0.11131293326616287, LR: 4.9512975238030776e-05\n",
      "E: 19, S: 66600, TA: 0.9837657809257507, TL: 0.10774315148591995, LR: 4.95089334435761e-05\n",
      "E: 19, S: 66700, TA: 0.9752770662307739, TL: 0.11121435463428497, LR: 4.950487709720619e-05\n",
      "E: 19, S: 66800, TA: 0.988993227481842, TL: 0.10485413670539856, LR: 4.9500806198921055e-05\n",
      "E: 19, S: 66900, TA: 0.9855923056602478, TL: 0.11541278660297394, LR: 4.9496713472763076e-05\n",
      "E: 19, S: 67000, TA: 0.9855875968933105, TL: 0.11192956566810608, LR: 4.949260983266868e-05\n",
      "E: 19, S: 67100, TA: 0.9878484606742859, TL: 0.10754676163196564, LR: 4.948848800268024e-05\n",
      "E: 19, S: 67200, TA: 0.9866102933883667, TL: 0.10895580053329468, LR: 4.948434798279777e-05\n",
      "E: 19, S: 67300, TA: 0.9859253764152527, TL: 0.10914253443479538, LR: 4.948019341100007e-05\n",
      "E: 19, S: 67400, TA: 0.990674614906311, TL: 0.10468168556690216, LR: 4.947602064930834e-05\n",
      "E: 19, S: 67500, TA: 0.9881884455680847, TL: 0.11506404727697372, LR: 4.947182969772257e-05\n",
      "E: 19, S: 67600, TA: 0.9925697445869446, TL: 0.10847974568605423, LR: 4.946762783220038e-05\n",
      "E: 19, S: 67700, TA: 0.9903671741485596, TL: 0.10935302078723907, LR: 4.9463404138805345e-05\n",
      "E: 19, S: 67800, TA: 0.9904641509056091, TL: 0.10871797800064087, LR: 4.945916589349508e-05\n",
      "E: 19, S: 67900, TA: 0.9868773221969604, TL: 0.11419306695461273, LR: 4.945491309626959e-05\n",
      "E: 19, S: 68000, TA: 0.9861167669296265, TL: 0.11219994723796844, LR: 4.945064210915007e-05\n",
      "E: 19, S: 68100, TA: 0.9892116189002991, TL: 0.1103103756904602, LR: 4.9446352932136506e-05\n",
      "E: 19, S: 68200, TA: 0.9901525378227234, TL: 0.10984340310096741, LR: 4.9442049203207716e-05\n",
      "E: 19, S: 68300, TA: 0.9915942549705505, TL: 0.10841158777475357, LR: 4.943772728438489e-05\n",
      "E: 19, S: 68400, TA: 0.9910702109336853, TL: 0.11266377568244934, LR: 4.943339081364684e-05\n",
      "E: 19, S: 68500, TA: 0.9881318807601929, TL: 0.1047838032245636, LR: 4.9429039790993556e-05\n",
      "E: 19, S: 68600, TA: 0.9874839782714844, TL: 0.10813634097576141, LR: 4.942467057844624e-05\n",
      "E: 19, S: 68700, TA: 0.9897662997245789, TL: 0.0999075397849083, LR: 4.942028317600489e-05\n",
      "E: 19, S: 68800, TA: 0.9880393147468567, TL: 0.1075223833322525, LR: 4.9415881221648306e-05\n",
      "E: 19, S: 68900, TA: 0.9895056486129761, TL: 0.11019526422023773, LR: 4.941146107739769e-05\n",
      "E: 19, S: 69000, TA: 0.9912292957305908, TL: 0.11131316423416138, LR: 4.9407026381231844e-05\n",
      "E: 19, S: 69100, TA: 0.9919354915618896, TL: 0.11131191998720169, LR: 4.9402573495171964e-05\n",
      "E: 19, S: 69200, TA: 0.9873471856117249, TL: 0.10765567421913147, LR: 4.939810241921805e-05\n",
      "E: 19, S: 69300, TA: 0.9897856712341309, TL: 0.1060846596956253, LR: 4.939362042932771e-05\n",
      "E: 19, S: 69400, TA: 0.9901580810546875, TL: 0.10225525498390198, LR: 4.938911661156453e-05\n",
      "E: 19, S: 69500, TA: 0.9784590005874634, TL: 0.11254739761352539, LR: 4.9384598241886124e-05\n",
      "E: 19, S: 69600, TA: 0.9867109656333923, TL: 0.11584992706775665, LR: 4.938006532029249e-05\n",
      "E: 19, S: 69700, TA: 0.9906207919120789, TL: 0.10268013179302216, LR: 4.9375514208804816e-05\n",
      "E: 19, S: 69800, TA: 0.9870165586471558, TL: 0.11069203168153763, LR: 4.9370948545401916e-05\n",
      "E: 19, S: 69900, TA: 0.984046220779419, TL: 0.1124144047498703, LR: 4.936636469210498e-05\n",
      "VALIDATION LOOP\n",
      "E: 19, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.12112676352262497, VL: 0.6956974267959595\n",
      "EPOCH: 20\n",
      "E: 20, S: 70000, TA: 0.9867315292358398, TL: 0.1040932834148407, LR: 4.936176264891401e-05\n",
      "E: 20, S: 70100, TA: 0.9919044971466064, TL: 0.11117101460695267, LR: 4.935714605380781e-05\n",
      "E: 20, S: 70200, TA: 0.9930687546730042, TL: 0.1117565855383873, LR: 4.935251490678638e-05\n",
      "E: 20, S: 70300, TA: 0.9878258109092712, TL: 0.10699708014726639, LR: 4.934786556987092e-05\n",
      "E: 20, S: 70400, TA: 0.9796600937843323, TL: 0.11324930191040039, LR: 4.934319804306142e-05\n",
      "E: 20, S: 70500, TA: 0.9893559217453003, TL: 0.11229507625102997, LR: 4.933851596433669e-05\n",
      "E: 20, S: 70600, TA: 0.9839422106742859, TL: 0.11614369601011276, LR: 4.933381933369674e-05\n",
      "E: 20, S: 70700, TA: 0.9890156388282776, TL: 0.1094340980052948, LR: 4.932910451316275e-05\n",
      "E: 20, S: 70800, TA: 0.9865055084228516, TL: 0.10876387357711792, LR: 4.932437150273472e-05\n",
      "E: 20, S: 70900, TA: 0.9915966391563416, TL: 0.10897821187973022, LR: 4.9319623940391466e-05\n",
      "E: 20, S: 71000, TA: 0.9881656765937805, TL: 0.10345129668712616, LR: 4.931486182613298e-05\n",
      "E: 20, S: 71100, TA: 0.9887839555740356, TL: 0.1037331074476242, LR: 4.931007788400166e-05\n",
      "E: 20, S: 71200, TA: 0.9876897931098938, TL: 0.11147020012140274, LR: 4.930528302793391e-05\n",
      "E: 20, S: 71300, TA: 0.985886812210083, TL: 0.11329028010368347, LR: 4.930046998197213e-05\n",
      "E: 20, S: 71400, TA: 0.9863072037696838, TL: 0.10771921277046204, LR: 4.929563874611631e-05\n",
      "E: 20, S: 71500, TA: 0.9903181195259094, TL: 0.11003169417381287, LR: 4.9290792958345264e-05\n",
      "E: 20, S: 71600, TA: 0.990234911441803, TL: 0.107974573969841, LR: 4.928593261865899e-05\n",
      "E: 20, S: 71700, TA: 0.9889495372772217, TL: 0.1118849366903305, LR: 4.928105045109987e-05\n",
      "E: 20, S: 71800, TA: 0.9903028607368469, TL: 0.1022624745965004, LR: 4.9276157369604334e-05\n",
      "E: 20, S: 71900, TA: 0.987261176109314, TL: 0.10648909211158752, LR: 4.927124609821476e-05\n",
      "E: 20, S: 72000, TA: 0.9834432601928711, TL: 0.11016947031021118, LR: 4.926631663693115e-05\n",
      "E: 20, S: 72100, TA: 0.9875706434249878, TL: 0.10845626890659332, LR: 4.9261372623732314e-05\n",
      "E: 20, S: 72200, TA: 0.9897327423095703, TL: 0.10860457271337509, LR: 4.925641405861825e-05\n",
      "E: 20, S: 72300, TA: 0.9901333451271057, TL: 0.11442587524652481, LR: 4.9251437303610146e-05\n",
      "E: 20, S: 72400, TA: 0.9923288226127625, TL: 0.105021171271801, LR: 4.924644235870801e-05\n",
      "E: 20, S: 72500, TA: 0.9896979928016663, TL: 0.10824984312057495, LR: 4.9241432861890644e-05\n",
      "E: 20, S: 72600, TA: 0.98900306224823, TL: 0.1057467833161354, LR: 4.923640517517924e-05\n",
      "E: 20, S: 72700, TA: 0.9868708848953247, TL: 0.11188790947198868, LR: 4.9231362936552614e-05\n",
      "E: 20, S: 72800, TA: 0.9885528683662415, TL: 0.1080768033862114, LR: 4.9226306146010756e-05\n",
      "E: 20, S: 72900, TA: 0.987634539604187, TL: 0.10514038056135178, LR: 4.9221231165574864e-05\n",
      "E: 20, S: 73000, TA: 0.9891660809516907, TL: 0.10737176984548569, LR: 4.9216137995244935e-05\n",
      "E: 20, S: 73100, TA: 0.9873972535133362, TL: 0.11204845458269119, LR: 4.921103027299978e-05\n",
      "E: 20, S: 73200, TA: 0.987874448299408, TL: 0.10738567262887955, LR: 4.920590799883939e-05\n",
      "E: 20, S: 73300, TA: 0.9817528128623962, TL: 0.11767642945051193, LR: 4.920076753478497e-05\n",
      "E: 20, S: 73400, TA: 0.9874299764633179, TL: 0.11249006539583206, LR: 4.9195612518815324e-05\n",
      "VALIDATION LOOP\n",
      "E: 20, BA: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.35211268>, BL: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.48397192>, VA: 0.17323943972587585, VL: 0.6706178784370422\n"
     ]
    }
   ],
   "source": [
    "FOLD_IDX = 0\n",
    "stat_logger = StatLogger()\n",
    "for epoch in range(TrainingConfig.NUM_EPOCHS // N_LOOPS_EVERY_VAL):\n",
    "  print(f'EPOCH: {epoch}')\n",
    "  train_ds, val_ds = load_tf_dataset(FOLD_IDX)\n",
    "  train_dist_ds = iter(strategy.experimental_distribute_dataset(train_ds))\n",
    "  val_dist_ds = iter(strategy.experimental_distribute_dataset(val_ds))\n",
    "  for _ in range(N_LOOPS_EVERY_VAL):\n",
    "    for i in range(TrainingConfig.STEPS // TrainingConfig.STEPS_PER):\n",
    "      tf.config.set_soft_device_placement(True)\n",
    "      dist_train_step(train_dist_ds, TrainingConfig.STEPS_PER)\n",
    "      for j in range(TrainingConfig.STEPS_PER):\n",
    "        scheduler.step()\n",
    "      stat_logger.update_train()\n",
    "  print(\"VALIDATION LOOP\")\n",
    "  for (input_ids, attention_mask, token_type_ids), labels in val_dist_ds:\n",
    "    ground_truth, prediction = dist_val_step(input_ids, attention_mask, token_type_ids, labels)\n",
    "    #metrics['val_f1'].update_state(ground_truth, prediction)\n",
    "  stat_logger.update_val()\n",
    "  if epoch == NUM_EPOCHS:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-captain",
   "metadata": {
    "id": "zEAUodiXFqPq",
    "papermill": {
     "duration": 0.196405,
     "end_time": "2021-06-22T21:29:49.763820",
     "exception": false,
     "start_time": "2021-06-22T21:29:49.567415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Distributed Variables inside of ValF1\n",
    "- Also, ValF1 States aren't updating\n",
    "- Debug on Max size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-parallel",
   "metadata": {
    "papermill": {
     "duration": 0.198244,
     "end_time": "2021-06-22T21:29:50.157568",
     "exception": false,
     "start_time": "2021-06-22T21:29:49.959324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Im SO DUMB. I didn't split a val set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-forward",
   "metadata": {
    "id": "9QCrG3Aj8STC",
    "papermill": {
     "duration": 0.195034,
     "end_time": "2021-06-22T21:29:50.549640",
     "exception": false,
     "start_time": "2021-06-22T21:29:50.354606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TODO;\n",
    "- Fix Attention Masks\n",
    "- Input Id type(from tokenizer)\n",
    "- Fix Validation Loop \n",
    "- ADD A CRF Layer.\n",
    "- SEND THE TFRECORDS to GCS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-gregory",
   "metadata": {
    "id": "zBrSq-i7KN8b",
    "papermill": {
     "duration": 0.206026,
     "end_time": "2021-06-22T21:29:50.953540",
     "exception": false,
     "start_time": "2021-06-22T21:29:50.747514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Runs on TPU now. Compile TIme seems to be pretty crazy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-semester",
   "metadata": {
    "id": "ZFQmmFrjJcvs",
    "papermill": {
     "duration": 0.195811,
     "end_time": "2021-06-22T21:29:51.346818",
     "exception": false,
     "start_time": "2021-06-22T21:29:51.151007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TODO: Tune the validation metrics and Training Hyper Params. I'm trying to just get it to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-henry",
   "metadata": {
    "id": "rW6V5DLQ5bem",
    "papermill": {
     "duration": 0.207727,
     "end_time": "2021-06-22T21:29:51.751606",
     "exception": false,
     "start_time": "2021-06-22T21:29:51.543879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I think Batch size was too large. I'm not sure.\n",
    "- Model isn't Converging: Reaches 2.27 Loss, much worse than baseline notebook: 2.1 Loss.\n",
    "- Estimated for actually good performance; 1.1 Loss or so.\n",
    "- Tesla V100 is the fastest GPU, then P100, the T4, then K80.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-stage",
   "metadata": {
    "id": "rcferySLjjd0",
    "papermill": {
     "duration": 0.199236,
     "end_time": "2021-06-22T21:29:52.150466",
     "exception": false,
     "start_time": "2021-06-22T21:29:51.951230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Cyclic LR isn't working as well\n",
    "- It seems a simple One-Cycle would be perfect for the task.\n",
    "- KEY NOTE: VAL Loss vs Training loss: Big Gap RN.\n",
    "- Lower and Lower LR needed\n",
    "- Restarting training helps a lot for some reason.\n",
    "- Base LR should be 0.0 or like 1e-13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-omaha",
   "metadata": {
    "id": "ABt9NzeyS3NY",
    "papermill": {
     "duration": 0.199748,
     "end_time": "2021-06-22T21:29:52.548707",
     "exception": false,
     "start_time": "2021-06-22T21:29:52.348959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Starts Overfitting by EPOCH 1.5 or around there.\n",
    "- Do one Overnight training today.\n",
    "- IDK why, but the Validation Score is super duper low.\n",
    "- Normal People have large Gaps(Ex. 0.8)\n",
    "- Seems like a bug. debug later.\n",
    "- It's the Learning Rate Scheduler: BERT is tough to tune\n",
    "- 2 EPOCH with 2e-5 is perfect, so probably freeze the backbone and train on smaller LR.\n",
    "- Current LR Scheduler: Just decay linearly down to 0.0\n",
    "- I think with a better LR schedule, it can work(One cycle with higher LR)\n",
    "- Sometimes, with weird testing, you can get down to 1.7 ~1.6 loss.\n",
    "- ROBERTA can further improve performance(ROBERTA base or large)\n",
    "- Freeze BEGINNING of ROBERTA-Large.\n",
    "- Dropout, weight decay\n",
    "- NLP Augmentations(avoiding Dataset names)\n",
    "- Training Baseline tonight\n",
    "- Seems to train pretty well so far using CyclicLR.\n",
    "- Overfitting RN.\n",
    "- Still Overfitting, but with more and more epochs, the gap decreases.\n",
    "- COnverged to 2.1 Train Loss\n",
    "- Val Loss keeps Converging.\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-yahoo",
   "metadata": {
    "id": "f2aai4jy72jA",
    "papermill": {
     "duration": 0.198281,
     "end_time": "2021-06-22T21:29:52.977403",
     "exception": false,
     "start_time": "2021-06-22T21:29:52.779122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-cisco",
   "metadata": {
    "id": "5q04grX5YfgK",
    "papermill": {
     "duration": 0.198489,
     "end_time": "2021-06-22T21:29:53.374447",
     "exception": false,
     "start_time": "2021-06-22T21:29:53.175958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TESTING:\n",
    "1) Baseline:\n",
    "- LR 2e-5, 2 EPOCHS - Able to Acheieve BaseLine Results - 0.17 LB\n",
    "- LR with Warm Restarts:Works well, but when it reaches the peak, it fails, so OneCycleLR should work.\n",
    "\n",
    "# Requirements:\n",
    "- MLM Model: 0.39 - 0.4 LB Explicit Remove Train Labels\n",
    "- NER Model: 0.4 LB\n",
    "- QA: 0.4LB\n",
    "- ENSEMBLE ALL: 0.45LB.\n",
    "- SOTA = ~0.5LB without string matching.\n",
    "\n",
    "# TO TEST:\n",
    "1) INFERENCE ON VALIDATION\n",
    "2) Add Text Augmentation: See if Validation is true or not.\n",
    "3) Start Using LB as Validation Please(we have enough submissions i guess)\n",
    "- BERT + Dropout - Doesn't Help at all: oof.(3.12)\n",
    "- BERT + Text Augmentation - Testing RN - Helps a lot to converge and bridge the gap between VL nd TL! - I think it's converging worse. Oof. - Failed Experiment(2.39)\n",
    "- Frozen BERT\n",
    "- Add Final Dropout Layer. - Doesn't Help. why does nothing work.(2.42)\n",
    "- Baseline(2.36) - Converges well with decent consistency. Problems is due to overfitting LB, since the public LB has train samples, which is really stupid.\n",
    "- Roberta\n",
    "- CRF Layer\n",
    "- FINE-TUNE the BERT model until 0.4 or 0.5 LB without string-matching.\n",
    "- NEED MINIMUM to 0.4 BEFORE MOVING TO ANOTHER MODEL\n",
    "- Other Models\n",
    "- MLM, QA, NER, SPACY models. \n",
    "- SPACY is a Machine Learning Based Classifier\n",
    "- BERT based Classifier\n",
    "- Pure Language Modelling Task(Seems to work well enough, if you check the LM output is actually in the text)\n",
    "- LM has very good performance compared to other.\n",
    "- Big Problem with overfitting to be honest.(Not sure how to prevent overfitting the new sentences)\n",
    "\n",
    "\n",
    "- Like BirdClef and BMS, folds are kinda useless, but you can add 5 FOLDS for each, for like 30 models total.\n",
    "- Test Hypothesis of randomly restarting training.\n",
    "- Heavy Bugs from restarting training.\n",
    "\n",
    "2) Testing:\n",
    "- It seems that everyone is heavily overfitting LM\n",
    "- Trying ROBERTA models right now, to see at least if better models get better results.\n",
    "\n",
    "3) Models:\n",
    "- SPACY: I suspect heavy LB overfitting\n",
    "- Attention based seems to work decently, at not overfitting\n",
    "- Longer Lengths should help.(500 token length?)\n",
    "- I think continue with Attention based model or test out MLM model\n",
    "- He didn't even use a pretrained BERT, so I think that this model can be heavily improved!\n",
    "- It also doesn't overfit as much even with train removed.\n",
    "- Swapping to Attention RN, can come back to MLM later(no time to fine tune a broken model)\n",
    "\n",
    "# ORDER:\n",
    "- Attention Model LM\n",
    "- NER\n",
    "- QA\n",
    "- SPACY \n",
    "- CLASSIFIER\n",
    "- MLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-crossing",
   "metadata": {
    "id": "e4jUtnIm4EJt",
    "papermill": {
     "duration": 0.198431,
     "end_time": "2021-06-22T21:29:53.768368",
     "exception": false,
     "start_time": "2021-06-22T21:29:53.569937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Current Model Uses up too much RAM\n",
    "- Can fix with TPU + HighRam\n",
    "- 15 GB RAM needed.\n",
    "- 6 Ex takes 11 Minutes\n",
    "- 10 Ex takes: 30 Minutes(MAX CAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-finnish",
   "metadata": {
    "id": "WfgdL2PIhkAy",
    "papermill": {
     "duration": 0.198014,
     "end_time": "2021-06-22T21:29:54.162842",
     "exception": false,
     "start_time": "2021-06-22T21:29:53.964828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4290.902352,
   "end_time": "2021-06-22T21:29:57.071978",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-22T20:18:26.169626",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01898f4ebc6e45138efc5da85886d31f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f51637c5d66e464397c104c58d416ca2",
       "placeholder": "​",
       "style": "IPY_MODEL_ef3eb29601de4757aa0728c8a2e1fb9a",
       "value": "&lt;tqdm.auto.tqdm object at 0x7ff59860f6d0&gt;"
      }
     },
     "0723bd534c474a8184486b449ac885d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a06c97b57504473b0cae748cbc9a494",
       "placeholder": "​",
       "style": "IPY_MODEL_86dc6858d2a04af4b3c625153a37c692",
       "value": "&lt;tqdm.auto.tqdm object at 0x7ff59856e390&gt;"
      }
     },
     "29c8f150a965457ba423f7d63ca423f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ece874b2b9e4d69989a182c448d2866": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39ab5efd3958442f8102e1343e67b5df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_536832028a504d66b3e663247a6d0df8",
       "max": 898823.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d0037651121747ffadc62dd81a63fd50",
       "value": 898823.0
      }
     },
     "3f1c7d9f34854fd9a9cd2ca5bc5ad6be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dc461f295ba647189ebeedc32cb21deb",
       "max": 481.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b0e302f977534f909e01aa4fa6b78e80",
       "value": 481.0
      }
     },
     "4a1780ca8a5c4dfab385a2a75fae5010": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c8e2df9f300462fb8621a3dc4dca65c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d9182fbbea5446692e8adcadf6f6597": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "513fb805b305422cb002d1601572554f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "536832028a504d66b3e663247a6d0df8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "593da84c922b4a5488dff8ba17aa5bde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c8e2df9f300462fb8621a3dc4dca65c",
       "placeholder": "​",
       "style": "IPY_MODEL_81a6668eb9cc4256a33b2d2a14ec5b84",
       "value": "&lt;tqdm.auto.tqdm object at 0x7ff59851f750&gt;"
      }
     },
     "5d23de6b460a4b1f8d80ee92f83f2c5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "81a6668eb9cc4256a33b2d2a14ec5b84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "86dc6858d2a04af4b3c625153a37c692": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88c068ab164f4d97b9242268e76cb47f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a06c97b57504473b0cae748cbc9a494": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b435e97b6bf41dea5c13f5c987d61b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_97ed3c64a93f47b790a7e39f6e11dd26",
        "IPY_MODEL_a8939c21841a4d7895d57b0daa77fbd1"
       ],
       "layout": "IPY_MODEL_9a2fdccb3a564749a550baf0bc9bf617"
      }
     },
     "8b9db41f30974a2d9554de4d233137e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fdf68f342ddd4226a3cdfe34a7fd61eb",
        "IPY_MODEL_0723bd534c474a8184486b449ac885d3"
       ],
       "layout": "IPY_MODEL_88c068ab164f4d97b9242268e76cb47f"
      }
     },
     "8fb337f9a89f423b8682909d4bac142a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "97ed3c64a93f47b790a7e39f6e11dd26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a206a121d9964d068643baaba793e734",
       "max": 657434796.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dae76556e5ed40a0951fdbb6cfe72b35",
       "value": 657434796.0
      }
     },
     "9a2fdccb3a564749a550baf0bc9bf617": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a206a121d9964d068643baaba793e734": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8939c21841a4d7895d57b0daa77fbd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4a1780ca8a5c4dfab385a2a75fae5010",
       "placeholder": "​",
       "style": "IPY_MODEL_fe066b1d8a854380a8df956c548de53e",
       "value": "&lt;tqdm.auto.tqdm object at 0x7ff5541bbed0&gt;"
      }
     },
     "b0c9e4bd9890478d82cea2151cb78631": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b0e302f977534f909e01aa4fa6b78e80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c0902e6b40804e34a62a9d0df462a6a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e3a598da1c64469f8a15f2dc05109574",
       "max": 1355863.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b0c9e4bd9890478d82cea2151cb78631",
       "value": 1355863.0
      }
     },
     "d0037651121747ffadc62dd81a63fd50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d286dd2ad0ab46b3b56581740a1eccbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c0902e6b40804e34a62a9d0df462a6a5",
        "IPY_MODEL_d6b9352db3db427c98bad6f4a25286d2"
       ],
       "layout": "IPY_MODEL_2ece874b2b9e4d69989a182c448d2866"
      }
     },
     "d6b9352db3db427c98bad6f4a25286d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ec4d419ce4ea47cc8f4233cf3b9d84a9",
       "placeholder": "​",
       "style": "IPY_MODEL_5d23de6b460a4b1f8d80ee92f83f2c5e",
       "value": "&lt;tqdm.auto.tqdm object at 0x7ff598576510&gt;"
      }
     },
     "d7809ec86a0e4f378f3ca8d7fe80e1d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3f1c7d9f34854fd9a9cd2ca5bc5ad6be",
        "IPY_MODEL_01898f4ebc6e45138efc5da85886d31f"
       ],
       "layout": "IPY_MODEL_513fb805b305422cb002d1601572554f"
      }
     },
     "dae76556e5ed40a0951fdbb6cfe72b35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "dc461f295ba647189ebeedc32cb21deb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3a598da1c64469f8a15f2dc05109574": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5442a536d544792a5c13fdfbbb4cf8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_39ab5efd3958442f8102e1343e67b5df",
        "IPY_MODEL_593da84c922b4a5488dff8ba17aa5bde"
       ],
       "layout": "IPY_MODEL_29c8f150a965457ba423f7d63ca423f0"
      }
     },
     "ec4d419ce4ea47cc8f4233cf3b9d84a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef3eb29601de4757aa0728c8a2e1fb9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f51637c5d66e464397c104c58d416ca2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdf68f342ddd4226a3cdfe34a7fd61eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4d9182fbbea5446692e8adcadf6f6597",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8fb337f9a89f423b8682909d4bac142a",
       "value": 456318.0
      }
     },
     "fe066b1d8a854380a8df956c548de53e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

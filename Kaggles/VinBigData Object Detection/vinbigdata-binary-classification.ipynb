{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"%%capture\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n!pip install ensemble-boxes\n!pip install livelossplot\n\nimport livelossplot\nimport copy\nimport random\nimport math\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport random\n\nimport tqdm.notebook as tqdm\n\nimport PIL\nimport os\nimport collections\n\nimport torchvision\nimport torchvision.transforms as transforms\n\n\nimport albumentations as al\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\n\nimport torch\nfrom torch.nn import functional as F\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport timm\n\nfrom sklearn.model_selection import train_test_split\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random\nseed = 42\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    numpy.random.seed(worker_seed)\n    random.seed(worker_seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data \n\nMultiStage Training Strategy:\n- \nTwo Problems inside of the Data:\n- Multiple No Findings(Solution: Train a 2 Part classifier, one training on classes or no classes, other on bbox, the ones with no findings are separated out from the rest of the dataset)\n- Multiple Radiographer Readings: We will use NMS to threshold out the bounding boxes so limited duplicates occur).\n\nNo problems:\n- If there is no finding, all radiographers all say no findings\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_2_class = {\n    0:'Aortic enlargement',\n    1:'Atelectasis',\n    2:'Calcification',\n    3:'Cardiomegaly',\n    4:'Consolidation',\n    5: 'ILD',\n    6: 'Infiltration',\n    7: 'Lung Opacity',\n    8: 'Nodule/Mass', \n    9: 'Other lesion',\n    10: 'Pleural effusion',\n    11: 'Pleural thickening',\n    12: 'Pneumothorax',\n    13: 'Pulmonary fibrosis',\n    14: 'No Finding'\n}\nclass_2_idx = {}\nfor idx in idx_2_class:\n    class_2_idx[idx_2_class[idx]] = idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HYPER PARAMETERS DEFINED HERE\nBATCH_SIZE = 8\nTEST_BATCH_SIZE = 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONSTANTS DEFINED HERE\nTRAIN_PATH = \"../input/vinbigdata-original-image-dataset/vinbigdata/train/\"\ntrain_csv = '../input/vinbigdata-original-image-dataset/vinbigdata/train.csv'\ntest_csv = '../input/vinbigdata-original-image-dataset/vinbigdata/test.csv'\ntrain_pd = pd.read_csv(train_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrainClassificationDataset(torch.utils.data.Dataset):\n    '''\n    This is the 2 way classification, where you classify whether a given image contains a finding or not \n    '''\n    \n    def __init__(self, dataframe, unique_ids, transforms, train_path):\n        self.dataframe = dataframe\n        self.transforms = transforms\n        self.train_path = train_path\n        \n        self.unique_ids = unique_ids\n    def cleanse_files(self, unique_ids):\n        '''\n        Cleanse all invalid files from the self.unique_ids\n        '''\n        valid_id = []\n        all_files = os.listdir(self.train_path)\n        for id in unique_ids:\n            if id + '.jpg' in all_files:\n                valid_id += [id]\n        return valid_id\n    def __len__(self):\n        return len(self.unique_ids)\n    def __getitem__(self, idx):\n        # Extract an image and whether it contains an abnormality or not.\n        image_id = self.unique_ids[idx]\n        image_path = TRAIN_PATH + image_id + '.jpg'\n        \n        # Load in Image\n        image = cv2.imread(image_path, 0)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # Check if classed or not(Only need to check the first one, as we perform binary classification)\n        rows = self.dataframe.loc[self.dataframe.image_id.values == image_id]\n        class_idx = 0\n        for row in rows.iterrows():\n            row = row[1]\n            if row['class_id'] != 14:\n                class_idx = 1\n            break\n            \n        # Augment Image\n        aug_image = self.transforms(image = image)['image']\n        return torch.tensor(aug_image), class_idx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Augmentations Used:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Augmentations to use for object detection:\nIMAGE_SIZE = 2048 # We will down convolution to get better performance\n\nTRAIN_AUGMENTATIONS_CLASS = al.Compose([\n    al.RandomResizedCrop(IMAGE_SIZE, IMAGE_SIZE, scale = (0.9, 0.9)),\n    al.HorizontalFlip(p=0.5),\n    al.RandomGamma(gamma_limit=(70, 130), p=0.3),\n    al.MultiplicativeNoise(),\n    al.ShiftScaleRotate(p=0.2, shift_limit=0.0025, scale_limit=0.01, rotate_limit=10),\n    al.RandomBrightnessContrast(p=0.2, brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1)),\n    al.HueSaturationValue(p=0.2, hue_shift_limit=0.1, sat_shift_limit=0.1, val_shift_limit=0.1),\n    al.Cutout(p = 0.2),\n    al.CoarseDropout(p=0.2),\n    al.IAASharpen(p=0.2),\n    al.Downscale(scale_min=0.7, scale_max=0.95),\n    al.CLAHE(),\n    al.Normalize(),\n    ToTensorV2()\n])\n\nTEST_AUGMENTATIONS_CLASS = al.Compose([\n    al.Resize(IMAGE_SIZE, IMAGE_SIZE),\n    al.Normalize(),\n    ToTensorV2()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique(list_of_values):\n    unique = []\n    for i in list_of_values:\n        if i not in unique:\n            unique += [i]\n    return unique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate Validation and Training Set\nunique_ids = unique(train_pd.image_id)\ntrain_ids, val_ids = train_test_split(unique_ids, train_size = 0.99, test_size = 0.01, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dataset\nTrainClassDataset = TrainClassificationDataset(train_pd, train_ids, TRAIN_AUGMENTATIONS_CLASS, TRAIN_PATH);\nValClassDataset = TrainClassificationDataset(train_pd, val_ids, TEST_AUGMENTATIONS_CLASS, TRAIN_PATH);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dataloaders\nTrainClassDataloader = torch.utils.data.DataLoader(TrainClassDataset, batch_size = BATCH_SIZE, shuffle = True, worker_init_fn = seed_worker)\nValClassDataloader = torch.utils.data.DataLoader(ValClassDataset, batch_size = TEST_BATCH_SIZE, worker_init_fn = seed_worker)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 1: Train an EfficientNetb0 for binary classification\nAdd Ons - Non Local Blocks, Squeeze Excite Blocks, pretty simple model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_features, out_features, kernel_size, padding, groups):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size, padding = padding, groups = groups)\n        self.SILU = nn.SiLU(inplace = True)\n        self.bn = nn.BatchNorm2d(out_features)\n    def forward(self, x):\n        return self.bn(self.SILU(self.conv(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvSqueezeExcite(nn.Module):\n    def __init__(self, in_features, inner_features):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.Squeeze = nn.Conv2d(self.in_features, self.inner_features, kernel_size = 1)\n        self.Excited = nn.Conv2d(self.inner_features, self.in_features, kernel_size = 1)\n        self.SILU = nn.SiLU(inplace = True)\n    def forward(self, x):\n        '''\n        x: Tensor(B, C, H, W)\n        '''\n        squeezed = self.SILU(self.Squeeze(x))\n        excited = torch.sigmoid(self.Excited(squeezed))\n        return excited * x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RegularSE(nn.Module):\n    '''\n    Normal Squeeze and Excitation Block \n    '''\n    def __init__(self, in_features, squeezed_features):\n        super().__init__()\n        self.in_features = in_features\n        self.squeezed_features = squeezed_features\n        self.Squeeze = nn.Linear(self.in_features, self.squeezed_features)\n        self.act1 = nn.SiLU(inplace = True)\n        self.Expand = nn.Linear(self.squeezed_features, self.in_features)\n    def forward(self, x):\n        '''\n        x: Tensor(B, C, H, W)\n        '''\n        # Max Pool over last 2 dims\n        max_pooled, _ = torch.max(x, dim = -1)\n        max_pooled, _ = torch.max(max_pooled, dim = -1) # (B, C)\n        # Squeeze and Excitation Network\n        squeezed = self.act1(self.Squeeze(max_pooled))\n        excited = torch.sigmoid(self.Expand(squeezed)).unsqueeze(-1).unsqueeze(-1)\n        return excited * x\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DownSampleConvBlock(nn.Module):\n    def __init__(self, in_features, out_features, kernel_size, padding, stride, groups):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size, padding = padding, stride = stride, groups = groups)\n        self.SiLU = nn.SiLU(inplace = True)\n        self.bn = nn.BatchNorm2d(out_features)\n    def forward(self, x):\n        return self.bn(self.SiLU(self.conv(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BottleNeck(nn.Module):\n    '''\n    Squeeze Excite Residual Block as Proposed in ResNet.\n    '''\n    def __init__(self, input_size, inner_size, device):\n        super().__init__()\n        self.device = device\n        self.input_size = input_size\n        self.inner_size = inner_size\n        self.Squeeze = ConvBlock(self.input_size, self.inner_size, 1, 0, 1)\n        self.Process = ConvBlock(self.inner_size, self.inner_size, 3, 1, 1)\n        self.Expand = ConvBlock(self.inner_size, self.input_size, 1, 0, 1)\n        self.SE = RegularSE(self.input_size, self.input_size // 16)\n        self.gamma = nn.Parameter(torch.zeros(1, device = self.device))\n    def forward(self, x):\n        squeezed = self.Squeeze(x)\n        processed = self.Process(squeezed)\n        expand = self.Expand(processed)\n        excited = self.SE(expand)\n        return self.gamma * excited + x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DownConvolutionBlock(nn.Module):\n    '''\n    Uses very cheap operations to process and downconvolve the massive image\n    '''\n    def __init__(self, device):\n        super().__init__()\n        self.device = device\n        self.in_features = 3\n        self.avgPool = nn.AvgPool2d(kernel_size = 5, padding = 2, stride = 2)\n        self.downConv = DownSampleConvBlock(3, 5, 3, 1, 2, 1) # (2048 -> 1024)\n        \n        self.downConv2 = DownSampleConvBlock(8, 16, 3, 1, 2, 1) # (1024 -> 512)\n        \n        self.downConv3 = DownSampleConvBlock(24, 64, 3, 1, 2, 1) # (512 -> 256)\n        self.process3 = nn.Sequential(*[\n            BottleNeck(64, 16, self.device) for i in range(3) # A little bit of processing\n        ])\n        \n        self.proj = nn.Sequential(*[\n            ConvBlock(64, 32, 1, 0, 1),\n            ConvBlock(32, 3, 1, 0, 1)])\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.device))\n        \n    def forward(self, x):\n        '''\n        Initial DownConvolution\n        x: Tensor(B, 3, 2048, 2048)\n        '''\n        B, _, _, _ = x.shape\n        interpolated = F.interpolate(x, (256, 256), mode = 'bilinear')\n        avgPool = self.avgPool(x) # (B, 3, 1024, 1024)\n        downConv = self.downConv(x) # (B, 5, 1024, 1024)\n        # Concatenate Features\n        concatted = torch.cat([downConv, avgPool], dim = 1) # (B, 8, 1024, 1024)\n        # DownConv again \n        avgPool2 = self.avgPool(concatted) # (B, 8, 512, 512)\n        downConv2 = self.downConv2(concatted) # (B, 32, 512, 512)\n        concatted2 = torch.cat([downConv2, avgPool2], dim = 1) # (B, 40, 512, 512)\n        # Conv Stride a Few times\n        conv3 = self.process3(self.downConv3(concatted2)) # (B, 64, 256, 256)  \n        proj = self.proj(conv3) # (B, 64, 128, 128)\n        return proj * self.gamma + interpolated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class InvertedResidualBlock(nn.Module):\n    def __init__(self, in_features, inner_features, device):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.device = device\n        self.expand = ConvBlock(self.in_features, self.inner_features, 1, 0, 1)\n        self.depthwise = ConvBlock(self.inner_features, self.inner_features, 3, 1, self.inner_features)\n        self.SE = RegularSE(self.inner_features, self.inner_features // 16)\n        self.squeeze = ConvBlock(self.inner_features, self.in_features, 1, 0, 1)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.device))\n    def forward(self, x):\n        expanded = self.expand(x)\n        depthwise = self.depthwise(expanded)\n        se = self.SE(depthwise)\n        squeezed = self.squeeze(se)\n        return self.gamma * squeezed + x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Blocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ModifiedEfficientNetStudent(nn.Module):\n    '''\n    Student uses Down Convolutional Block to quickly downsample super large images.\n    '''\n    def freeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = False\n    def unfreeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = True\n    def __init__(self, num_classes, device, model_name = 'efficientnet_b8', drop_prob = 0.0):\n        super().__init__()\n        self.num_classes = num_classes \n        self.device = device\n        self.model_name = model_name\n        self.drop_prob = drop_prob\n        self.model = timm.create_model(self.model_name, pretrained = True)\n        \n        # Extract Layers\n        self.downsampled = DownConvolutionBlock(self.device)\n        self.conv1 = self.model.conv_stem\n        self.bn1 = self.model.bn1\n        self.act1 = self.model.act1\n        \n        self.block0 = self.model.blocks[0]\n        self.block1 = self.model.blocks[1]\n        self.block2 = self.model.blocks[2]\n        self.block3 = self.model.blocks[3]\n        self.block4 = self.model.blocks[4]\n        self.block5 = self.model.blocks[5]\n        self.block6 = self.model.blocks[6]\n        \n        # Custom Layers\n        self.Attention1 = RegularSE(56, 16)\n        self.Attention2 = RegularSE(88, 32)\n        self.Attention3 = RegularSE(248, 64)\n        self.Attention4 = RegularSE(704, 256)\n        \n        self.layer4 = nn.Sequential(*[\n            DownSampleConvBlock(704, 704, 5, 2, 2, 704), # (B, 320, 4, 4)\n            ConvBlock(704, 768, 1, 0, 1)] + # (B, 768, 4, 4)\n        [\n            InvertedResidualBlock(768, 1536, self.device) for i in range(5)\n         \n        ]\n        )\n        self.conv2 = ConvBlock(768, 1536, 1, 0, 1)\n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(self.drop_prob)\n        self.Linear = nn.Linear(1536, self.num_classes)\n    def forward(self, x):\n        '''\n        x: Tensor(B, 3, 320, 320)\n        '''\n        downsampled = self.downsampled(x) # (B, 3, 256, 256)\n        conv1 = self.bn1(self.act1(self.conv1(downsampled))) # (B, 32, 256, 256)\n        # Extract Features\n        block0 = self.block0(conv1)\n        block1 = self.block1(block0) # (B, 24, 64, 64) \n        attention1 = self.Attention1(block1)\n        \n        block2 = self.block2(attention1) # (B, 40, 32, 32)\n        attention2 = self.Attention2(block2)\n        \n        block3 = self.block3(attention2)\n        block4 = self.block4(block3) # (B, 112, 16, 16)\n        attention3= self.Attention3(block4)\n        \n        block5 = self.block5(attention3)\n        block6 = self.block6(block5) # (B, 320, 8, 8)\n        attention4 = self.Attention4(block6)\n        # Custom Layer 4\n        layer4 = self.layer4(attention4) # (B, 512, 4, 4)\n        # Classification Head.\n        conv2 = self.conv2(layer4) # (B, 1536, 4, 4)\n        avg_pool = torch.squeeze(self.global_avg(conv2))\n        dropped_pool = self.dropout(avg_pool)\n        return torch.squeeze(self.Linear(dropped_pool))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train Alpha."},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationAlpha(nn.Module):\n    def __init__(self, num_classes, device):\n        super().__init__()\n        self.num_classes = num_classes\n        self.device = device\n        \n        self.model = ModifiedEfficientNetStudent(self.num_classes, self.device, drop_prob = 0.0)\n        \n        self.optim = optim.Adam(self.model.parameters(), lr = 3e-4, weight_decay = 1e-3)\n        self.lr_decay = optim.lr_scheduler.CosineAnnealingLR(self.optim, 5, eta_min = 1e-7)\n        self.lr_decay2 = optim.lr_scheduler.StepLR(self.optim, 5, 0.9)\n        self.criterion = nn.BCEWithLogitsLoss()\n    def forward(self, x):\n        self.eval()\n        with torch.no_grad():\n            return self.model(x)\n    def training_loop(self, train_dataloader, val_dataloader, NUM_EPOCHS, display_every = 16):\n        liveloss = livelossplot.PlotLosses()\n        torch.cuda.empty_cache()\n        \n        best_val_loss = 999\n        best_val_accuracy = 0\n        for EPOCH in range(NUM_EPOCHS):\n            self.train()\n            logs = {}\n            count = 0\n            total_loss = 0.0\n            for images, labels in train_dataloader:\n                self.optim.zero_grad()\n                images = images.to(torch.float32).to(self.device)\n                labels = labels.to(self.device).to(torch.float32)\n                logits = self.model(images)\n                loss = self.criterion(logits, labels)\n                loss.backward()\n                self.optim.step()\n                total_loss += loss.item()\n                count += 1\n                del images\n                del labels\n                del logits\n                torch.cuda.empty_cache()\n                if count == display_every:\n                    break\n            logs['loss'] = total_loss / display_every\n            print(f\"EPOCH: {EPOCH}, total_loss: {logs['loss']}\")\n            \n            self.eval()\n            self.lr_decay.step()\n            self.lr_decay2.step()\n            with torch.no_grad():\n                logs['val_loss'] = 0\n                logs['accuracy'] = 0\n                count = 0\n                for images, labels in val_dataloader:\n                    images = images.to(torch.float32).to(self.device)\n                    labels = labels.to(self.device).to(torch.float32)\n                    pred = self.model(images)\n                    logs['val_loss'] += self.criterion(pred, labels).item()\n                    sigmoided = torch.sigmoid(pred)\n                    ones = sigmoided >= 0.5\n                    sigmoided[:] = 0\n                    sigmoided[ones] = 1\n                    logs['accuracy'] += torch.sum((sigmoided == labels).int()).item() / sigmoided.shape[0]\n                    count += 1\n                    del images\n                    del labels\n                    del pred\n                    del sigmoided\n                    torch.cuda.empty_cache();\n                logs['val_loss'] /= count\n                logs['accuracy'] /= count\n            \n            liveloss.update(logs)\n            liveloss.send()\n            if logs['val_loss'] < best_val_loss:\n                torch.save(self.state_dict(), \"./BestLoss.pth\");\n                best_val_loss = logs['val_loss']\n            if logs['accuracy'] > best_val_accuracy:\n                torch.save(self.state_dict(), \"./BestAcc.pth\")\n                best_val_accuracy = logs['accuracy']\n            print(f\"EPOCH: {EPOCH}, Train_Loss: {round(logs['loss'], 4)}, Val_Loss: {round(logs['val_loss'], 4)}, val_accuracy {round(logs['accuracy'], 4)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\nClassifier = ClassificationAlpha(1, device)\nClassifier.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"Classifier.training_loop(TrainClassDataloader, ValClassDataloader, 30, display_every = 128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(Classifier.state_dict(), \"./FinalModel.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Dependencies"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%%capture\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim \nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score\n\n!pip install livelossplot\nimport livelossplot\n\n!pip install timm\nimport timm\n\n# Import Ranger Optimizer\n%cd ..\n!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer \n%cd Ranger-Deep-Learning-Optimizer\n!pip install -e .\n%cd ..\n%cd working\nimport sys\nsys.path.append(\"../Ranger-Deep-Learning-Optimizer\")\nfrom ranger import Ranger\n\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport random\n\nimport tqdm.notebook as tqdm\nimport copy\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reproducibility"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def seed_all():\n    seed = 42\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    numpy.random.seed(worker_seed)\n    random.seed(worker_seed)\nseed_all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# HYPERPARAMETERS\ndataframe_path = \"../input/plant-pathology-2021-fgvc8/train.csv\"\nBASE_PATH = \"../input/plant-pathology-2021-fgvc8/train_images/\"\nBATCH_SIZE = 24\nTEST_BATCH_SIZE = 32\nINPUT_WIDTH = 320\nIMAGE_SIZE = 320\nNUM_FOLDS = 3\nINPUT_HEIGHT = int(INPUT_WIDTH *1.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_transforms = A.Compose([\n    A.RandomResizedCrop(INPUT_WIDTH, INPUT_HEIGHT, scale=(0.6, 0.8), p=1),\n    A.Flip(p = 0.7),\n    A.OneOf([\n        A.MotionBlur(blur_limit=(3, 5)),\n        A.MedianBlur(blur_limit=5),\n        A.GaussianBlur(blur_limit=(3, 5)),\n        A.GaussNoise(var_limit=(5.0, 30.0)),\n        A.MultiplicativeNoise(),\n    ], p=0.7),\n    A.OneOf([\n        A.OpticalDistortion(distort_limit=1.0),\n        A.GridDistortion(num_steps=5, distort_limit=1.),\n        A.ElasticTransform(alpha=3),\n    ], p=0.7),\n    A.CLAHE(clip_limit=4.0, p=0.7),\n    A.IAASharpen(p=0.5),\n    A.ColorJitter(p = 0.7),\n    A.OneOf([\n        A.ImageCompression(),\n        A.Downscale(scale_min=0.7, scale_max=0.95),\n    ], p=0.2),\n    A.OneOf([\n        A.ToGray(),\n        A.ToSepia()\n    ]),\n    A.CoarseDropout(max_holes=8, max_height=int(INPUT_HEIGHT * 0.1),\n                       max_width=int(INPUT_WIDTH* 0.1), p=0.5),\n    A.Cutout(num_holes = 32),\n    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=45, border_mode=0, p=0.85),\n    A.Normalize(),\n    ToTensorV2()\n])\n\ntest_transforms = A.Compose([\n    A.Resize(INPUT_WIDTH, INPUT_HEIGHT),\n    A.Normalize(),\n    ToTensorV2()\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Process Dataset"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"dataFrame = pd.read_csv(dataframe_path)\ndataFrame = dataFrame.set_index(\"image\")\ndef process_dataframe(dataframe):\n    '''\n    dataFrame: pandas dataframe containing image ids and labels\n    '''\n    classes = []\n    count = 0\n    for row in dataframe.iterrows():\n        labels = str.split(row[1][0])\n        classes += labels\n    classes = sorted(list(set(classes)))\n    classes.remove('healthy')\n    return classes # Multi Class Classification Over 5 Classes\nCLASSES = process_dataframe(dataFrame)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class PlantDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, classes, base_path, transforms):\n        self.dataframe = dataframe\n        self.transforms = transforms\n        self.classes = classes\n        self.base_path = base_path\n        # Internal Dictionaries\n        self.class2idx = {}\n        self.idx2class = {}\n        for class_idx in range(len(self.classes)):\n            self.idx2class[class_idx] = self.classes[class_idx]\n            self.class2idx[self.classes[class_idx]] = class_idx\n        self.num_classes = len(self.class2idx) # Healthy is Omitted, added at test-time if no other predictions present\n    def __len__(self):\n        return len(self.dataframe)\n    def __getitem__(self, idx):\n        # Select Image\n        row = self.dataframe.iloc[idx]\n        img_id = row.name\n        values = str.split(row[0])\n        # Generate Tensor\n        classes = torch.zeros((self.num_classes))\n        for class_val in values:\n            if class_val == 'healthy':\n                break\n            else:\n                classes[self.class2idx[class_val]] = 1\n        # Load image in\n        img_path = self.base_path + img_id\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n        image = self.transforms(image = image)['image']\n        return torch.tensor(image), classes\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Generate 3 Folds\nsplitter = KFold(n_splits = 70, shuffle = True, random_state = 42)\nKSPLITS = []\ncount = 0\nfor train_idx, test_idx in splitter.split(dataFrame):\n    train_idx = np.array(train_idx)\n    test_idx = np.array(test_idx) \n    \n    train_dataframe = dataFrame.iloc[train_idx]\n    test_dataframe = dataFrame.iloc[test_idx]\n    KSPLITS += [(train_dataframe, test_dataframe)]\n    count += 1\n    if count == NUM_FOLDS:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def display_image(image):\n    plt.imshow(image.cpu().transpose(0, 1).transpose(1, 2))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Creation: Part 0 Down Sampler(No CNN)"},{"metadata":{},"cell_type":"markdown","source":"Handy Convolutional Blocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomLoss(nn.Module):\n    '''\n    Separates BCE loss into 0s and 1 to weight them evenly(1s are sparse)\n    '''\n    def __init__(self):\n        super().__init__()\n        self.criterion = nn.BCEWithLogitsLoss()\n    def forward(self, pred, y_true):\n        one_bools = y_true == 1\n        zero_bools = y_true == 0\n        pred_one = pred[one_bools]\n        pred_zeros = pred[zero_bools]\n        \n        one_loss = self.criterion(pred_one, torch.ones_like(pred_one, device = pred_one.device))\n        zero_loss = self.criterion(pred_zeros, torch.zeros_like(pred_zeros, device = pred_zeros.device))\n        \n        return one_loss + zero_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class StridedConvBlock(nn.Module):\n    def __init__(self, in_features, out_features, kernel_size, padding, groups, stride):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size = kernel_size, padding = padding, groups = groups, stride = stride)\n        self.bn = nn.BatchNorm2d(out_features)\n        self.act1 = nn.SiLU(inplace = True)\n    def forward(self, x):\n        return self.bn(self.act1(self.conv(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_features, out_features, kernel_size, padding, groups):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size = kernel_size, padding = padding, groups = groups) \n        self.bn = nn.BatchNorm2d(out_features)\n        self.act1 = nn.SiLU(inplace = True)\n    def forward(self, x):\n        return self.bn(self.act1(self.conv(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class CBAMChannel(nn.Module):\n    def __init__(self, in_dim, inner_dim):\n        super().__init__()\n        self.in_dim = in_dim \n        self.inner_dim = inner_dim\n        \n        self.Squeeze = nn.Linear(self.in_dim, self.inner_dim)\n        self.Excite = nn.Linear(self.inner_dim, self.in_dim)\n        self.act1 = nn.SiLU(inplace = True)\n    def forward(self, x):\n        avg_pool = torch.mean(x, dim = -1)\n        avg_pool = torch.mean(avg_pool, dim = -1)\n        \n        max_pool, _ = torch.max(x, dim = -1)\n        max_pool, _ = torch.max(max_pool, dim = -1)\n        \n        avg_squeeze = self.act1(self.Squeeze(avg_pool))\n        max_squeeze = self.act1(self.Squeeze(max_pool))\n        \n        avg_excite = self.Excite(avg_squeeze)\n        max_excite = self.Excite(max_squeeze)\n        \n        logits = torch.sigmoid(avg_excite + max_excite).unsqueeze(-1).unsqueeze(-1)\n        return logits * x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class SqueezeExcite(nn.Module):\n    def __init__(self, in_dim, inner_dim):\n        super().__init__()\n        self.in_dim = in_dim\n        self.inner_dim = inner_dim\n        \n        self.Squeeze = nn.Linear(self.in_dim, self.inner_dim)\n        self.Excite = nn.Linear(self.inner_dim, self.in_dim)\n        self.act1 = nn.SiLU(inplace = True) \n    def forward(self, x):\n        max_pool, _ = torch.max(x, dim = -1) \n        max_pool, _ = torch.max(max_pool, dim = -1)\n        \n        squeezed = self.act1(self.Squeeze(max_pool))\n        excite = torch.sigmoid(self.Excite(squeezed)).unsqueeze(-1).unsqueeze(-1)\n        return excite * x\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class BottleNeck(nn.Module):\n    def __init__(self, in_features, inner_features, device, stochastic_depth = 0.2):\n        super().__init__()\n        self.stochastic_depth = stochastic_depth\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.device = device\n        \n        self.Squeeze = ConvBlock(self.in_features, self.inner_features, 1, 0, 1)\n        self.Process = ConvBlock(self.inner_features, self.inner_features, 3, 1, 1)\n        self.Expand = ConvBlock(self.inner_features, self.in_features, 1, 0, 1)\n        self.SE = SqueezeExcite(self.in_features, self.in_features // 16)\n       \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.device))\n    def forward(self, x):\n        if self.training and random.random() < self.stochastic_depth:\n            return x\n        squeeze = self.Squeeze(x)\n        process = self.Process(squeeze)\n        expand = self.Expand(process)\n        excited = self.SE(expand)\n        return self.gamma * excited + x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class InvertedBottleNeck(nn.Module):\n    def __init__(self, in_dim, inner_dim, device, stochastic_depth = 0.2):\n        super().__init__()\n        self.stochastic_depth = stochastic_depth\n        self.device = device\n        self.in_dim = in_dim\n        self.inner_dim = inner_dim\n        \n        self.expand = ConvBlock(self.in_dim, self.inner_dim, 1, 0, 1)\n        self.depthwise = ConvBlock(self.inner_dim, self.inner_dim, 3, 1, self.inner_dim)\n        self.SE = SqueezeExcite(self.inner_dim, self.inner_dim // 16)\n        self.squeeze = ConvBlock(self.inner_dim, self.in_dim, 1, 0, 1)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.device))\n    def forward(self, x):\n        if self.training and random.random() < self.stochastic_depth:\n            return x \n        expanded = self.expand(x)\n        depthwise = self.depthwise(expanded)\n        excited = self.SE(depthwise)\n        squeezed = self.squeeze(excited)\n        return self.gamma * squeezed + x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class RegDownSampler(nn.Module):\n    '''\n    Just standard resize operation\n    '''\n    def __init__(self, out_size, device):\n        super().__init__()\n        self.device = device\n        self.out_size = out_size\n    def forward(self, x):\n        '''\n        Bilinear Interpolation to resize images\n        '''\n        resized = F.interpolate(x, size = (self.out_size, self.out_size), mode = 'bilinear')\n        return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class CNNDownSampler(nn.Module):\n    '''\n    Uses Convolution and Resizing to Downsample images\n    '''\n    def __init__(self, out_size, device):\n        super().__init__()\n        self.device = device\n        self.out_size = out_size\n        self.initialCNN = nn.Sequential(*[\n            ConvBlock(3, 16, 1, 0, 1), ConvBlock(16, 16, 1, 0, 1)])\n        \n        self.post_processing = nn.Sequential(*[\n            ConvBlock(16, 16, 1, 0, 1) for i in range(2) \n        ])\n        self.proj = ConvBlock(16, 3, 1, 0, 1)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.device))\n    def forward(self, x):\n        resized = F.interpolate(x, size = (self.out_size, self.out_size), mode = 'bilinear')\n        initial_processing = self.initialCNN(x)\n        # Resize\n        resize_processed = F.interpolate(initial_processing, size = (self.out_size, self.out_size), mode = 'bilinear')\n        # Further Processing\n        further_processed = self.post_processing(resize_processed)\n        proj = self.proj(further_processed)\n        return proj * self.gamma + resized","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BaseLine Model: MobileNetv3"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class MobileNetv3(nn.Module):\n    '''\n    BaseLine MobileNet v3 Based Model\n    '''\n    def freeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = False\n    def __init__(self, out_size, num_classes, device, dropout = 0.2, stochastic_depth = 0.2):\n        super().__init__()\n        self.drop_prob = dropout\n        self.stochastic_depth = stochastic_depth\n        self.model_name = 'mobilenetv3_large_100'\n        self.model = timm.create_model(self.model_name, pretrained = True)\n        \n        self.out_size = out_size\n        self.num_classes = num_classes\n        self.device = device\n        self.downsampler = CNNDownSampler(self.out_size, self.device) \n        \n        self.conv1 = self.model.conv_stem\n        self.bn1 = self.model.bn1\n        self.act1 = self.model.act1\n        \n        self.block0 = self.model.blocks[0] # (16)\n        self.block1 = self.model.blocks[1] # (24)\n        self.block2 = self.model.blocks[2] \n        self.block3 = self.model.blocks[3]\n        self.block4 = self.model.blocks[4]\n        self.block5 = self.model.blocks[5]\n        self.block6 = self.model.blocks[6] # We won't be using this block, it's very expensive\n        \n        # Freeze Initial Layers\n        #self.freeze(self.conv1)\n        #self.freeze(self.bn1)\n        #self.freeze(self.block0)\n        #self.freeze(self.block1)\n        #self.freeze(self.block2)\n        #self.freeze(self.block3)\n        #self.freeze(self.block4)\n        #self.freeze(self.block5)\n        \n        # Custom Layers\n        self.Attention1 = SqueezeExcite(40, 16)\n        self.Attention2 = SqueezeExcite(112, 32)\n        self.Attention3 = SqueezeExcite(160, 48)\n        self.layer4 = nn.Sequential(*[\n            ConvBlock(160, 320, 1, 0, 1)\n        ] + [\n            BottleNeck(320, 64, self.device, stochastic_depth = self.stochastic_depth) for i in range(5)\n        ])\n        \n        self.Attention4 = SqueezeExcite(320, 96)\n        self.layer5 = nn.Sequential(*[\n            StridedConvBlock(320, 512, 1, 0, 1, 2)\n        ] + [\n            BottleNeck(512, 128, self.device, stochastic_depth = self.stochastic_depth) for i in range(3)\n        ])\n        \n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(self.drop_prob)\n        self.Linear = nn.Linear(512, self.num_classes)\n    def forward(self, x):\n        downsampled = self.downsampler(x)\n        features0 = self.bn1(self.act1(self.conv1(downsampled)))\n        block0 = self.block0(features0) # (16, 160)\n        block1 = self.block1(block0) # (24, 80)\n        block2 = self.block2(block1) # (40, 40)\n        block2 = self.Attention1(block2)\n        \n        block3 = self.block3(block2) # (80, 20)\n        block4 = self.block4(block3) # (112, 20)\n        block4 = self.Attention2(block4)\n        \n        block5 = self.block5(block4) # (160, 10)\n        block5 = self.Attention3(block5)\n        \n        layer4 = self.layer4(block5) \n        layer4 = self.Attention4(layer4) # (320, 10)\n        \n        layer5 = self.layer5(layer4) # (512, 5) \n        \n        avg_pool = torch.squeeze(self.global_avg(layer5))\n        avg_pool = self.dropout(avg_pool)\n        return self.Linear(avg_pool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class MobileSolverQTPi(nn.Module):\n    def __init__(self, num_classes, device):\n        super().__init__()\n        self.out_size = IMAGE_SIZE\n        self.num_classes = num_classes\n        self.device = device\n        self.dropout = 0.5\n        self.stochastic_depth = 0.0\n        self.model = MobileNetv3(self.out_size, self.num_classes, self.device, dropout = self.dropout, stochastic_depth = self.stochastic_depth)\n        self.optim = Ranger(self.model.parameters(), lr = 1e-3, weight_decay = 1e-2)\n        self.lr_decay = optim.lr_scheduler.StepLR(self.optim, 5, 0.95)\n        self.lr_decay2 = optim.lr_scheduler.CosineAnnealingLR(self.optim, 5, eta_min = 1e-7)\n        self.criterion = CustomLoss()\n    def forward(self, x):\n        self.eval()\n        with torch.no_grad():\n            return self.model(x)\n    def threshold(self, pred):\n        bools = pred >= 0.5\n        pred[:, :] = 0\n        pred[bools] = 1\n        return pred\n    def f_score(self, pred, y_true):\n        '''\n        Computes the f score given logits(not sigmoided\n        '''\n        pred = torch.squeeze(torch.sigmoid(pred))\n        pred_labels = self.threshold(pred)\n        return f1_score(y_true, pred_labels, average= 'weighted')\n    def accuracy(self, pred, labels):\n        pred = torch.squeeze(torch.sigmoid(pred))\n        # Round to nearest\n        bools = pred >= 0.5\n        pred[:] = 0\n        pred[bools] = 1\n        B,C= pred.shape\n        return torch.sum((pred == labels).int()) / B / C\n    def training_loop(self, trainloader, valloader, NUM_EPOCHS, display_every = 16):\n        liveloss = livelossplot.PlotLosses()\n        bestValAcc = 0\n        bestValLoss = 999\n        torch.cuda.empty_cache()\n        for EPOCH in range(NUM_EPOCHS):\n            self.train()\n            logs = {}\n            logs['loss'] = 0\n            logs['accuracy'] = 0\n            logs['f_score'] = 0\n            count = 0\n            for images, labels in trainloader:\n                self.optim.zero_grad()\n                images = images.to(self.device)\n                labels = labels.to(self.device)\n                \n                pred = self.model(images)\n                loss = self.criterion(pred, labels)\n                \n                loss.backward()\n                self.optim.step() \n                \n                logs['loss'] += loss.item()\n                accuracy = self.accuracy(pred, labels).item()\n                logs['accuracy'] += accuracy\n                \n                logs['f_score'] += self.f_score(pred.cpu().detach(), labels.cpu())\n                print(f\"Step: {count}, L: {round(loss.item(), 3)}, A: {round(accuracy, 3)}\")\n                del images, labels\n                del pred, loss, accuracy\n                torch.cuda.empty_cache() \n                count += 1\n                if count == display_every:\n                    break\n            logs['loss'] /= count\n            logs['accuracy'] /= count\n            logs['loss'] = round(logs['loss'], 3)\n            logs['accuracy'] = round(logs['accuracy'], 3)\n            logs['f_score'] /= count\n            logs['f_score'] = round(logs['f_score'], 3)\n            self.eval()\n            self.lr_decay.step()\n            self.lr_decay2.step()\n            with torch.no_grad():\n                logs['val_loss'] = 0\n                logs['val_accuracy'] = 0\n                logs['val_f_score'] = 0\n                count = 0\n                for images, labels in valloader:\n                    images = images.to(self.device)\n                    labels = labels.to(self.device)\n                    \n                    pred = self.model(images)\n                    loss = self.criterion(pred, labels).item()\n                    accuracy = self.accuracy(pred, labels).item()\n                    \n                    logs['val_loss'] += loss\n                    logs['val_accuracy'] += accuracy\n                    logs['val_f_score'] += self.f_score(pred.cpu(), labels.cpu())\n                    count += 1\n                    del images, labels\n                    del pred, loss, accuracy\n                    torch.cuda.empty_cache()\n                logs['val_loss'] /= count\n                logs['val_accuracy'] /= count\n                logs['val_loss'] = round(logs['val_loss'], 3)\n                logs['val_accuracy'] = round(logs['val_accuracy'], 3)\n                logs['val_f_score'] /= count\n                logs['val_f_score'] = round(logs['val_f_score'], 3)\n\n            liveloss.update(logs)\n            liveloss.send()\n            print(f\"E: {EPOCH}, L: {logs['loss']}, A: {logs['accuracy']}, F: {logs['f_score']} VL: {logs['val_loss']}, VA: {logs['val_accuracy']} VF: {logs['val_f_score']}\")\n            if logs['val_loss'] <= bestValLoss:\n                bestValLoss= logs['val_loss']\n                torch.save(self.state_dict(), \"./BestValLoss.pth\")\n            if logs['val_accuracy'] >= bestValAcc:\n                bestValAcc = logs['val_accuracy']\n                torch.save(self.state_dict(), \"./BestValAcc.pth\")\n        torch.save(self.state_dict(), \"./FinalModel.pth\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stage 2: Modified ResNet Blocks with MultiFold Training"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class ModifiedEffNetQT(nn.Module):\n    '''\n    EfficientNet B4 Variant of the Same Model\n    '''\n    def freeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = False\n    def unfreeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = True\n    def __init__(self, out_size, num_classes, device, dropout = 0.2, stochastic_depth = 0.2):\n        super().__init__()\n        self.model_name = \"tf_efficientnet_b4_ns\"\n        self.model = timm.create_model(self.model_name, pretrained = True)\n        \n        self.out_size = out_size\n        self.num_classes = num_classes\n        self.device = device\n        self.drop_prob = dropout\n        self.stochastic_depth = stochastic_depth\n        \n        self.downsampler = CNNDownSampler(self.out_size, self.device)\n        \n        self.conv1 = self.model.conv_stem\n        self.bn1 = self.model.bn1\n        self.act1 = self.model.act1\n    \n        self.block0 = self.model.blocks[0]\n        self.block1 = self.model.blocks[1]\n        self.block2 = self.model.blocks[2]\n        self.block3 = self.model.blocks[3]\n        self.block4 = self.model.blocks[4]\n        self.block5 = self.model.blocks[5]\n        self.block6 = self.model.blocks[6]\n       \n        # Freeze Values(Uncomment if you replace self.downsampler with nn.Identity)\n        #self.freeze(self.conv1)\n        #self.freeze(self.bn1)\n        #self.freeze(self.block0)\n        #self.freeze(self.block1)\n        #self.freeze(self.block2)\n        \n        self.Attention1 = SqueezeExcite(56, 16)\n        self.Attention2 = SqueezeExcite(160, 32)\n        self.Attention3 = SqueezeExcite(448, 128)\n        \n        self.layer5 = nn.Sequential(*[\n            StridedConvBlock(448, 768, 1, 0, 1, 2)\n        ] + [\n           InvertedBottleNeck(768, 1536, self.device, stochastic_depth = self.stochastic_depth) for i in range(3)\n        ])\n        self.proj = ConvBlock(768, 2048, 1, 0, 1)\n        \n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(self.drop_prob)\n        self.Linear = nn.Linear(2048, self.num_classes)\n    def forward(self, x):\n        downsampled = self.downsampler(x)\n        features0 = self.bn1(self.act1(self.conv1(downsampled))) # (B, 48, 160, 160)\n        \n        block0 = self.block0(features0)\n        block1 = self.block1(block0)\n        block2 = self.block2(block1) # (B, 56, 40, 40)\n        # Attention1\n        block2 = self.Attention1(block2)\n        \n        block3 = self.block3(block2)\n        block4 = self.block4(block3) # (B, 160, 20, 20)\n        # Attention2\n        block4 = self.Attention2(block4)\n        \n        block5 = self.block5(block4)\n        block6 = self.block6(block5)\n        # attention 3\n        block6 = self.Attention3(block6) # (B, 448, 10, 10)\n        \n        layer5 = self.layer5(block6)\n        layer5 = self.proj(layer5)\n        global_avg = torch.squeeze(self.global_avg(layer5))\n        dropped = self.dropout(global_avg)\n        return self.Linear(dropped)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class ModifiedResNetQT(nn.Module):\n    '''\n    Modified ResNet200D\n    '''\n    def freeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = False\n    def unfreeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = True\n    def __init__(self, out_size, num_classes, device, dropout = 0.2, stochastic_depth = 0.2):\n        super().__init__()\n        self.device = device\n        self.num_classes = num_classes\n        self.drop_prob = dropout \n        self.out_size = out_size\n        self.device = device\n        self.stochastic_depth = stochastic_depth\n        self.model_name = 'resnet101d'\n        self.model = timm.create_model(self.model_name, pretrained = True)\n        \n        self.downsampler = CNNDownSampler(self.out_size, self.device) \n        \n        self.conv1 = self.model.conv1\n        self.bn1 = self.model.bn1\n        self.act1 = self.model.act1\n        self.pool = self.model.maxpool\n        \n        self.layer1 = self.model.layer1\n        self.layer2 = self.model.layer2\n        self.layer3 = self.model.layer3\n        self.layer4 = self.model.layer4 # we won't use this layer.\n        \n        # Freeze Initial Layers\n        #self.freeze(self.conv1)\n        #self.freeze(self.bn1)\n        #self.freeze(self.layer1)\n        #self.freeze(self.layer2)\n        \n        # Custom Layer\n        self.Attention2 = SqueezeExcite(512, 128)\n        self.Attention3 = SqueezeExcite(1024, 256)\n        self.Attention4 = SqueezeExcite(1536, 512)\n        \n        self.layer4 = nn.Sequential(*[\n            StridedConvBlock(1024, 1536, 1, 0, 1, 2)\n        ] + [\n            BottleNeck(1536, 512, self.device, stochastic_depth = self.stochastic_depth) for i in range(5)\n        ])\n        self.layer5 = nn.Sequential(*[\n            StridedConvBlock(1536, 2048, 1, 0, 1, 2)\n        ] + [\n            BottleNeck(2048, 512, self.device, stochastic_depth = self.stochastic_depth) for i in range(2)\n        ])\n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(self.drop_prob)\n        self.Linear = nn.Linear(2048, self.num_classes)\n    def forward(self, x):\n        '''\n        x: Tensor(B, 3, H, W)\n        '''\n        downsampled = self.downsampler(x) # (B, 3, out_size, out_size)\n        features0 = self.pool(self.bn1(self.act1(self.conv1(downsampled)))) # (B, 64, 160, 160)\n        \n        layer1 = self.layer1(features0)\n        layer2 = self.layer2(layer1)\n        # Attention2\n        layer2 = self.Attention2(layer2)\n        \n        layer3 = self.layer3(layer2)\n        # Attention 3\n        layer3 = self.Attention3(layer3)\n        \n        layer4 = self.layer4(layer3)\n        layer4 = self.Attention4(layer4)\n        \n        layer5 = self.layer5(layer4)\n        \n        global_avg = torch.squeeze(self.global_avg(layer5))\n        dropped = self.dropout(global_avg)\n        return self.Linear(dropped)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class MultiFoldQTPi(nn.Module):\n    def __init__(self, num_classes, device):\n        super().__init__()\n        self.out_size = IMAGE_SIZE\n        self.num_classes = num_classes\n        self.device = device\n        self.dropout = 0.5\n        self.stochastic_depth = 0.0\n        self.model = ModifiedEffNetQT(self.out_size, self.num_classes, self.device, dropout = self.dropout, stochastic_depth = self.stochastic_depth)\n        self.optim = Ranger(self.model.parameters(), lr = 1e-3, weight_decay = 1e-2)\n        self.lr_decay = optim.lr_scheduler.StepLR(self.optim, 5, 0.95)\n        self.lr_decay2 = optim.lr_scheduler.CosineAnnealingLR(self.optim, 5, eta_min = 1e-7)\n        self.criterion = CustomLoss()\n    def forward(self, x):\n        self.eval()\n        with torch.no_grad():\n            return self.model(x)\n    def threshold(self, pred):\n        bools = pred >= 0.5\n        pred[:, :] = 0\n        pred[bools] = 1\n        return pred\n    def f_score(self, pred, y_true):\n        '''\n        Computes the f score given logits(not sigmoided\n        '''\n        pred = torch.squeeze(torch.sigmoid(pred))\n        pred_labels = self.threshold(pred)\n        return f1_score(y_true, pred_labels, average= 'weighted')\n    def accuracy(self, pred, labels):\n        pred = torch.squeeze(torch.sigmoid(pred))\n        # Round to nearest\n        bools = pred >= 0.5\n        pred[:] = 0\n        pred[bools] = 1\n        B,C= pred.shape\n        return torch.sum((pred == labels).int()) / B / C\n    def training_loop(self, trainloader, valloader, NUM_EPOCHS, fold_num = 0, display_every = 16):\n        liveloss = livelossplot.PlotLosses()\n        bestValAcc = 0\n        bestValLoss = 999\n        bestValF = 0\n        torch.cuda.empty_cache()\n        for EPOCH in range(NUM_EPOCHS):\n            self.train()\n            logs = {}\n            logs['loss'] = 0\n            logs['accuracy'] = 0\n            logs['f_score'] = 0\n            count = 0\n            for images, labels in trainloader:\n                self.optim.zero_grad()\n                images = images.to(self.device)\n                labels = labels.to(self.device)\n                \n                pred = self.model(images)\n                loss = self.criterion(pred, labels)\n                \n                loss.backward()\n                self.optim.step() \n                \n                logs['loss'] += loss.item()\n                accuracy = self.accuracy(pred, labels).item()\n                logs['accuracy'] += accuracy\n                \n                logs['f_score'] += self.f_score(pred.cpu().detach(), labels.cpu())\n                print(f\"Step: {count}, L: {round(loss.item(), 3)}, A: {round(accuracy, 3)}\")\n                del images, labels\n                del pred, loss, accuracy\n                torch.cuda.empty_cache() \n                count += 1\n                if count == display_every:\n                    break\n            logs['loss'] /= count\n            logs['accuracy'] /= count\n            logs['loss'] = round(logs['loss'], 3)\n            logs['accuracy'] = round(logs['accuracy'], 3)\n            logs['f_score'] /= count\n            logs['f_score'] = round(logs['f_score'], 3)\n            self.eval()\n            self.lr_decay.step()\n            self.lr_decay2.step()\n            with torch.no_grad():\n                logs['val_loss'] = 0\n                logs['val_accuracy'] = 0\n                logs['val_f_score'] = 0\n                count = 0\n                for images, labels in valloader:\n                    images = images.to(self.device)\n                    labels = labels.to(self.device)\n                    \n                    pred = self.model(images)\n                    loss = self.criterion(pred, labels).item()\n                    accuracy = self.accuracy(pred, labels).item()\n                    \n                    logs['val_loss'] += loss\n                    logs['val_accuracy'] += accuracy\n                    logs['val_f_score'] += self.f_score(pred.cpu(), labels.cpu())\n                    count += 1\n                    del images, labels\n                    del pred, loss, accuracy\n                    torch.cuda.empty_cache()\n                logs['val_loss'] /= count\n                logs['val_accuracy'] /= count\n                logs['val_loss'] = round(logs['val_loss'], 3)\n                logs['val_accuracy'] = round(logs['val_accuracy'], 3)\n                logs['val_f_score'] /= count\n                logs['val_f_score'] = round(logs['val_f_score'], 3)\n\n            liveloss.update(logs)\n            liveloss.send()\n            \n            if logs['val_f_score'] >= bestValF:\n                bestValF = logs['val_f_score']\n                torch.save(self.state_dict(), f\"./fold_{fold_num}_F.pth\")\n            if logs['val_loss'] <= bestValLoss:\n                bestValLoss= logs['val_loss']\n                #torch.save(self.state_dict(), f\"./fold_{fold_num}_Loss.pth\")\n            if logs['val_accuracy'] >= bestValAcc:\n                bestValAcc = logs['val_accuracy']\n                #torch.save(self.state_dict(), f\"./fold_{fold_num}_Acc.pth\")\n            print(f\"E: {EPOCH}, BF: {bestValF} BA: {bestValAcc} BL: {bestValLoss} L: {logs['loss']}, A: {logs['accuracy']}, F: {logs['f_score']} VL: {logs['val_loss']}, VA: {logs['val_accuracy']} VF: {logs['val_f_score']}\")\n\n        torch.save(self.state_dict(), f\"./fold_{fold_num}_Final.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def train_folds(KSPLITS, NUM_EPOCHS, display_every = 16, load_prev = None):\n    '''\n    Trains through all folds, saving BestValLoss and Final Model Only\n    load_prev: Resume Training all folds. Splits should be identical due to seeding.\n    '''\n    for idx, (train, val) in enumerate(KSPLITS):\n        # Create Datasets\n        train_dataset = PlantDataset(train, copy.deepcopy(CLASSES), BASE_PATH, train_transforms)\n        val_dataset = PlantDataset(val, copy.deepcopy(CLASSES), BASE_PATH, test_transforms)\n        # Create Dataloaders\n        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, worker_init_fn = seed_worker)\n        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = TEST_BATCH_SIZE, shuffle = False, worker_init_fn = seed_worker)\n        # Create Model\n        model = MultiFoldQTPi(len(CLASSES), device)\n        model.to(device)\n        if load_prev != None:\n            # Load in Prev Fold Values\n            path = load_prev + f'fold_{idx}_Final.pth'\n            model.load_state_dict(torch.load(path, map_location = device))\n            \n        # Train Fold\n        model.training_loop(train_dataloader, val_dataloader, NUM_EPOCHS, fold_num = idx, display_every = display_every)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"NUM_EPOCHS = 50\nDISPLAY_EVERY = 64 # Train each fold at each commit(Fully Train Each One Per Commit, Splits are identical each time with seeding)\ntrain_folds([KSPLITS[2]], NUM_EPOCHS, display_every = DISPLAY_EVERY, load_prev = '../input/halftrained/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n                 'Swan Ganz Catheter Present']","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\nsys.path.append('../input/pytorch-images-seresnet')\nimport os\nimport copy\nimport math\nimport ast\nimport time\nimport random\nimport shutil\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import check_random_state\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.models as models\nimport torchvision\n\nimport albumentations\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nfrom tqdm.notebook import tqdm\nimport timm\n\nimport matplotlib.pyplot as plt\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load in Models "},{"metadata":{"trusted":true},"cell_type":"code","source":"class BatchNormBlock(nn.Module):\n    def __init__(self, in_features, out_features, kernel_size, padding, stride, groups):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size = kernel_size, padding = padding, stride= stride, groups = groups)\n        self.bn = nn.BatchNorm2d(out_features)\n    def forward(self, x):\n        return self.bn(F.relu(self.conv(x), inplace = True)) ","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BottleNeck(nn.Module):\n    def __init__(self, in_dim, inner_dim):\n        '''\n        in_features, out_features, kernel_size, padding, stride, groups\n        '''\n        super().__init__()\n        self.in_dim = in_dim\n        self.inner_dim = inner_dim\n        self.squeeze = BatchNormBlock(self.in_dim, self.inner_dim, 1, 0, 1, 1)\n        self.process = BatchNormBlock(self.inner_dim, self.inner_dim, 3, 1, 1, 1)\n        self.expand = BatchNormBlock(self.inner_dim, self.in_dim, 1, 0, 1, 1)\n        self.bn = nn.BatchNorm2d(self.in_dim)\n        self.gamma = nn.Parameter(torch.zeros(1, device = device))\n        #self.gamma.requires_grad = False\n    def forward(self, x):\n        return self.bn(self.expand(self.process(self.squeeze(x)))) * self.gamma + x","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ModifiedResNetAlpha(nn.Module):\n    def freeze(self, layer):\n        for parameter in layer.parameters():\n            parameter.requires_grad = False\n    def __init__(self, num_classes, device, drop_prob = 0.2):\n        # modified ResNet Student, with additional processing and one less attention head for maximal performance\n        super().__init__()\n        self.device = device\n        self.num_classes = num_classes\n        self.model = timm.create_model(\"resnet200d_320\", pretrained = True, features_only = True)\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        \n        self.conv1 = self.model.conv1\n        self.bn1 = self.model.bn1\n        \n        self.layer1 = self.model.layer1\n        \n        self.layer2 = self.model.layer2\n        \n        self.layer3 = self.model.layer3\n        \n        # Freeze Initial Layers\n        #self.freeze(self.layer1)\n        #self.freeze(self.conv1)\n        #self.freeze(self.bn1)\n        #self.freeze(self.layer2)\n        #self.freeze(self.layer3) \n        \n        self.layer4 = self.model.layer4 # Extract layers from ResNet\n        \n        self.layer2_5 = nn.Sequential(*[\n            BottleNeck(512, 128) for i in range(12) # 18 BottleNeck Blocks, Really Really Cheap Operation so use wisely.\n        ])\n        \n        self.layer2_att = nn.Identity()#CBAMAttention(512, 256, 2)\n        self.se2 = nn.Identity()#CBAMSqueezeExcite(512, 256)\n        \n        self.layer3_att = nn.Identity()#CBAMAttention(1024, 512, 2)\n        self.se3 = nn.Identity()#CBAMSqueezeExcite(1024, 256) \n        # Custom Layer 3.5(Between layer 3 and 4)\n        \n        self.layer3_5 = nn.Sequential(*[BottleNeck(1024, 256) for i in range(15)]) #+\n            #[nn.MaxPool2d(kernel_size = 3, padding = 1, stride = 2)] + \n            #[BottleNeck(1024, 256) for i in range(12)])\n\n        \n        self.layer4_att = nn.Identity()#CBAMAttention(1024, 512, 2)\n        self.se4 = nn.Identity()#CBAMSqueezeExcite(1024, 256) \n        \n        self.Dropout = nn.Dropout(drop_prob)\n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.Linear = nn.Linear(2048, self.num_classes)\n       \n        \n    def forward(self, x):\n        B, _, _, _ = x.shape\n        base_features = self.model(x)[-3] # (B, 512, 80, 80)\n        # Process through Layer 2.5\n        layer2_5 = self.layer2_5(base_features) # (B, 512, 80, 80)\n        \n        attention2 = self.layer2_att(layer2_5)\n        excited_features2 = self.se2(attention2)\n    \n        layer3 = self.layer3(excited_features2) # (B, 1024, 40, 40)\n        \n        attention3 = self.layer3_att(layer3)\n        excited_features3 = self.se3(attention3)\n        \n        layer3_5 = self.layer3_5(excited_features3)\n        attention4 = self.layer4_att(layer3_5)\n        excited_features4 = self.se4(attention4) # (B, 1024, 10, 10)\n        \n        layer4 = self.layer4(excited_features4) # (B, 2048, 5, 5)\n        # Pooled Features\n        avg_pooled = torch.squeeze(self.global_avg(layer4)) # (B, 2048)\n        dropped_features = self.Dropout(avg_pooled) # (B, 2048)\n        \n        logits = self.Linear(dropped_features) # (B, 11)\n        \n        return logits, excited_features2, excited_features3, excited_features4, layer4, avg_pooled ","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class StudentSolver(nn.Module):\n    def __init__(self, student):\n        super().__init__()\n        self.student = student\n    def forward(self, x):\n        '''\n        Runs Inference on the Student Model, performing a sigmoid on the logits\n        '''\n        self.eval()\n        with torch.no_grad():\n            logits, _, _, _, _, _ = self.student(x)\n            return logits","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load in the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 320\ntest_transforms = Compose([\n            Resize(IMAGE_SIZE, IMAGE_SIZE),\n            Normalize(),\n            ToTensorV2(),\n        ])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transforms):\n        self.df = df \n        self.file_names = df.index.values\n        self.transforms = transforms \n        self.testing_path = \"../input/ranzcr-clip-catheter-line-classification/test/\"\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        test_id= self.file_names[idx]\n        test_path = self.testing_path + test_id + '.jpg'\n        # load in the image\n        image = cv2.imread(test_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # Test Transforms\n        transformed_image = self.transforms(image = image)['image']\n        return transformed_image, test_id\n        ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/ranzcr-clip-catheter-line-classification/sample_submission.csv\", index_col = \"StudyInstanceUID\")\ntest_dataset = TestDataset(test_data, test_transforms)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 8)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Models into Memory"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d_320'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 11)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output\n\nclass SeResNet152D(nn.Module):\n    def __init__(self, model_name='seresnet152d'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 11)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONSTANTS\nRESNET200D_PATH = '../input/resnet200d-public/resnet200d_320_CV9632.pth'\nSERESNET_PATH = '../input/seresnet152d-cv9615/seresnet152d_320_CV96.15.pth'\nCUSTOM_MODEL_PATH = \"../input/stage3/FinalModel.pth\"\nSERESNET_WEIGHT = 1\nRESNET200D_WEIGHT = 2\nCUSTOMMODEL_WEIGHT = 1\nDIVIDE = 4","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\nresnet200D = ResNet200D()\nresnet200D.load_state_dict(torch.load(RESNET200D_PATH)['model'])\nresnet200D.to(device)\nseresnet152 = SeResNet152D()\nseresnet152.load_state_dict(torch.load(SERESNET_PATH)['model'])\nseresnet152.to(device)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n# Load Custom Model Here.\nCustomModel = StudentSolver(ModifiedResNetAlpha(11, device, drop_prob = 0.0))\nCustomModel.to(device)\nCustomModel.load_state_dict(torch.load(CUSTOM_MODEL_PATH))","execution_count":20,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"__init__() missing 1 required positional argument: 'device'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-112199720782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load Custom Model Here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCustomModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStudentSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModifiedResNetAlpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUSTOM_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'device'"]}]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble and Predict on the Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, images):\n    model.eval()\n    with torch.no_grad():\n        predicted1 = torch.sigmoid(model(images)).cpu()\n        predicted2 = torch.sigmoid(model(images.flip(-1))).cpu()\n        predicted_logits = (predicted1 + predicted2) / 2\n    return predicted_logits","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_custom(model, images):\n    model.eval()\n    with torch.no_grad():\n        predicted1, _, _, _, _, _ = model(images)\n        predicted1 = torch.sigmoid(predicted1).cpu()\n        predicted2, _, _, _, _, _ = model(images.flip(-1))\n        predicted2 = torch.sigmoid(predicted2).cpu()\n        predicted_logits = (predicted1 + predicted2) / 2\n    return predicted_logits","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_predictions(test_dataloader):\n    '''\n    performs an ensemble prediction on SEResNet, ResNet, and Custom ResNet\n    '''\n    predictions = {\"StudyInstanceUID\": []}\n    for title in target_cols:\n        predictions[title] = []\n    # Iterate over the test_dataloader\n    for images, ids in tqdm(test_dataloader):\n        images = images.to(device)\n        predictedResNet = predict(resnet200D, images) * RESNET200D_WEIGHT\n        predictedSE = predict(seresnet152, images) * SERESNET_WEIGHT\n        predictedCustom = predict_custom(CustomModel, images) * CUSTOMMODEL_WEIGHT\n        # Ensemble Logits\n        final_predictions = (predictedResNet + predictedSE + predictedCustom) / DIVIDE # (B, 11)\n        # Add to predictions\n        predictions['StudyInstanceUID'] += list(ids)\n        for title_idx in range(len(target_cols)):\n            predicted = final_predictions[:, title_idx]\n            title = target_cols[title_idx]\n            predictions[title] += predicted.numpy().tolist()\n        break\n    return predictions","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submission(predictions):\n    '''\n    Creates a pandas daatframe and makes a final prediction\n    '''\n    df = pd.DataFrame(predictions, index = \"StudyInstanceUID\")\n    df.to_csv(\"./submission.csv\", index = False)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = make_predictions(test_dataloader)\nmake_submission(predictions)","execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/448 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b133a3aa54d41e3a74d7d78d728c1ce"}},"metadata":{}},{"output_type":"error","ename":"NameError","evalue":"name 'CustomModel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-2bb8f9ed6999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmake_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-b2dbb8dab79c>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(test_dataloader)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpredictedResNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet200D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mRESNET200D_WEIGHT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpredictedSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseresnet152\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSERESNET_WEIGHT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpredictedCustom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustomModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mCUSTOMMODEL_WEIGHT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Ensemble Logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfinal_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictedResNet\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredictedSE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredictedCustom\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mDIVIDE\u001b[0m \u001b[0;31m# (B, 11)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'CustomModel' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Dependencies","metadata":{}},{"cell_type":"code","source":"%%capture\nimport torch\nimport torch.nn as nn \nimport torch.nn.functional as F \nimport torch.optim as optim\nimport torchvision\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport numpy as np\nimport pandas as pd\nimport json\nimport cv2\n\nimport os\nimport math\nimport copy\nimport random\n\n!pip install livelossplot\nimport livelossplot\n\n!pip install timm\nimport timm\n\nimport pytorch_lightning as pl\nfrom collections import Counter \nimport fastai.vision.all as fastai \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\n# Import Ranger Optimizer\n%cd ..\n!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer \n%cd Ranger-Deep-Learning-Optimizer\n!pip install -e .\n%cd ..\n%cd working\nimport sys\nsys.path.append(\"../Ranger-Deep-Learning-Optimizer\")\nfrom ranger import Ranger\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"For Reproducibility:","metadata":{}},{"cell_type":"code","source":"def seed():\n    seed = 42\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    numpy.random.seed(worker_seed)\n    random.seed(worker_seed)\nseed()","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Process the Dataset","metadata":{}},{"cell_type":"code","source":"def process_ids(df):\n    '''\n    Hotel Ids range from 0 -> 60000, but there are only 7000 unique values.\n    Thus, we should map the classes down to 7700 instead of 60000 and remap on inference.\n    '''\n    orig_index_values = df.hotel_id.values\n    unique = sorted(list(set(orig_index_values)))\n    orig2cls = {unique[i]: i for i in range(len(unique))}\n    cls2orig = {i: unique[i] for i in range(len(unique))}\n    return orig2cls, cls2orig","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_folds(train_df, NUM_FOLDS):\n    # Split into KFolds\n    KFOLDS = []\n    splitter = KFold(n_splits = 300, shuffle = True, random_state = 42)\n    count = 0\n    for train, test in splitter.split(train_df):\n        train_split = train_df.iloc[train]\n        test_split = train_df.iloc[test]\n        KFOLDS += [(train_split, test_split)]\n        count += 1\n        if count == NUM_FOLDS:\n            break\n    return KFOLDS\ndef get_albumentations(IMAGE_SIZE):\n    '''\n    Loads Augmentations\n    '''\n    train_transforms = A.Compose([\n        A.RandomResizedCrop(IMAGE_SIZE, IMAGE_SIZE, scale = (0.9, 0.9), p = 1),\n        A.HorizontalFlip(p = 0.7),\n        A.OneOf([\n            A.Blur(), # Either Noise or Blur\n            A.MultiplicativeNoise(),\n        ], p=0.7),\n        A.OpticalDistortion(distort_limit=1.0, p = 0.7),\n        #A.CLAHE(clip_limit=4.0, p=0.7),\n        A.ColorJitter(p = 0.7, brightness = 0.1, contrast = 0.1, hue = 0.1, saturation = 0.1),\n        #A.OneOf([\n        #    A.ImageCompression(),\n        #    A.Downscale(scale_min=0.7, scale_max=0.95),\n        #], p=0.2),\n        #A.CoarseDropout(max_holes=8, max_height=int(IMAGE_SIZE * 0.05),\n        #                   max_width=int(IMAGE_SIZE* 0.05), p=0.5),\n        A.Cutout(num_holes = 32, max_h_size= 8, max_w_size =8),\n        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=15, border_mode=0, p=0.85),\n        A.Normalize(),\n        ToTensorV2()\n    ])\n\n    test_transforms = A.Compose([\n        A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n        A.Normalize(),\n        ToTensorV2()\n    ])\n    \n    return train_transforms, test_transforms","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Dataset and Dataloader","metadata":{}},{"cell_type":"code","source":"def display_image_np(image):\n    plt.imshow(image)\n    plt.show()\ndef display_image_pt(image):\n    plt.imshow(image.transpose(0,1).transpose(1, 2))\n    plt.show()","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class HotelDataset(torch.utils.data.Dataset):\n    def __init__(self, df, orig2cls, cls2orig, image_size, transforms):\n        self.df = df\n        self.image_size = image_size\n        self.indices = self.df.index.values\n        self.orig2cls = orig2cls\n        self.cls2orig = cls2orig\n        self.transforms = transforms\n        \n    def decode_pred(self, idx):\n        return self.cls2orig[idx]\n    def encode_pred(self, idx):\n        return self.orig2cls[idx]\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        GT = self.encode_pred(row['hotel_id'])\n        file_path = Config.train_base_path + f\"{row['chain']}/\" + row['image']\n        #print(file_path)\n        # Load in Image\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        image = self.transforms(image = image)['image']\n        return image, GT","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def split_df(df, num):\n    '''\n    Splits up DataFrame for Overfitting Testing.\n    '''\n    overfit, _ = train_test_split(df, train_size = num / len(df), test_size = ((len(df) - num) / len(df)), random_state = 42)\n    return overfit\nclass Config:\n    '''\n    Holds many states for the model.\n    '''\n    overfit_samples = -1\n    train_path = \"../input/hotel-id-2021-fgvc8/train.csv\"\n    train_base_path = '../input/hotel-id-2021-fgvc8/train_images/'\n    \n    train_df = pd.read_csv(train_path)\n    orig2cls, cls2orig = process_ids(train_df) \n    NUM_CLASSES = len(orig2cls)\n    # Overfit Split \n    if overfit_samples != -1:\n        train_df, _ = train_test_split(train_df, train_size = overfit_samples, test_size = 1 - overfit_samples, random_state = 42)\n    NUM_FOLDS = 1\n    FOLDS = get_folds(train_df, NUM_FOLDS)\n    \n    IMAGE_SIZE = 320\n    train_transforms, test_transforms = get_albumentations(IMAGE_SIZE)\n    \n    BATCH_SIZE = 32\n    TEST_BATCH_SIZE = 64\n    \n    device = device\n    \n    # Training States\n    NUM_EPOCHS = 6# 90000 images is a lot.\n","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class LightningDataModule(pl.LightningDataModule):\n    def __init__(self, KSPLITS):\n        self.KSPLITS = KSPLITS\n    def train_dataloader(self, idx):\n        split = self.KSPLITS[idx][0]\n        train_dataset = HotelDataset(split, Config.orig2cls, Config.cls2orig, Config.IMAGE_SIZE, Config.train_transforms)\n        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = Config.BATCH_SIZE, shuffle = True, num_workers = 4, worker_init_fn = seed_worker, pin_memory = True)\n        return train_dataloader\n    def val_dataloader(self, idx):\n        split = self.KSPLITS[idx][1]\n        val_dataset = HotelDataset(split, Config.orig2cls, Config.cls2orig, Config.IMAGE_SIZE, Config.test_transforms)\n        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = Config.TEST_BATCH_SIZE, shuffle = False, worker_init_fn = seed_worker, num_workers = 4, pin_memory = True)\n        return val_dataloader\n    def get_both(self, idx):\n        return self.train_dataloader(idx), self.val_dataloader(idx)\ndataModule = LightningDataModule(Config.FOLDS)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# BaseLine Model, Modified ResNet using Fast AI.","metadata":{}},{"cell_type":"markdown","source":"Fast AI vs Vanilla Pytorch","metadata":{}},{"cell_type":"markdown","source":"Vanilla Pytorch","metadata":{}},{"cell_type":"code","source":"class ConvBlockVanilla(pl.LightningModule):\n    '''\n    Basic ConvBlock with BN(Removed Later) \n    '''\n    def __init__(self, in_features, out_features, kernel_size, padding, groups, stride, act = 'relu'):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size = kernel_size, padding = padding, groups = groups, stride = stride, bias = False)\n        self.bn = nn.BatchNorm2d(out_features)\n        if act == 'relu':\n            self.act1 = nn.ReLU(inplace = True)\n        else:\n            self.act1 = nn.SiLU(inplace = True)\n    def forward(self, x):\n        return self.bn(self.act1(self.conv(x)))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Squeeze Attend Blocks(Traditionally Used in Semantic Segmentation, but I find it can work really well in classification too)\nclass ConvPlusBatchNorm(pl.LightningModule):\n    def __init__(self, in_features, out_features, kernel_size, padding, groups, stride):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size = kernel_size, padding = padding, groups = groups, stride = stride, bias = False)\n        self.bn = nn.BatchNorm2d(out_features)\nclass CBAMSqueezeAttend(pl.LightningModule):\n    def __init__(self, in_features, inner_features, squeeze_factor = 4, act = 'relu'):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.squeeze_factor = squeeze_factor\n        \n        self.avg_pool = nn.AvgPool2d(kernel_size = 5, padding = 2, stride = self.squeeze_factor)\n        self.max_pool = nn.MaxPool2d(kernel_size = 5, padding = 2, stride = self.squeeze_factor)\n        \n        self.Squeeze = ConvBlockVanilla(self.in_features, self.inner_features, 3, 1, 1, 1, act = act)\n        self.Excite = ConvPlusBatchNorm(self.inner_features, self.in_features, 3, 1, 1, 1)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.device))\n    def forward(self, x):\n        '''\n        Squeeze Attend Blocks\n        '''\n        avg_pool = self.avg_pool(x)\n        max_pool = self.max_pool(x)\n        \n        squeeze_avg = self.Squeeze(avg_pool)\n        squeeze_max = self.Squeeze(max_pool)\n        \n        excite_avg = self.Excite(squeeze_avg)\n        excite_max = self.Excite(squeeze_max)\n        \n        excite = torch.sigmoid((excite_avg + excite_max) / 2)\n        # Interpolate Up\n        excite = F.interpolate(excite, scale_factor = self.squeeze_factor, mode = 'nearest')\n        return excite * x * self.gamma + (1 - self.gamma) * x\n    \nclass SESqueezeAttend(pl.LightningModule):\n    def __init__(self, in_features, inner_features, squeeze_factor = 4, act = 'relu'):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.squeeze_factor = squeeze_factor \n        \n        self.avg_pool = nn.AvgPool2d(kernel_size = 5, padding = 2, stride = self.squeeze_factor) \n        \n        self.Squeeze = ConvBlockVanilla(self.in_features, self.inner_features, 3, 1, 1, 1, act = act)\n        self.Excite = ConvPlusBatchNorm(self.inner_features, self.in_features, 3, 1, 1, 1)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.device))\n    def forward(self, x):\n        pooled = self.avg_pool(x)\n        squeeze = self.Squeeze(pooled) \n        excite = torch.sigmoid(self.Excite(squeeze))\n        # Upsample\n        excite = F.interpolate(excite, scale_factor = self.squeeze_factor, mode = 'nearest')\n        return self.gamma * excite * x + (1 - self.gamma) * x\n\nclass CBAMVanilla(pl.LightningModule):\n    '''\n    Uses CBAM channel only, CBAM Spatial often messes up the features too much.\n    '''\n    def __init__(self, in_features, inner_features, dev):\n        super().__init__()\n        self.in_features = in_features \n        self.inner_features = inner_features\n        self.dev = dev \n        \n        self.Squeeze = nn.Linear(self.in_features, self.inner_features)\n        self.act1 = nn.SiLU(inplace = True)\n        self.Excite = nn.Linear(self.inner_features, self.in_features)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        avg_pool = torch.mean(x, dim = -1)\n        avg_pool = torch.mean(avg_pool, dim = -1)\n        \n        max_pool, _ = torch.max(x, dim = -1)\n        max_pool, _ = torch.max(max_pool, dim = -1)\n        \n        squeeze_avg = self.act1(self.Squeeze(avg_pool))\n        squeeze_max = self.act1(self.Squeeze(max_pool))\n        \n        excite_avg = self.Excite(squeeze_avg) \n        excite_max = self.Excite(squeeze_max)\n        \n        excite = torch.sigmoid((excite_avg + excite_max) / 2).unsqueeze(-1).unsqueeze(-1)\n        return (excite * x) * self.gamma + (1 - self.gamma) * x # 1 - Gamma to assure magnitude of vectors remain around the same and we don't inflate outputs\n        # gamma thresholds how much `excited` features, and how much `normal` to keep\nclass SEVanilla(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev):\n        super().__init__()\n        self.dev = dev\n        self.in_features = in_features\n        self.inner_features = inner_features\n        \n        self.Squeeze = nn.Linear(self.in_features, self.inner_features) \n        self.act1 = nn.SiLU(inplace = True)\n        self.Excite = nn.Linear(self.inner_features, self.in_features)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        avg_pool = torch.mean(x, dim = -1)\n        avg_pool = torch.mean(avg_pool, dim = -1)\n        \n        squeeze = self.act1(self.Squeeze(avg_pool))\n        excite = torch.sigmoid(self.Excite(squeeze)).unsqueeze(-1).unsqueeze(-1)\n        return (excite * x) * self.gamma + (1 - self.gamma) * x\n\nclass SelfAttentionVanilla(pl.LightningModule):\n    def __init__(self, in_features, inner_features, num_heads, dev):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.num_heads = num_heads\n        self.dev = dev\n        \n        self.K = ConvPlusBatchNorm(self.in_features, self.inner_features * self.num_heads, 3, 1, 1, 1)\n        self.V = ConvPlusBatchNorm(self.in_features, self.inner_features * self.num_heads, 3, 1, 1, 1)\n        self.Q = ConvPlusBatchNorm(self.in_features, self.inner_features * self.num_heads, 3, 1, 1, 1)\n        \n        self.Linear = ConvPlusBatchNorm(self.inner_features * self.num_heads, self.in_features, 3, 1, 1,1)\n        self.gamma = nn.Parameter(torch.zeros((1), dvice = self.dev))\n    def forward(self, x):\n        B, C, H, W = x.shape\n        Keys = self.K(x)\n        Values = self.V(x)\n        Queries = self.Q(x)\n        \n        Keys = Keys.reshape(B, self.num_heads, self.inner_features, H, W)\n        Values = Values.reshape(B, self.num_heads, self.inner_features, H, W)\n        Queries = Queries.reshape(B, self.num_heads, self.inner_features, H, W)\n        \n        Keys = Keys.reshape(B * self.num_heads, self.inner_features, H * W)\n        Values = Values.reshape(B * self.num_heads, self.inner_features, H * W)\n        Queries = Queries.reshape(B * self.num_heads, self.inner_features, H * W)\n        \n        att_mat = F.softmax(torch.bmm(Keys.transpose(1, 2), Queries) / math.sqrt(self.inner_features))\n        att_scores = torch.bmm(Values, att_mat)\n        \n        att_scores = att_scores.reshape(B, self.num_heads, self.inner_features, H, W)\n        att_scores = att_scores.reshape(B, self.num_heads * self.inner_features, H * W)\n        \n        linear = self.Linear(att_scores)\n        return linear * self.gamma + (1 - self.gamma) * x\nclass AttentionVanilla(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev, attention_type = 'se', act = 'relu'):\n        super().__init__()\n        assert attention_type in ['se', 'cbam', 'self', 'cbam_attend', 'se_attend']\n        self.attention_type = attention_type\n        if self.attention_type == 'se':\n            self.layer = SEVanilla(in_features, inner_features, dev)\n        elif self.attention_type == 'cbam':\n            self.layer = CBAMVanilla(in_features, inner_features, dev)\n        elif self.attention_type == 'cbam_attend':\n            self.layer = CBAMSqueezeAttend(in_features, inner_features, squeeze_factor = 4, act = act)\n        elif self.attention_type == 'se_attend':\n            self.layer = SESqueezeAttend(in_features, inner_features, squeeze_factor = 4, act = act)\n        else:\n            self.layer = SelfAttentionVanilla(in_features, inner_features, 1, dev)\n    def forward(self, x):\n        return self.layer(x) ","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class BottleNeckVanilla(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev, stochastic_depth = 0.2, attention_type = 'se', act = 'relu'):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.dev = dev\n        self.stochastic_depth = stochastic_depth\n        \n        self.Squeeze = ConvBlockVanilla(self.in_features, self.inner_features, 1, 0, 1, 1, act = act)\n        self.Process = ConvBlockVanilla(self.inner_features, self.inner_features, 3, 1, 1, 1, act = act) \n        self.Expand = ConvBlockVanilla(self.inner_features, self.in_features, 1, 0, 1, 1, act = act)\n        self.SE = AttentionVanilla(self.in_features, self.in_features // 4, self.dev, attention_type = attention_type, act = act)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n        \n    def forward(self, x):\n        if self.training and random.random() < self.stochastic_depth:\n            return x # Stochastic Depth\n        squeezed = self.Squeeze(x)\n        processed = self.Process(squeezed)\n        expanded = self.Expand(processed) \n        SE = self.SE(expanded) \n        return self.gamma * SE + (1 - self.gamma) * x\n        \nclass InverseBottleNeckVanilla(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev, stochastic_depth = 0.2, attention_type = 'se', act = 'relu'):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.dev = dev\n        self.stochastic_depth = stochastic_depth\n        \n        self.expand = ConvBlockVanilla(self.in_features, self.inner_features, 1, 0, 1, 1, act = act)\n        self.process = ConvBlockVanilla(self.inner_features, self.inner_features, 3, 1, self.inner_features, 1, act = act)\n        self.SE = AttentionVanilla(self.inner_features, self.inner_features // 4, self.dev, attention_type = attention_type, act = act)\n        self.squeeze = ConvBlockVanilla(self.inner_features, self.in_features, 1, 0, 1, 1, act = act)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        if self.training and random.random() < self.stochastic_depth:\n            return x\n        expanded = self.expand(x)\n        processed = self.process(expanded)\n        SE = self.SE(processed)\n        squeezed = self.squeeze(SE)\n        return self.gamma * squeezed + (1 - self.gamma) * x","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Certain Blocks can actually more effective when the downsampling is in the middle, this needs special blocks\n# You can see this in NFNets, EffNets, and ResNets!\nclass BottleNeckDownSampler(pl.LightningModule):\n    def __init__(self, in_features, inner_features, out_features, stride, dev, attention_type = 'se', act = 'relu'):\n        # You can't exactly have a stochastic depth for this block.\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.out_features = out_features\n        self.stride = stride \n        self.dev = dev\n        \n        self.Squeeze = ConvBlockVanilla(self.in_features, self.inner_features, 1, 0, 1, 1, act = act)\n        self.Process = ConvBlockVanilla(self.inner_features, self.inner_features, 3, 1, self.inner_features, self.stride, act = act) \n        self.Expand = ConvBlockVanilla(self.inner_features, self.out_features, 1, 0, 1, 1, act = act )\n        self.SE = AttentionVanilla(self.out_features, self.out_features // 4, self.dev, attention_type = attention_type, act = act)\n        \n        self.pool = nn.AvgPool2d(kernel_size = 3, padding = 1, stride = self.stride)\n        self.pool_conv = ConvBlockVanilla(self.in_features, self.out_features, 1, 0, 1, 1, act = act)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        pooled = self.pool_conv(self.pool(x)) # Capture orig info\n        squeezed = self.Squeeze(x)\n        processed = self.Process(squeezed)\n        expand = self.Expand(processed)\n        excited = self.SE(expand)\n        \n        return excited * self.gamma + (1 - self.gamma) * pooled\nclass InverseBottleNeckDownSampler(pl.LightningModule):\n    def __init__(self, in_features, inner_features, out_features, stride, dev, attention_type = 'se', act = 'relu'):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.out_features = out_features\n        self.stride = stride\n        self.dev = dev\n        \n        self.Expand = ConvBlockVanilla(self.in_features, self.inner_features, 1, 0, 1, 1, act = act)\n        self.Process = ConvBlockVanilla(self.inner_features, self.inner_features, 3, 1, self.inner_features, self.stride, act = act)\n        self.SE = AttentionVanilla(self.inner_features, self.inner_features // 4, self.dev, attention_type = attention_type, act = act)\n        self.Squeeze = ConvBlockVanilla(self.inner_features, self.out_features, 1, 0, 1, 1, act = act)\n        \n        self.pool = nn.AvgPool2d(kernel_size = 3, padding = 1, stride = self.stride)\n        self.pool_conv = ConvBlockVanilla(self.in_features, self.out_features, 1, 0, 1, 1, act = act)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        pool = self.pool_conv(self.pool(x)) \n        expanded = self.Expand(x)\n        processed = self.Process(expanded)\n        SE = self.SE(processed)\n        squeezed = self.Squeeze(SE)\n        return squeezed * self.gamma + (1 - self.gamma) * pool","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Fast AI ","metadata":{}},{"cell_type":"code","source":"# FAST AI Abstractions\nclass ConvBlockFA(pl.LightningModule):\n    '''\n    ConvLayer + BN, all abstracted away\n    '''\n    def __init__(self, in_features, out_features, kernel_size, padding, groups, stride, transposed = False, activation = nn.SiLU):\n        super().__init__()\n        self.layer = fastai.ConvLayer(in_features, out_features, ks = kernel_size, padding = padding, groups = groups, stride = stride, act_cls = activation, transpose = transposed)\n    def forward(self, x):\n        return self.layer(x)\nclass SEFA(pl.LightningModule):\n    def __init__(self, in_features, inner_features):\n        super().__init__()\n        self.layer = fastai.SEModule(in_features, inner_features)\n    def forward(self, x):\n        return self.layer(x)\nclass SelfAttentionFA(pl.LightningModule):\n    def __init__(self, in_features):\n        super().__init__()\n        self.layer = fastai.SelfAttention(in_features)\n    def forward(self, x):\n        return self.layer(x)\nclass BottleNeckFA(pl.LightningModule):\n    def __init__(self, in_features, out_features, stochastic_depth = 0.2):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.stochastic_depth = stochastic_depth\n        self.layer = fastai.SEBlock(1, in_features, out_features, reduction = 4) # Squeeze Factor of 4.\n    def forward(self, x):\n        if self.training and random.random() < self.stochastic_depth:\n            return x\n        return self.layer(x)\nclass InverseBottleNeckFA(pl.LightningModule):\n    def __init__(self, in_features, out_features, stochastic_depth = 0.2):\n        super().__init__()\n        self.stochastic_depth = stochastic_depth\n        self.layer = fastai.SEBlock(2, in_features, out_features, reduction = 4, dw = True)\n    def forward(self, x):\n        if self.training and random.random() < self.stochastic_depth:\n            return x\n        return self.layer(x) ","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class SE(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev, framework = 'fastai'):\n        super().__init__()\n        self.framework = framework \n        if self.framework == 'fastai':\n            self.layer = SEFA(in_features, in_features)\n        else:\n            self.layer = SEVanilla(in_features, inner_features, dev)\n    def forward(self, x):\n        return self.layer(x)\nclass SelfAttention(pl.LightningModule):\n    def __init__(self, in_features, framework = 'fastai'):\n        super().__init__()\n        self.framework = framework\n        if self.framework == 'fastai':\n            self.layer = SelfAttentionFA(in_features)\n        else:\n            self.layer = SelfAttention(in_features)\n    def forward(self, x):\n        return self.layer(x)\nclass Attention(pl.LightningModule):\n    '''\n    Select Between SE or CBAM in one module.\n    '''\n    def __init__(self, in_features, inner_features, dev, framework = 'fastai', attention_type = 'se', act = 'relu'):\n        assert attention_type in ['se', 'cbam', 'self', 'none', 'se_attend', 'cbam_attend']\n        super().__init__()\n        self.framework = framework\n        if attention_type == 'none':\n            self.layer = nn.Identity()\n        elif self.framework == 'fastai':\n            if attention_type == 'se':\n                self.layer = SE(in_features, inner_features, dev, framework = framework)\n            else:\n                self.layer= SelfAttention(in_features, framework = framework)\n        else:\n            self.layer = AttentionVanilla(in_features, inner_features, dev, attention_type = attention_type, act = act)\n    def forward(self, x):\n        return self.layer(x)","metadata":{"scrolled":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Select Between FrameWorks","metadata":{}},{"cell_type":"code","source":"# FAST AI Abstractions\nclass ConvBlock(pl.LightningModule):\n    '''\n    ConvLayer + BN, all abstracted away\n    '''\n    def __init__(self, in_features, out_features, kernel_size, padding, groups, stride, transposed = False, activation = nn.SiLU, framework = 'fastai', act = 'relu'):\n        super().__init__()\n        self.framework = framework\n        if self.framework == 'fastai':\n            self.layer = ConvBlockFA(in_features, out_features, kernel_size, padding, groups, stride, transposed = transposed, activation = activation)\n        else:\n            self.layer = ConvBlockVanilla(in_features, out_features, kernel_size, padding, groups, stride, act = act)\n    def forward(self, x):\n        return self.layer(x)\n\nclass BottleNeck(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev, stochastic_depth = 0.2, framework = 'fastai', attention_type = 'se', act = 'relu'):\n        super().__init__()\n        self.framework = framework\n        if self.framework == 'fastai':\n            self.layer = BottleNeckFA(in_features, in_features, stochastic_depth = stochastic_depth)\n        else:\n            self.layer = BottleNeckVanilla(in_features, inner_features, dev, stochastic_depth = stochastic_depth, attention_type = attention_type, act = act) \n    def forward(self, x):\n        return self.layer(x)\nclass InverseBottleNeck(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev, stochastic_depth = 0.2, framework = 'fastai', attention_type= 'se', act = 'relu'):\n        super().__init__()\n        self.framework = framework\n        if self.framework == 'fastai':\n            self.layer = InverseBottleNeckFA(in_features, in_features, stochastic_depth = stochastic_depth)\n        else:\n            self.layer = InverseBottleNeckVanilla(in_features, inner_features, dev, stochastic_depth = stochastic_depth, attention_type = attention_type, act = act) \n    def forward(self, x):\n        return self.layer(x)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Resizing Module","metadata":{}},{"cell_type":"code","source":"class Resizer(pl.LightningModule):\n    '''\n    Resizes Images from 1024 x 1024 to 320 x 320 for the CNNs. Light CNN + Bilinear Interpolation(CNN should capture key information)\n    NO STOCHASTIC DEPTH here(its already a light model.)\n    '''\n    def __init__(self, out_size, dev, framework = 'fastai', attention_type = 'se', act = 'relu'):\n        super().__init__()\n        self.out_size = out_size\n        self.dev = dev\n        self.framework = framework\n        self.stochastic_depth = 0\n        # CNN Parts\n        \n        self.Initial = nn.Sequential(*[\n            ConvBlock(3, 8, 3, 1, 1, 1, framework = self.framework, act = act),\n            ConvBlock(8, 16, 1, 0, 1, 1, framework = self.framework, act = act )\n        ])\n        \n        self.Process = nn.Sequential(*[\n            BottleNeck(16, 4, self.dev, stochastic_depth = self.stochastic_depth, framework = self.framework, attention_type= attention_type, act = act) for i in range(1)\n        ])\n\n        self.proj = ConvBlock(16, 3, 3, 1, 1, 1, framework = self.framework, act = act)\n     \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        '''\n        X: Tensor(B, 3, 1024, 1024)\n        '''\n        resize = F.interpolate(x, size = (self.out_size, self.out_size))\n        \n        initial = self.Initial(x)\n        resized_conv = F.interpolate(initial, size = (self.out_size, self.out_size))\n        process = self.Process(resized_conv) + resized_conv\n        proj = self.proj(process)\n        return self.gamma * proj + (1 - self.gamma) * resize","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"BaseLine Model","metadata":{}},{"cell_type":"code","source":"class BaseLineResNet(pl.LightningModule):\n    '''\n    BaseLine ResNet-50D\n    '''\n    def freeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = False\n    def unfreeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = True\n    def increase_drop_prob(self):\n        self.drop_prob += self.increase_dropout\n    def increase_stochasticity(self):\n        self.cur_stochastic += self.stochastic_increase\n    def __init__(self, num_classes, dev, increase_dropout = 0.1, framework = 'fastai', stochastic_depth = False, act = 'relu'):\n        super().__init__()\n        self.num_classes = num_classes\n        self.dev = dev\n        self.framework = framework\n        self.stochastic_depth = stochastic_depth\n        # HYPER PARAMETER ------------------------------------\n        self.model_name = 'resnet50d'\n        self.increase_dropout = increase_dropout\n        self.drop_prob = 0\n        if not self.stochastic_depth:\n            self.cur_stochastic = 0\n            self.stochastic_increase = 0\n        else:\n            self.cur_stochastic = 0\n            self.stochastic_increase = 0.1\n        self.attention_type = 'se'\n        # END OF HYPER PARAMETERS ----------------------------\n        \n        # Pretrained Model\n        self.model = timm.create_model(self.model_name, pretrained = True)\n        # Extract Layers\n        self.conv1 = self.model.conv1 # (64)\n        self.bn1 = self.model.bn1\n        self.act1 = self.model.act1\n        self.pool = self.model.maxpool\n        \n        self.layer1 = self.model.layer1 # (256)\n        self.layer2 = self.model.layer2 # (512)\n        self.layer3 = self.model.layer3 # (1024)\n        self.layer4 = self.model.layer4 # we won't use this layer, it's too computationally expensive and doesn't fully use the sizes.\n        \n        # Freeze Initial Layers\n        self.freeze([self.conv1, self.bn1, self.layer1, self.layer2])  \n        # Custom Layers\n        \n        self.DropoutLayer2 = nn.Dropout2d(self.drop_prob)\n        self.AttentionLayer2 = Attention(512, 128, self.dev, attention_type = self.attention_type, act = act, framework = self.framework) \n        self.increase_drop_prob()\n        self.DropoutLayer3 = nn.Dropout2d(self.drop_prob)\n        self.AttentionLayer3 = Attention(1024, 256, self.dev, attention_type = self.attention_type, act = act, framework = self.framework)\n        self.increase_drop_prob()\n        self.DropoutLayer4 = nn.Dropout2d(self.drop_prob)\n        self.AttentionLayer4 = Attention(1256, 320, self.dev, attention_type = self.attention_type, act = act, framework = self.framework)\n        self.increase_drop_prob()\n        def add_layer(x):\n            self.increase_stochasticity()\n            return x\n        self.layer4 = nn.Sequential(*[\n            BottleNeckDownSampler(1024, 256, 1256, 2, self.dev, attention_type = self.attention_type, act = act)\n        ] + [\n            add_layer(BottleNeck(1256, 320, self.dev, stochastic_depth = self.stochastic_depth, framework = self.framework, attention_type = self.attention_type, act = act)) for i in range(3) \n        ])\n        \n        \n        self.layer5 = nn.Sequential(*[\n            BottleNeckDownSampler(1256, 320, 1536, 2, self.dev, attention_type = self.attention_type, act = act)\n        ] + [\n            add_layer(BottleNeck(1536, 512, self.dev, stochastic_depth = self.stochastic_depth, framework = self.framework, attention_type = self.attention_type, act = act)) for i in range(2)\n        ])\n        \n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.increase_drop_prob()\n        self.DropoutFinal = nn.Dropout(self.drop_prob)\n        self.Linear = nn.Linear(1536, self.num_classes)\n        \n    def forward(self, x):\n        '''\n        BaseLine(BN) resnet Model\n        '''\n        features0 = self.pool(self.bn1(self.act1(self.conv1(x)))) # (B, 64, 160, 160)\n        layer1 = self.layer1(features0) # (B, 256, 80, 80)\n        layer2 = self.layer2(layer1) # (B, 512, 40, 40)\n        # Attention2\n        layer2 = self.DropoutLayer2(layer2)\n        layer2 = self.AttentionLayer2(layer2)\n        \n        layer3 = self.layer3(layer2) # (B, 1024, 20, 20)\n        # Attention3\n        layer3 = self.DropoutLayer3(layer3)\n        layer3 = self.AttentionLayer3(layer3)\n        \n        layer4 = self.layer4(layer3) # (B, 1256, 10, 10) \n        # Attention4\n        layer4 = self.DropoutLayer4(layer4)\n        layer4 = self.AttentionLayer4(layer4)\n        \n        layer5 = self.layer5(layer4) # (B, 1536, 5, 5) \n        # Avg Pool\n        avg_pool = torch.squeeze(self.global_avg(layer5))\n        dropped = self.DropoutFinal(avg_pool)\n        return self.Linear(dropped)\n        \n        \n\nclass BaseLineEffNet(pl.LightningModule):\n    '''\n    BaseLine EffNet-b4\n    '''\n    def freeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = False\n    def unfreeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = False\n    def increase_stochasticity(self):\n        '''\n        Increases the Factor of Stochastic Depth.\n        '''\n        self.cur_stochastic += self.stochastic_increase\n    def increase_drop_prob(self):\n        self.drop_prob += self.increase_dropout\n    def __init__(self, num_classes, dev, increase_dropout = 0.2, framework = 'fastai', stochastic_depth = False, act = 'silu'):\n        super().__init__()\n        self.framework = framework\n        self.dev = dev\n        self.num_classes = num_classes\n        self.stochastic_depth = stochastic_depth\n        \n        # HYPER PARAMETERS -----------------------------------\n        self.drop_prob = 0\n        self.increase_dropout = increase_dropout\n        self.model_name = 'tf_efficientnet_b4_ns'\n        self.attention_type = 'se'\n        if self.stochastic_depth == False:\n            self.cur_stochastic = 0.0\n            self.stochastic_increase = 0.0\n        else:\n            self.cur_stochastic = 0.2\n            self.stochastic_increase = 0.1\n        # END OF HYPER PARAMETERS ----------------------------\n        \n        self.model = timm.create_model(self.model_name, pretrained = True)\n        # Extract Layers \n        self.conv1 = self.model.conv_stem\n        self.bn1 = self.model.bn1\n        self.act1 = self.model.act1\n        \n        self.block0 = self.model.blocks[0]\n        self.block1 = self.model.blocks[1]\n        self.block2 = self.model.blocks[2]\n        self.block3 = self.model.blocks[3]\n        self.block4 = self.model.blocks[4]\n        self.block5 = self.model.blocks[5]\n        self.block6 = self.model.blocks[6]\n        # Freeze Layers\n        self.freeze([self.conv1, self.bn1, self.block0, self.block1, self.block2])\n        # Custom Layers\n        self.Dropout0 = nn.Dropout2d(self.drop_prob)\n        self.increase_drop_prob()\n        self.Attention0 = Attention(56, 16, self.dev, attention_type = self.attention_type, act = act, framework = self.framework) \n        \n        self.Dropout1 = nn.Dropout2d(self.drop_prob)\n        self.increase_drop_prob()  \n        self.Attention1 = Attention(160, 48, self.dev, attention_type = self.attention_type, act = act, framework = self.framework)\n        self.Dropout2 = nn.Dropout2d(self.drop_prob)\n        self.increase_drop_prob()\n        self.Attention2 = Attention(448, 128, self.dev, attention_type = self.attention_type, act = act, framework = self.framework )\n        \n        def add_block():\n            self.increase_stochasticity()\n            return InverseBottleNeck(512, 1024, self.dev, stochastic_depth = self.cur_stochastic, framework = self.framework, attention_type = self.attention_type, act = act)\n        self.block7 = nn.Sequential(*[\n            InverseBottleNeckDownSampler(448, 1536, 512, 2, self.dev, attention_type = self.attention_type, act = act)\n        ] + [\n            add_block() for i in range(3)\n        ])\n        self.proj = ConvBlock(512, 1536, 1, 0, 1, 1, framework = self.framework, act =act)\n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.increase_drop_prob()\n        self.Final_Drop = nn.Dropout(self.drop_prob)\n        self.Linear = nn.Linear(1536, self.num_classes)\n    def forward(self, x):\n        features0 = self.bn1(self.act1(self.conv1(x))) # (48, 160, 160)\n        block0 = self.block0(features0) # (B, 24, 160, 160)\n        block1 = self.block1(block0) # (B, 32, 80, 80)\n        block2 = self.block2(block1) # (B, 56, 40, 40)\n        # Attention0\n        block2 = self.Dropout0(block2)\n        block2 = self.Attention0(block2)\n        \n        block3 = self.block3(block2) # (B, 112, 20, 20)\n        block4 = self.block4(block3) # (B, 160, 20, 20)\n        # Attention1\n        block4 = self.Dropout1(block4)\n        block4 = self.Attention1(block4)\n        \n        block5 = self.block5(block4) # (B, 272, 10, 10)\n        block6 = self.block6(block5) # (B, 448, 10, 10)\n        # Attention2 \n        block6 = self.Dropout2(block6)\n        block6 = self.Attention2(block6) \n        \n        # Custom Layer7\n        block7 = self.block7(block6)\n        proj = self.proj(block7)\n        # Global Average\n        global_avg = torch.squeeze(self.global_avg(proj))\n        global_avg = self.Final_Drop(global_avg)\n        return self.Linear(global_avg)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class BaseLineMobileNet(pl.LightningModule):\n    def freeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = False\n    def unfreeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = True\n    def __init__(self, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.model_name = 'mobilenetv3_large_100'\n        self.model = timm.create_model(self.model_name, pretrained = True)\n        \n        # Block Extraction\n        self.conv1 = self.model.conv_stem\n        self.bn1 = self.model.bn1\n        self.act1 = self.model.act1\n        \n        self.block0 = self.model.blocks[0]\n        self.block1 = self.model.blocks[1]\n        self.block2 = self.model.blocks[2]\n        self.block3 = self.model.blocks[3]\n        self.block4 = self.model.blocks[4]\n        self.block5 = self.model.blocks[5]\n        self.block6 = self.model.blocks[6]\n        \n        #self.freeze([self.conv1, self.bn1, self.block0, self.block1, self.block2, self.block3, self.block4, self.block5, self.block6])\n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(960, self.num_classes)\n    def forward(self, x):\n        features0 = self.bn1(self.act1(self.conv1(x)))\n        block0 = self.block0(features0)\n        block1 = self.block1(block0)\n        block2 = self.block2(block1)\n        block3 = self.block3(block2)\n        block4 = self.block4(block3)\n        block5 = self.block5(block4)\n        block6 = self.block6(block5)\n        avg = torch.squeeze(self.global_avg(block6))\n        return self.fc(avg)\n        ","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# ARCFACE MODULE, Trying to differentiate between samples.","metadata":{}},{"cell_type":"code","source":"class ArcFaceModule(pl.LightningModule):\n    '''\n    Given some model, it takes the logits, and manipulates them to add a margin and make the difference between samples larger.\n    \n    Different actions at test and train time.\n    \n    Experimental, it didn't work too great.\n    '''\n    def __init__(self, model, num_classes):\n        super().__init__()\n        self.model = model\n        self.num_classes = num_classes\n        self.Linear = nn.Linear(self.num_classes, self.num_classes, bias = False)\n        self.margin = 0.2 # about 10 degrees away in radians(7700 classes is a lot, so margins cant be too large)\n        self.eps = 1e-7\n    def forward_train(self, x, y):\n        logits = self.model(x)\n        # Extract Weights and Normalize\n        weights = F.normalize(self.Linear.weight)\n        norm_logits = F.normalize(logits)\n        \n        cos = F.linear(norm_logits, weights, bias = None)\n        # Clip to prevent numeric stability errors\n        cos = cos.clip(-1 + self.eps, 1 - self.eps)\n        arccos = cos.arccos()\n        \n        # Add Margin\n        arccos = arccos + F.one_hot(y, num_classes = self.num_classes) * self.margin\n        # Convert back to cos\n        cos = arccos.cos()\n        return logits, F.cross_entropy(cos, y)\n    def forward(self, x):\n        return self.model(x)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"BaseLine Training code with PyTorch Lightning:","metadata":{}},{"cell_type":"code","source":"class BaseLineOptimConfig:\n    optimizer = 'adam'\n    act = 'relu'\n    weight_decay = 1e-3\n    lr = 3e-4\n    eta_min = 1e-7 # Cosine Annealing LR\n    num_steps = 5 # StepLR and Cosine Annealing LR\n     \n    step = 0.95 # StepLR\n    model_type = 'baseline'","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Training Code","metadata":{}},{"cell_type":"code","source":"class PyTorchLightningBaseLineQT(pl.LightningModule):\n    def __init__(self, num_classes, dev, fold_num = 0):\n        super().__init__()\n        self.num_classes = num_classes\n        self.dev = dev\n        self.fold_num = fold_num\n        # HYPERPARAMETERS ----------------------------\n        self.framework = 'pytorch' # Fast AI's implementation ironically takes 2GB more memory.\n        self.increase_dropout = 0.0\n        self.stochastic_depth = False\n        self.learning_rate = BaseLineOptimConfig.lr\n        # END OF HYPERPARAMETERS ---------------------\n        self.liveloss = livelossplot.PlotLosses()\n        # Send Model to Device\n        self.model = self.configure_model()\n        self.optim = self.configure_optimizers()[0]\n        self.to(self.dev)\n        # Internal States\n        self.bestValLoss = float('inf')\n        self.bestValAcc = 0\n        # Per Epoch States\n        self.trainLoss = 0\n        self.valLoss = 0\n        self.trainAcc = 0\n        self.valAcc = 0\n        \n        self.trainCount = 0\n        self.valCount = 0\n        self.curEpoch = 0\n    def inference(self, x):\n        self.eval()\n        with torch.no_grad():\n            return F.softmax(self.model(x))\n    def forward(self, x):\n        return self.model(x)\n    def configure_optimizers(self):\n        '''\n        Loads Optimizers and LR_scheduler for the model.\n        '''\n        # Creates an Optimizer for the model \n        if BaseLineOptimConfig.optimizer == 'ranger':\n            # Ranger(Radam + Lookahead)\n            optimizer = Ranger(self.parameters(), lr = self.learning_rate, weight_decay = BaseLineOptimConfig.weight_decay)\n        else:\n            # Adam\n            optimizer = optim.Adam(self.parameters(), lr = self.learning_rate, weight_decay = BaseLineOptimConfig.weight_decay)\n        # Load in LR_Scheduler\n        self.lr_decay = optim.lr_scheduler.CosineAnnealingLR(optimizer, BaseLineOptimConfig.num_steps, eta_min = BaseLineOptimConfig.eta_min)\n            \n        # Load in Second LR Scheduler\n        self.lr_decay2 =  optim.lr_scheduler.StepLR(optimizer, BaseLineOptimConfig.num_steps, BaseLineOptimConfig.step)\n            \n        return [optimizer]\n    def configure_model(self):\n        '''\n        Loads a New Model\n        '''\n        if BaseLineOptimConfig.model_type == 'resnet':\n            model = BaseLineResNet(self.num_classes, self.dev, act = BaseLineOptimConfig.act, increase_dropout = self.increase_dropout, framework = self.framework, stochastic_depth = self.stochastic_depth)\n        elif BaseLineOptimConfig.model_type == 'baseline':\n            model = BaseLineMobileNet(self.num_classes)\n        else:\n            model = BaseLineEffNet(self.num_classes, self.dev, act = BaseLineOptimConfig.act, increase_dropout = self.increase_dropout, framework = self.framework, stochastic_depth = self.stochastic_depth)\n        model = ArcFaceModule(model, self.num_classes) \n        return model\n    def accuracy(self, y_pred, y_true):\n        '''\n        y_pred: Tensor(B, C)\n        y_true: Tensor(B)\n        Accuracy From Logits\n        '''\n        # Argmax\n        B, C = y_pred.shape\n        _, y_logits = torch.max(F.softmax(y_pred), dim = -1)\n        acc = torch.sum((y_logits == y_true).int()) / B\n        return acc\n        \n    def training_step(self, train_batch, batch_idx):\n        '''\n        One Training Step\n        '''\n        x, y = train_batch\n        # Send Data to GPU\n        x = x.to(self.dev)\n        y = y.to(self.dev)\n        \n        logits, loss = self.model.forward_train(x, y)\n        \n        acc = self.accuracy(logits, y)\n\n        # Log the data for LiveLossPlot\n        print(f\"STEP: {batch_idx}, L: {loss.item()}, A: {acc.item()}\")\n        self.trainLoss += loss.item()\n        self.trainAcc += acc.item()\n        self.trainCount += 1\n        if batch_idx % 100 == 0:\n            self.lr_decay.step()\n            self.lr_decay2.step()\n        del x, y, acc\n        return loss\n        \n    def validation_step(self, val_batch, batch_idx):\n        '''\n        One Validation Step\n        '''\n        x, y = val_batch\n        # Send Data to GPU\n        x = x.to(self.dev)\n        y = y.to(self.dev)\n        pred, loss = self.model.forward_train(x)\n        acc = self.accuracy(pred, y)\n        # Logs For Early Stopping\n        self.log('val_loss', loss.item())\n        self.log('val_acc', acc.item())\n        # Logs for Validation end\n        self.valLoss += loss.item()\n        self.valAcc += acc.item()\n        self.valCount += 1\n        del x, y, pred, loss, acc\n    def update_states(self):\n        # Per Epoch States\n        self.trainLoss = 0\n        self.valLoss = 0\n        self.trainAcc = 0\n        self.valAcc = 0\n        \n        self.trainCount = 0\n        self.valCount = 0\n        self.curEpoch += 1\n    def create_logs(self):\n        '''\n        Creates Logs for LiveLossPlot\n        '''\n        logs = {}\n        logs['loss'] = self.trainLoss\n        logs['val_loss'] = self.valLoss\n        logs['accuracy'] = self.trainAcc\n        logs['val_accuracy'] = self.valAcc\n        return logs\n    def saveBest(self):\n        '''\n        If this is a best model, saves the state dictionaries\n        '''\n        if self.valLoss < self.bestValLoss:\n            self.bestValLoss = self.valLoss\n            torch.save(self.state_dict(), f'./fold_{self.fold_num}_loss.pth')\n        elif self.valAcc > self.bestValAcc:\n            self.bestValAcc = self.valAcc\n            torch.save(self.state_dict(), f\"./fold_{self.fold_num}_acc.pth\")\n    def training_epoch_end(self, outputs):\n        self.lr_decay.step()\n        self.lr_decay2.step()\n    def validation_epoch_end(self, outputs):\n        '''\n        Logs all data to livelossplot and saves models when necessary(Improvement)\n        '''\n        # Divide Losses to get a per Step loss\n        if self.valCount != 0:\n            self.valLoss /= self.valCount\n            self.valAcc /= self.valCount\n        if self.trainCount != 0:\n            self.trainLoss /= self.trainCount\n            self.trainAcc /= self.trainCount\n        # Round Values\n        self.valLoss = round(self.valLoss, 3) \n        self.valAcc = round(self.valAcc, 3)\n        \n        self.trainLoss = round(self.trainLoss, 3)\n        self.trainAcc = round(self.trainAcc, 3) # Round for cleaner Numbes\n        \n        # Update LiveLossPlot\n        logs = self.create_logs()\n        self.liveloss.update(logs)\n        self.liveloss.send()\n        # best state dict?\n        self.saveBest()\n        # Print Logs:\n        print(f\"E {self.curEpoch}, BL: {self.bestValLoss}, BA: {self.bestValAcc}, L:{self.trainLoss}, A: {self.trainAcc}, VL: {self.valLoss}, VA: {self.valAcc}\")\n        # Clear States\n        self.update_states()\n    def training_loop(self, trainloader, NUM_EPOCHS):\n        for EPOCH in range(NUM_EPOCHS):\n            self.train()\n            for idx, (images, labels) in enumerate(trainloader):\n                self.optim.zero_grad()\n                loss = self.training_step((images, labels), idx) \n                loss.backward()\n                self.optim.step()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Train Initial Network ","metadata":{}},{"cell_type":"code","source":"def construct_new(fold_idx, load_prev = None):\n    model = PyTorchLightningBaseLineQT(Config.NUM_CLASSES, Config.device, fold_idx)\n    if load_prev:\n        model.load_state_dict(torch.load(f'{load_prev}fold_{fold_idx}_loss.pth', map_location = Config.device))\n    # Create Trainer\n    early_stopping = []\n    \n    trainer = pl.Trainer(max_epochs = Config.NUM_EPOCHS, checkpoint_callback = False, logger = None, check_val_every_n_epoch = 1, gpus = 1, num_sanity_val_steps = 0, callbacks = early_stopping, benchmark = False, deterministic = True, precision = 16)\n    return model, trainer\ndef MultiFoldTrainPL(NUM_SPLITS):\n    for fold_idx in range(NUM_SPLITS):\n        train, val = dataModule.get_both(fold_idx)\n        model = PyTorchLightningBaseLineQT(Config.NUM_CLASSES, Config.device, fold_idx)\n        model.training_loop(train, val, Config.NUM_EPOCHS)\ndef BaseLineMultiFoldTrain(fold_idx, load_prev = None):\n    train_loader, val_loader = dataModule.get_both(fold_idx)\n    # Create New Model\n    model, trainer = construct_new(fold_idx, load_prev = load_prev)\n    trainer.fit(model, train_loader, val_loader)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#pl.seed_everything()\n#print(BaseLineMultiFoldTrain(0, load_prev = None))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# NFNet Blocks from Scratch","metadata":{}},{"cell_type":"code","source":"class ScaledReLU(pl.LightningModule):\n    '''\n    Scaled ReLU block, used to reduce the size of activations after a NFBlock.\n    \n    Decided sort of arbitrarily from the paper writers. Scale by constant: (math.sqrt(2 / (1 - (1 / pi))))\n    '''\n    def __init__(self):\n        super().__init__()\n        self.act1 = nn.ReLU(inplace = True)\n        self.constant = math.sqrt(2 / (1 - (1 / math.pi)))\n    def forward(self, x):\n        return self.act1(x) * self.constant # Scale Down Magnitude of RELU Activation\n\nclass WSConv(pl.LightningModule):\n    '''\n    Weight Standardized Convolutional Block\n    '''\n    def __init__(self, in_features, out_features, kernel_size, padding, groups, stride):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.kernel_size = kernel_size\n        self.padding = padding\n        self.groups = groups\n        self.stride = stride\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size = kernel_size, padding = padding, groups = groups, stride = stride)\n    def forward(self, x):\n        '''\n        Simply Standardizes the Weights before applying Conv2d.\n        '''\n        out_cn, A, B, C = self.conv.weight.shape\n        norm_weights = self.conv.weight#F.layer_norm(self.conv.weight, (A, B, C))\n        return F.conv2d(x, weight = norm_weights, bias = self.conv.bias, stride = self.stride, padding = self.padding, groups = self.groups)\nclass WSConvBlock(pl.LightningModule):\n    '''\n    Encloses all Parts related to Weight-Standardized Convolutions and Scaled RELU\n    \n    No BatchNorm Here!\n    '''\n    def __init__(self, in_features, out_features, kernel_size, padding, groups, stride, activation = True):\n        super().__init__()\n        self.conv = WSConv(in_features, out_features, kernel_size, padding, groups, stride)\n        self.act1 = ScaledReLU()\n    def forward(self, x):\n        return self.act1(self.conv(x))\n\nclass ScaledSE(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.dev = dev\n        \n        self.Squeeze = nn.Linear(self.in_features, self.inner_features)\n        self.act1 = ScaledReLU()\n        self.Excite = nn.Linear(self.inner_features, self.in_features)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        mean = torch.mean(x, dim = -1)\n        mean = torch.mean(mean, dim = -1)\n        squeezed = self.act1(self.Squeeze(mean))\n        excited = torch.sigmoid(self.Excite(squeezed)).unsqueeze(-1).unsqueeze(-1)\n        return excited * x * self.gamma + x * (1 - self.gamma) \n    \nclass ScaledCBAM(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features \n        self.dev = dev\n    \n        self.Squeeze = nn.Linear(self.in_features, self.inner_features) \n        self.act1 = ScaledReLU()\n        self.Excite = nn.Linear(self.inner_features, self.in_features)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        mean = torch.mean(x, dim = -1)\n        mean = torch.mean(mean, dim = -1)\n        max_pooled, _ = torch.max(x, dim = -1)\n        max_pooled, _ = torch.max(max_pooled, dim = -1)\n        \n        squeeze_mean = self.act1(self.Squeeze(mean))\n        excite_mean = self.Excite(squeeze_mean)\n        \n        squeeze_max = self.act1(self.Squeeze(max_pooled))\n        excite_max = self.Excite(squeeze_max) \n        \n        excite = torch.sigmoid((excite_max + excite_mean) / 2).unsqueeze(-1).unsqueeze(-1)\n        return excite * x * self.gamma + x * (1 - self.gamma)\nclass ScaledAttention(pl.LightningModule):\n    def __init__(self, in_features, inner_features, dev, attention_type = 'se'):\n        super().__init__()\n        self.attention_type = attention_type\n        assert self.attention_type in ['se', 'cbam']\n        if self.attention_type == 'se':\n            self.layer = ScaledSE(in_features, inner_features, dev)\n        else:\n            self.layer = ScaledCBAM(in_features, inner_features, dev)\n    def forward(self, x):\n        return self.layer(x)","metadata":{"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"class NFBlock(pl.LightningModule):\n    '''\n    Replaces the Need for a BottleNeck Block, effectively a InverseBottleNeck with a variety of other tricks to replace BN.\n    '''\n    def __init__(self, in_features, inner_features, dev, layer_num = 0, attention_type = 'se', stochastic_depth = 0.2):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.dev = dev\n        self.attention_type = attention_type\n        self.layer_num = layer_num\n        self.stochastic_depth = stochastic_depth\n        \n        # Parameters\n        self.alpha = 0.2 \n        self.beta = math.sqrt(1 + self.layer_num * self.alpha ** 2)\n        # Custom Layers\n        self.expand = WSConvBlock(self.in_features, self.inner_features, 1, 0, 1, 1)\n        self.dw = WSConvBlock(self.inner_features, self.inner_features, 3, 1, self.inner_features, 1) \n        self.squeeze = WSConvBlock(self.inner_features, self.in_features, 1, 0, 1, 1)\n        self.SE = ScaledAttention(self.in_features, self.in_features // 4, self.dev, attention_type = self.attention_type)\n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        # Stochastic Depth\n        if self.training and random.random() < self.stochastic_depth:\n            return x\n        # Scale Down the Initial value to reduce to unit-variance\n        x = x / self.beta\n        \n        expand = self.expand(x)\n        dw = self.dw(expand)\n        squeeze = self.squeeze(dw)\n        SE = self.SE(squeeze) * self.alpha\n        return self.gamma * SE + (1 - self.gamma) * x      ","metadata":{"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"class NFDownsamplerBlock(pl.LightningModule):\n    def __init__(self, in_features, inner_features, out_features, stride, dev, layer_num = 0, attention_type = 'se'):\n        super().__init__()\n        self.in_features = in_features\n        self.inner_features = inner_features\n        self.out_features = out_features\n        self.stride = stride\n        self.dev = dev\n        self.layer_num = layer_num\n        self.attention_type = attention_type\n        \n        # Scaling Params\n        self.alpha = 0.2\n        self.beta = math.sqrt(1 + self.layer_num * self.alpha ** 2) \n    \n        # Custom Layers \n        self.pool = nn.AvgPool2d(kernel_size = 3, padding = 1, stride = self.stride)\n        self.conv_pool = WSConvBlock(self.in_features, self.out_features, 1, 0, 1, 1)\n        \n        self.expand = WSConvBlock(self.in_features, self.inner_features, 1, 0, 1, 1)\n        self.dw = WSConvBlock(self.inner_features, self.inner_features, 3, 1, self.inner_features, self.stride)\n        self.squeeze = WSConvBlock(self.inner_features, self.out_features, 1, 0, 1, 1)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        # Scale Down Activation\n        x = x / self.beta\n    \n        pool = self.conv_pool(self.pool(x))\n        \n        expand = self.expand(x)\n        dw = self.dw(expand)\n        squeeze = self.squeeze(dw)\n        return (self.gamma * squeeze + (1 - self.gamma) * pool) * self.alpha","metadata":{"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Normalizer-Free Resizer \nclass NFResizer(pl.LightningModule):\n    def __init__(self, out_size, dev):\n        super().__init__()\n        self.out_size = out_size\n        self.dev = dev\n        # HYPER PARAMETERS ----------------------\n        self.stochastic_depth = 0 \n        self.attention_type = 'se'\n        # END OF HYPER PARAMETERS ---------------\n        self.initial = nn.Sequential(*[\n            WSConvBlock(3, 8, 3, 1, 1, 1),\n            WSConvBlock(8, 16, 1, 0, 1, 1)\n        ])\n        \n        self.process = nn.Sequential(*[\n            NFBlock(16, 32, self.dev, layer_num = i, attention_type = self.attention_type, stochastic_depth = self.stochastic_depth) for i in range(1)\n        ])\n        self.proj = WSConvBlock(16, 3, 3, 1, 1, 1)\n        \n        self.gamma = nn.Parameter(torch.zeros((1), device = self.dev))\n    def forward(self, x):\n        '''\n        Normalizer Free Resizer Module(To preserve information from 1024x1024 images and try to autoencode them into 320x320)\n        '''\n        # Standard Resize\n        resize = F.interpolate(x, size= (self.out_size, self.out_size), mode = 'bilinear')\n        \n        initial = self.initial(x)\n        resized_initial= F.interpolate(initial, size = (self.out_size, self.out_size), mode = 'bilinear')\n        process = self.process(resized_initial)\n        proj = self.proj(process)\n        \n        return proj * self.gamma + (1 - self.gamma) * resize","metadata":{"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"class ModifiedNFNet_f0(pl.LightningModule):\n    '''\n    Modifies and Transfer Learns on the NFNet_f0(13 M parameters pretrained, 3M from scratch\n    Heavily Modified to reduce memory and make it feasibly trainable.\n    '''\n    def freeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = False\n    def unfreeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = False \n    def increase_drop_prob(self):\n        self.drop_prob += self.increase_dropout\n    def increase_layer_num(self):\n        self.initial_layer_num += 1\n    def increase_stochasticity(self):\n        self.start_stochastic += self.increase_stochastic\n    def __init__(self, num_classes, dev, increase_dropout = 0.1, attention_type = 'se', stochastic_depth = False):\n        super().__init__()\n        self.num_classes = num_classes\n        self.dev = dev \n        self.drop_prob = 0\n        self.increase_dropout= increase_dropout\n        self.attention_type = attention_type\n        self.stochastic_depth = stochastic_depth\n        # HYPER PARAMETERS -----------------------\n        if self.stochastic_depth:\n            self.start_stochastic = 0\n            self.increase_stochastic = 0.05 # Each layer, stochasticity increases to reduce param sizes.\n        else:\n            self.start_stochastic = 0\n            self.increase_stochastic = 0.00\n        # END OF HYPER PARAMETERS ----------------\n        self.model_name = 'dm_nfnet_f0'\n        self.model = timm.create_model(self.model_name, pretrained = True) \n        # Extract Layers\n        self.stem = self.model.stem # (B, 128, 160, 160)\n        self.layer1 = self.model.stages[0] # (B, 256, 80, 80)\n        self.layer2 = self.model.stages[1] # (B, 512, 40, 40)\n        #self.freeze([ self.stem, self.layer1, self.layer2])\n        # Custom Layers\n        self.initial_layer_num = 3 # 4th layer in NFNet(3 0-based counting)\n        \n        def add_layer(x):\n            # Returns x, but increments layer num and stochasticity.\n            self.increase_layer_num()\n            self.increase_stochasticity()\n            return x\n        def add_layer_no_stoc(x):\n            self.increase_layer_num()\n            return x\n        self.Attention2 = ScaledAttention(512, 128, self.dev, attention_type = self.attention_type)\n        self.Dropout2 = nn.Dropout2d(self.drop_prob)\n        self.increase_drop_prob()\n        \n        self.layer3 = nn.Sequential(*[\n            add_layer_no_stoc(NFDownsamplerBlock(512, 768, 640, 2, self.dev, layer_num = self.initial_layer_num, attention_type = self.attention_type))\n        ] + [\n            add_layer(NFBlock(640, 768, self.dev, layer_num = self.initial_layer_num, attention_type = self.attention_type, stochastic_depth = self.start_stochastic)) for i in range(5)\n        ])\n        self.Attention3 = ScaledAttention(640, 196, self.dev, attention_type = self.attention_type)\n        self.Dropout3 = nn.Dropout2d(self.drop_prob)\n        self.increase_drop_prob()\n        \n        self.layer4 = nn.Sequential(*[\n          add_layer_no_stoc(NFDownsamplerBlock(640, 1024, 768, 2, self.dev, layer_num = self.initial_layer_num, attention_type = self.attention_type))  \n        ] + [\n            add_layer(NFBlock(768, 1024, self.dev, layer_num = self.initial_layer_num, attention_type = self.attention_type, stochastic_depth = self.start_stochastic)) for i in range(3) \n        ])\n        self.Attention4 = ScaledAttention(768, 256, self.dev, attention_type = self.attention_type)\n        self.Dropout4 = nn.Dropout2d(self.drop_prob)\n        self.increase_drop_prob()\n        \n        self.layer5 = nn.Sequential(*[\n            add_layer_no_stoc(NFDownsamplerBlock(768, 1256, 1024, 2, self.dev, layer_num = self.initial_layer_num, attention_type = self.attention_type))\n        ] + [\n            add_layer(NFBlock(1024, 1536, self.dev, layer_num = self.initial_layer_num, attention_type = self.attention_type, stochastic_depth = self.start_stochastic)) for i in range(2)\n        ])\n        self.proj = WSConvBlock(1024, 2048, 1, 0, 1, 1)\n        \n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.increase_drop_prob()\n        self.FinalDropout = nn.Dropout(self.drop_prob)\n        self.Linear = nn.Linear(2048, self.num_classes)\n        del self.model\n        \n    def forward(self, x):\n        stem = self.stem(x) # (B, 128, 160, 160)\n        layer1 = self.layer1(stem) # (B, 256, 80, 80)\n        layer2 = self.layer2(layer1) # (B, 512, 40, 40)\n        # Attention 2\n        layer2 = self.Dropout2(layer2)\n        layer2 = self.Attention2(layer2) # (B, 512, 40, 40)\n        \n        layer3 = self.layer3(layer2) # (B, 768, 20, 20)\n        # Attention 3\n        layer3 = self.Dropout3(layer3)\n        layer3 = self.Attention3(layer3)\n        \n        layer4 = self.layer4(layer3)\n        # Attention 4\n        layer4 = self.Dropout4(layer4)\n        layer4 = self.Attention4(layer4)\n        \n        layer5 = self.layer5(layer4)\n        proj = self.proj(layer5)\n        # Pool\n        pooled = torch.squeeze(self.FinalDropout(self.global_avg(proj)))\n        return self.Linear(pooled)","metadata":{"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# BaseLine Model For Debugging, Pure Transfer Learned\nclass BaseLineNFNet(pl.LightningModule):\n    def freeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = False\n    def unfreeze(self, layers):\n        for layer in layers:\n            for parameter in layer.parameters():\n                parameter.requires_grad = True\n    def __init__(self, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.model_name = 'dm_nfnet_f0'\n        self.model = timm.create_model(self.model_name, pretrained = True)\n        \n        # Extract Layers\n        self.stem = self.model.stem\n        self.stage0 = self.model.stages[0]\n        self.stage1 = self.model.stages[1]\n        self.stage2 = self.model.stages[2]\n        \n        # Freeze(Optional) Layers\n        self.freeze([self.stem, self.stage0])\n        # Custom Layers\n        self.proj = WSConv(1536, 3072, 3, 1, 1, 1)\n        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n    \n        self.Linear = nn.Linear(3072, self.num_classes)\n        del self.model\n    def forward(self, x):\n        features0 = self.stem(x)\n        stage0 = self.stage0(features0)\n        stage1 = self.stage1(stage0)\n        stage2 = self.stage2(stage1)\n        \n        proj = self.proj(stage2)\n        avg = torch.squeeze(self.global_avg(proj))\n        return self.Linear(avg)\n        ","metadata":{"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"class AdaptiveGradientClipping(optim.Optimizer):\n    '''\n    Custom Optimizer to Clip Gradients on All Layers except for the FC.\n    '''\n    def unitnorm(self, x):\n        '''\n        Computes the unit norm of a vector\n        \n        Computes the norm over every dim but the first\n        '''\n        if x.ndim <= 1:\n            # Scalar or Tensor of shape (B), dont keep dim, just return a scalar\n            dim = [0]\n            keep_dim = False\n        else:\n            dim = [i + 1 for i in range(len(x.shape) - 1)]\n            keep_dim = True\n        x = x ** 2\n        for d in dim:\n            x = torch.sum(x, dim = d).unsqueeze(d)\n        return x ** 0.5\n         \n    def __init__(self, model, optim, clip_limit = 1e-2, eps = 1e-5, ignore = \"fc\"):\n        self.model = model \n        self.optim = optim\n        self.clip_limit = clip_limit\n        self.eps = eps\n        self.param_groups = self.optim.param_groups\n        self.ignore = ignore # Should be the final MLP\n        # Extract Parameters out of Model\n        self.params = [{'params': list(module.parameters())} for name, module in model.named_modules() if name != ignore]\n    def step(self):\n        '''\n        Iterates through all parameters, clipping gradients adaptively.\n        '''\n        for p in self.params[0]['params']:\n            if p.grad is None:\n                continue\n            # Weight Stored in P, p.grad stores gradients\n            grad_norm = self.unitnorm(p.grad.detach() * 1)\n            weight_norm = self.unitnorm(p.detach() * 1)\n            \n            normed = grad_norm / weight_norm # (B)\n            threshold = normed > self.clip_limit\n            \n            clipped = p.grad * self.clip_limit * (weight_norm / torch.max(grad_norm, torch.ones_like(grad_norm, device = grad_norm.device) * self.eps))\n            if clipped.shape[0] == 1 and len(clipped.shape) == 1:\n                clipped = torch.squeeze(clipped)\n                threshold = torch.squeeze(threshold)\n            p.grad.detach().data.copy_(torch.where(threshold, clipped, p.grad))\n        self.optim.step()\n            \n            \n    def zero_grad(self):\n        self.optim.zero_grad() # Use the Normal One\n        ","metadata":{"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"# PyTorch Lightning Training","metadata":{}},{"cell_type":"code","source":"class NFNetQTPiConfig:\n    num_classes = Config.NUM_CLASSES\n    device = Config.device\n    increase_dropout = 0.0\n    stochastic_depth = False\n    attention_type = 'se'\n    \n    model_type = 'baseline'\n    lr = 1e-3\n    optim = 'adam'\n    weight_decay = 1e-3\n    \n    num_steps = 5\n    eta_min = 1e-7\n    step_size = 0.95","metadata":{"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"class NFNetQTPi(pl.LightningModule):\n    def __init__(self, dev, fold_idx = 0):\n        super().__init__()\n        self.dev = dev\n        self.fold_idx = fold_idx\n        self.config = NFNetQTPiConfig\n        \n        self.model_type = self.config.model_type\n        assert self.model_type in ['baseline', 'QTPi']\n        self.model = self.configure_model()\n        self.criterion = nn.CrossEntropyLoss()\n        # Internal States\n        self.train_loss = 0\n        self.train_acc = 0\n        self.train_steps = 0\n        \n        self.val_loss = 0\n        self.val_acc = 0\n        self.val_steps = 0\n    \n        self.best_val_loss = 0\n        self.best_val_acc = 0\n        self.num_epochs = 0\n        self.liveloss = livelossplot.PlotLosses()\n        \n        self.to(self.device)\n    def configure_optimizers(self):\n        if self.config.optim == 'adam':\n            optimizer = optim.Adam(self.model.parameters(), lr = self.config.lr, weight_decay = self.config.weight_decay)\n        else:\n            optimizer = Ranger(self.model.parameters(), lr = self.config.lr, weight_decay = self.config.weight_decay)\n        optimizer = AdaptiveGradientClipping(self.model, optimizer, ignore = \"Linear\")\n        self.lr_decay = optim.lr_scheduler.StepLR(optimizer.optim, self.config.num_steps, self.config.step_size)\n        self.lr_decay2 = optim.lr_scheduler.CosineAnnealingLR(optimizer.optim, self.config.num_steps, eta_min = self.config.eta_min)\n        return [optimizer]\n    def configure_model(self):\n        '''\n        Loads in the Model\n        '''\n        if self.model_type == 'baseline':\n            model = BaseLineNFNet(self.config.num_classes)\n        else:\n            model = ModifiedNFNet_f0(self.config.num_classes, self.config.device, increase_dropout = self.config.increase_dropout, attention_type = self.config.attention_type, stochastic_depth = self.config.stochastic_depth)\n        #model = ArcFaceModule(model, self.config.num_classes)\n        return model\n    def reset_states(self):\n        self.train_loss = 0\n        self.train_acc = 0\n        self.train_steps = 0\n        \n        self.val_loss = 0\n        self.val_acc = 0\n        self.val_steps = 0\n        \n        self.num_epochs += 1\n    def fix_states(self):\n        if self.train_steps != 0:\n            self.train_loss /= self.train_steps\n            self.train_acc /= self.train_steps\n        if self.val_steps != 0:\n            self.val_loss /= self.val_steps\n            self.val_acc /= self.val_steps\n        \n        self.train_loss = round(self.train_loss, 3)\n        self.train_acc = round(self.train_acc, 3)\n        \n        self.val_loss = round(self.val_loss, 3)\n        self.val_acc = round(self.val_acc, 3)\n    def accuracy(self, pred, y):\n        \n        pred = F.softmax(pred)\n        _, indices = torch.max(pred, dim = -1)\n        B = indices.shape[0]\n        return torch.sum((indices == y).int()) / B\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        x = x.to(self.dev)\n        y = y.to(self.dev)\n        \n        pred = self.model(x)\n        loss = self.criterion(pred, y)\n        acc = self.accuracy(pred, y)\n        print(f\"STEP: {batch_idx}, L: {round(loss.item(), 3)}, A: {round(acc.item(), 3)}\")\n        self.train_loss += loss.item()\n        self.train_acc += acc.item()\n        self.train_steps += 1\n        if batch_idx % 100 == 0:\n            self.lr_decay.step()\n            self.lr_decay2.step()\n        del x, y, acc\n        return loss\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        x = x.to(self.dev)\n        y = y.to(self.dev)\n        \n        pred = self.model(x)\n        loss = self.criterion(pred, y)\n        acc = self.accuracy(pred, y)\n        \n        self.log('val_loss', loss.item())\n        self.log('val_acc', acc.item())\n        \n        self.val_loss += loss.item()\n        self.val_acc += acc.item()\n        del x, y, pred, loss, acc\n    def training_epoch_end(self, _):\n        self.lr_decay.step()\n        self.lr_decay2.step()\n    def save_states(self):\n        if self.val_loss <= self.best_val_loss:\n            self.best_val_loss = self.val_loss\n            torch.save(self.state_dict(), f'./fold_{self.fold_idx}_loss.pth')\n        if self.val_acc >= self.best_val_acc:\n            self.best_val_acc = self.val_acc\n            torch.save(self.state_dict(), f'./fold_{self.fold_idx}_acc.pth')\n    def generate_logs(self):\n        logs = {}\n        logs['loss'] = self.train_loss\n        logs['val_loss'] = self.val_loss\n        logs['accuracy'] = self.train_acc\n        logs['val_accuracy'] = self.val_acc\n        self.liveloss.update(logs)\n        self.liveloss.send()\n    def validation_epoch_end(self, _):\n        self.fix_states()\n        self.reset_states()","metadata":{"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"def trainNF(fold_idx):\n    '''\n    Trains one Fold, since everything is seeded, just tweak the number to change folds.\n    '''\n    train, val = dataModule.get_both(fold_idx)\n    model = NFNetQTPi(NFNetQTPiConfig.device, fold_idx = fold_idx)\n    early_stopping = []\n    trainer = pl.Trainer(check_val_every_n_epoch = 1, max_epochs = Config.NUM_EPOCHS, checkpoint_callback = False, logger = None, gpus = 1, num_sanity_val_steps = 0, callbacks = early_stopping, benchmark = False, deterministic = True, precision = 16)\n    print(f\"START OF TRAINING\")\n    trainer.fit(model, train, val)","metadata":{"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything()\ntrainNF(0)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"START OF TRAINING\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31cce58906464eeaa22c3fbbc4d7feae"}},"metadata":{}},{"name":"stdout","text":"STEP: 0, L: 9.196, A: 0.0\nSTEP: 0, L: 9.918, A: 0.031\nSTEP: 0, L: 9.775, A: 0.031\nSTEP: 0, L: 9.817, A: 0.062\nSTEP: 0, L: 9.937, A: 0.031\nSTEP: 0, L: 96.299, A: 0.031\nSTEP: 0, L: 93.462, A: 0.031\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
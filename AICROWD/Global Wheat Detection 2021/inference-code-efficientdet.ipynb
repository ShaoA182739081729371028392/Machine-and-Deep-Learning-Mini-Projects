{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Dependencies","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install ensemble-boxes","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:03:26.25817Z","iopub.execute_input":"2021-07-05T01:03:26.258637Z","iopub.status.idle":"2021-07-05T01:03:35.767623Z","shell.execute_reply.started":"2021-07-05T01:03:26.258535Z","shell.execute_reply":"2021-07-05T01:03:35.766032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ensemble_boxes import *\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as backend\nimport collections\nfrom tensorflow.keras import *\nimport tensorflow_addons as tfa\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np\nimport string\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom glob import glob\nimport random\nimport math\nfrom tqdm.notebook import tqdm\nimport os\n\n\nimport matplotlib.pyplot as plt\nimport cv2\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:03:35.769985Z","iopub.execute_input":"2021-07-05T01:03:35.770564Z","iopub.status.idle":"2021-07-05T01:03:43.662637Z","shell.execute_reply.started":"2021-07-05T01:03:35.770381Z","shell.execute_reply":"2021-07-05T01:03:43.661244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n    #keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\nexcept:\n    TPU = None\n    strategy = tf.distribute.get_strategy() \nN_REPLICAS = 8\ntf.config.optimizer.set_jit(True)\nbs = 2 # TPU's compile faster with smaller BS.\nBATCH_SIZE = bs * N_REPLICAS\nTARGET_DTYPE =  tf.float32","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:03:43.665679Z","iopub.execute_input":"2021-07-05T01:03:43.665992Z","iopub.status.idle":"2021-07-05T01:03:49.390462Z","shell.execute_reply.started":"2021-07-05T01:03:43.665964Z","shell.execute_reply":"2021-07-05T01:03:49.389377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load in the Model Fully.","metadata":{}},{"cell_type":"markdown","source":"Generate Anchors","metadata":{}},{"cell_type":"code","source":"def get_anchors(image_size):\n    all_anchors = []\n    grid_size = np.array([8, 16, 32, 64, 128], np.float32)\n    anchor_sizes = grid_size * 4.\n    anchor_ratios = np.array([0.5, 1, 2], np.float32)\n    anchor_scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)], np.float32)\n    for i in range(5):\n        # anchors (1, 9, 4)\n        anchors_list = np.zeros((len(anchor_ratios) * len(anchor_scales), 4))\n        anchors_list[:, 2] = np.tile(anchor_sizes[i] * anchor_scales, 3) / np.sqrt(np.repeat(anchor_ratios, len(anchor_scales)))\n        anchors_list[:, 3] = np.tile(anchor_sizes[i] * anchor_scales, 3) * np.sqrt(np.repeat(anchor_ratios, len(anchor_scales)))\n        anchors_list[:, 0::2] -= anchors_list[:, 2:3] * 0.5\n        anchors_list[:, 1::2] -= anchors_list[:, 3:4] * 0.5\n        anchors_list = np.expand_dims(anchors_list, axis=0)\n        \n        # shift (K, 1, 4)\n        shift_pts = np.arange(grid_size[i] // 2, image_size, grid_size[i], dtype=np.float32)  # [4, 12, 30, ...]\n        shift_list = np.zeros((len(shift_pts) ** 2, 4)) # (K, 1, 4)\n        shift_list[:,0] = shift_list[:,2] = np.tile(shift_pts, len(shift_pts)) # x1 x2   np.tile (0, 1, 2) => (0, 1, 2, 0, 1, 2, 0, 1, 2)\n        shift_list[:,1] = shift_list[:,3] = np.repeat(shift_pts, len(shift_pts)) # y1 y2  np.repeat (0, 1, 2) => (0, 0, 0, 1, 1, 1, 2, 2, 2)\n        shift_list = np.expand_dims(shift_list, axis=1)\n        \n        # merge (K, 9, 4) = > (K * 9, 4)\n        all_anchors.append(np.reshape(anchors_list + shift_list, (-1, 4)))\n    all_anchors = np.concatenate(all_anchors, axis=0)\n    return tf.cast(all_anchors, tf.float32)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:03:49.392104Z","iopub.execute_input":"2021-07-05T01:03:49.392413Z","iopub.status.idle":"2021-07-05T01:03:49.40734Z","shell.execute_reply.started":"2021-07-05T01:03:49.392382Z","shell.execute_reply":"2021-07-05T01:03:49.405979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Helper FN's.","metadata":{}},{"cell_type":"code","source":"def compute_area(bbox):\n    # Computes Areas of a Bbox\n    ones = bbox[:, :2] # (N, 2)\n    twos = bbox[:, 2:4] # (N, 2)\n    diff = tf.maximum(twos - ones, 0.0) # (N, 2)\n    return diff[:, 0] * diff[:, 1] # (N,)\ndef filter_bboxes(box):\n    # Filters out Bboxes if their area is < 0\n    indices_for_object = tf.where(tf.math.reduce_all([box[:,4] >= 0, \n                                                          box[:, 2] >= box[:, 0], \n                                                          box[:, 3] >= box[:, 1]], axis=0))\n    box = tf.cond(tf.shape(indices_for_object)[0] == 0, \n                    lambda: tf.reshape([0., 0., -1., -1., 0.], (-1, 1, box.shape[-1])),\n                    lambda: tf.reshape(tf.gather(box, indices_for_object), (-1, 1, box.shape[-1]))) # (?, 1, 5)\n    return box\ndef compute_centers(bbox):\n    return 0.5 * (bbox[:, :2] + bbox[:, 2:4])\ndef compute_iou(bbox, anchors):\n    # Computes IOU Between Bbox and Anchors\n    # Bbox: tensor(N, min(4)) - As long as the first 4 values are (x1, y1, x2, y2)\n    # Anchors: (x1, y1, x2, y2)\n    \n    # Expand bbox and anchor for broadcasting\n    area_bbox = compute_area(bbox) # (N, )\n    area_anchor = compute_area(anchors) # (M,)\n    \n    area_bbox = tf.expand_dims(area_bbox, axis = 0) # (1, N)\n    area_anchor = tf.expand_dims(area_anchor, axis = 1) # (M, 1)\n    \n    \n    bbox = tf.expand_dims(bbox, axis = 0) # (1, N, 5)\n    anchors = tf.expand_dims(anchors, axis = 1) # (M, 1, 5)\n    top_left_bboxes = tf.maximum(bbox[:, :, :2], anchors[:, :, :2]) # (M, N, 2)\n    bottom_right_bbox = tf.minimum(bbox[:, :, 2:4], anchors[:, :, 2:4]) # (M, N, 2)\n    \n    \n    \n    differences = bottom_right_bbox - top_left_bboxes# (M, N, 2)\n    differences = tf.maximum(differences, 0.0)\n    \n    inter = tf.maximum(differences[:, :, 0] * differences[:, :, 1], 0.0) # (M, N)\n    union = area_bbox + area_anchor - inter # (M, N)\n\n    eps = 1e-6\n    return (inter + eps) / (union + eps) # (M, N)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:03:49.409557Z","iopub.execute_input":"2021-07-05T01:03:49.409937Z","iopub.status.idle":"2021-07-05T01:03:49.428378Z","shell.execute_reply.started":"2021-07-05T01:03:49.409903Z","shell.execute_reply":"2021-07-05T01:03:49.427269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Module + Loading in Data ","metadata":{}},{"cell_type":"code","source":"class DataModule:\n    data_dir = 'test-gwd'\n    if TPU:\n        data_dir = KaggleDatasets().get_gcs_path(data_dir)\n        data_dir += '/*.tfrec'\n        glob_function = lambda x: tf.io.gfile.glob(x)\n    else:\n        data_dir = f\"../input/{data_dir}/*.tfrec\"\n        glob_function = lambda x: glob(x)\n    # grab all files \n    all_files = glob_function(data_dir)\n \n    NUM_FILES = sum(1 for _ in tf.data.TFRecordDataset(all_files))\n    \n    REQUIRED_DATASET_PAD = BATCH_SIZE-NUM_FILES%BATCH_SIZE \n    IMG_SHAPE = (1024, 1024, 3)\n    \n    MAX_BBOXES = 200 # Maximum number of Wheat Heads Possible\n    NUM_TTA = 4\n    # ANCHOR BOXES:\n    ANCHORS = get_anchors(IMG_SHAPE[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:03:49.429572Z","iopub.execute_input":"2021-07-05T01:03:49.430047Z","iopub.status.idle":"2021-07-05T01:04:03.17262Z","shell.execute_reply.started":"2021-07-05T01:03:49.430001Z","shell.execute_reply":"2021-07-05T01:04:03.170216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(example):\n    feature_dict = {\n        'image': tf.io.FixedLenFeature(shape=[], dtype=tf.string, default_value=''),\n        'image_id': tf.io.FixedLenFeature(shape = [], dtype = tf.string, default_value=\"\")\n    }\n    features = tf.io.parse_single_example(example, features=feature_dict)   \n    image = features['image']\n    image_id = features['image_id']\n    \n    \n    # Load image\n    image = tf.io.decode_jpeg(image, channels = 3)\n    # Cast to Desired Dtype\n    image = tf.cast(image, tf.float32) / 255.0\n    # Reshape the image \n    image = tf.reshape(image,  DataModule.IMG_SHAPE) # (1024, 1024, 3)\n    \n    # TTA 4\n    image0 = tf.identity(image)\n    image1 = tf.image.flip_left_right(tf.identity(image))\n    image2 = tf.image.flip_up_down(tf.identity(image))\n    image3 = tf.image.flip_up_down(tf.image.flip_left_right(tf.identity(image)))\n    \n    return image0, image1, image2, image3, image_id","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.176118Z","iopub.execute_input":"2021-07-05T01:04:03.176993Z","iopub.status.idle":"2021-07-05T01:04:03.191193Z","shell.execute_reply.started":"2021-07-05T01:04:03.176928Z","shell.execute_reply":"2021-07-05T01:04:03.189714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test_data():\n    '''\n    Load in the test data\n    '''\n    dataset = tf.data.TFRecordDataset(\n        DataModule.all_files,\n        num_parallel_reads = AUTO\n    )\n    options = tf.data.Options()\n    options.experimental_deterministic = False\n    \n    dataset = dataset.with_options(options)\n    dataset = dataset.map(lambda x: load_image(x), num_parallel_calls = AUTO, deterministic = False)\n    \n    # CREATE PADDING DATASET\n    if DataModule.REQUIRED_DATASET_PAD != 0:\n        extra_padding = DataModule.REQUIRED_DATASET_PAD\n        pad_dataset = tf.data.Dataset.from_tensor_slices((\n            tf.zeros((extra_padding, *DataModule.IMG_SHAPE), dtype=TARGET_DTYPE),  \n            tf.zeros((extra_padding, *DataModule.IMG_SHAPE), dtype = TARGET_DTYPE),\n            tf.zeros((extra_padding, *DataModule.IMG_SHAPE), dtype = TARGET_DTYPE),\n            tf.zeros((extra_padding, *DataModule.IMG_SHAPE), dtype = TARGET_DTYPE),# Fake Images\n            tf.constant([\"000000000000\",]*extra_padding, dtype=tf.string))   # Fake IDs\n        )\n        dataset = dataset.concatenate(pad_dataset)\n        \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.194442Z","iopub.execute_input":"2021-07-05T01:04:03.194899Z","iopub.status.idle":"2021-07-05T01:04:03.206433Z","shell.execute_reply.started":"2021-07-05T01:04:03.194854Z","shell.execute_reply":"2021-07-05T01:04:03.205138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_test_data()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.209098Z","iopub.execute_input":"2021-07-05T01:04:03.209556Z","iopub.status.idle":"2021-07-05T01:04:03.467146Z","shell.execute_reply.started":"2021-07-05T01:04:03.209495Z","shell.execute_reply":"2021-07-05T01:04:03.466075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load in the model","metadata":{}},{"cell_type":"code","source":"def increment_index(indices, index):\n  begin = indices[:index]\n  end = indices[index + 1:]\n  middle = tf.expand_dims(indices[index] + 1, axis = 0)\n  indices = tf.concat([begin, middle, end], axis = 0)\n  return indices\ndef replace_index_double_bbox(bboxes, first_index, second_index, new_value):\n  # Double Index\n  first_index = tf.squeeze(first_index)\n  second_index = tf.squeeze(second_index)\n  \n  begin = bboxes[:first_index]\n  end = bboxes[first_index + 1:]\n\n  middle = bboxes[first_index]\n  middle = tf.expand_dims(replace_index_bbox(middle, second_index, new_value), axis = 0)\n  new_bboxes = tf.concat([begin, middle, end], axis = 0)\n  return new_bboxes\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.468841Z","iopub.execute_input":"2021-07-05T01:04:03.469265Z","iopub.status.idle":"2021-07-05T01:04:03.477781Z","shell.execute_reply.started":"2021-07-05T01:04:03.46922Z","shell.execute_reply":"2021-07-05T01:04:03.476351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_images(images, bboxes):\n    values = tf.where((tf.greater_equal(bboxes[0][:, 4], 1.0)))\n    idx = tf.squeeze(tf.where((tf.greater_equal(bboxes[0][:, 4], 1.0))))\n    bounding = tf.gather(bboxes[0], idx)\n    anchors = tf.gather(DataModule.ANCHORS, idx)\n    images = images.numpy()\n    bounding = decode_bounding_box(bounding, anchors).numpy()\n    for idx in range(len(bounding)):\n        bbox = bounding[idx, :] # (5)\n        x1, y1, x2, y2 = bbox[:4]\n        coord1 = (x1, y1)\n        coord2 = (x2, y2)\n\n\n        cv2.rectangle(images, (int(x1), int(y1)), (int(x2), int(y2)), 220, 3)\n    plt.imshow(images)\n    plt.show()\n    \n\ndef decode_bounding_box(bboxes, anchors, image_size = 1024):\n    # Decodes the Predictions of the Bboxes(N,5) - Only X1,Y1, X2, Y2\n    width = anchors[:, 2] - anchors[:, 0]\n    height = anchors[:, 3] - anchors[:, 1]\n    # Obj Score should be kept the same for NMS.\n    \n    x1 = tf.expand_dims(bboxes[:, 0] + anchors[:, 0], axis = 1)\n    y1 = tf.expand_dims(bboxes[:, 1] + anchors[:, 1], axis = 1)\n    w =  tf.expand_dims(tf.math.exp(bboxes[:, 2]) * width, axis = 1)\n    h = tf.expand_dims(tf.math.exp(bboxes[:, 3]) * height, axis = 1)\n    obj =bboxes[:, 4:]\n    \n    \n    x2 = x1 + w\n    y2 = y1 + h\n    \n    new_bboxes = tf.concat([x1, y1, x2, y2, obj], axis = 1)\n    return new_bboxes\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.47936Z","iopub.execute_input":"2021-07-05T01:04:03.480144Z","iopub.status.idle":"2021-07-05T01:04:03.496403Z","shell.execute_reply.started":"2021-07-05T01:04:03.480085Z","shell.execute_reply":"2021-07-05T01:04:03.494836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def EfficientNetBN(n, input_tensor=None, input_shape=None, **kwargs):\n    CONV_KERNEL_INITIALIZER = {\n        'class_name': 'VarianceScaling',\n        'config': {\n            'scale': 2.0,\n            'mode': 'fan_out',\n            # EfficientNet actually uses an untruncated normal distribution for\n            # initializing conv layers, but keras.initializers.VarianceScaling use\n            # a truncated distribution.\n            # We decided against a custom initializer for better serializability.\n            'distribution': 'normal'\n        }\n    }\n\n    def get_swish():\n        def swish(x):\n            return x * tf.math.sigmoid(x)\n        return swish\n\n\n    def get_dropout():\n        class FixedDropout(layers.Dropout):\n            def _get_noise_shape(self, inputs):\n                if self.noise_shape is None:\n                    return self.noise_shape\n                symbolic_shape = tf.shape(inputs)\n                noise_shape = [symbolic_shape[axis] if (shape is None) else shape for axis, shape in enumerate(self.noise_shape)]\n                return tuple(noise_shape)\n        return FixedDropout\n\n\n    def round_filters(filters, width_coefficient, depth_divisor):\n        filters *= width_coefficient\n        new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n        new_filters = max(depth_divisor, new_filters)\n        if new_filters < 0.9 * filters:\n            new_filters += depth_divisor\n        return int(new_filters)\n\n\n    def round_repeats(repeats, depth_coefficient):\n        return int(math.ceil(depth_coefficient * repeats))\n\n\n    def mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', freeze_bn=False):\n        has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n        bn_axis = 3 \n\n        Dropout = get_dropout()\n\n        filters = block_args.input_filters * block_args.expand_ratio\n        if block_args.expand_ratio != 1:\n            x = layers.Conv2D(filters, 1, padding='same', use_bias=False, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'expand_conv')(inputs)\n            x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'expand_bn')(x)\n            x = layers.Activation(activation, name=prefix + 'expand_activation')(x)\n        else:\n            x = inputs\n\n        # Depthwise Convolution\n        x = layers.DepthwiseConv2D(block_args.kernel_size, strides=block_args.strides, padding='same', use_bias=False, depthwise_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'dwconv')(x)\n        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'bn')(x)\n        x = layers.Activation(activation, name=prefix + 'activation')(x)\n\n        # Squeeze and Excitation phase\n        if has_se:\n            num_reduced_filters = max(1, int(block_args.input_filters * block_args.se_ratio))\n            se_tensor = layers.GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)\n\n            target_shape = (1, 1, filters) if backend.image_data_format() == 'channels_last' else (filters, 1, 1)\n            se_tensor = layers.Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n            se_tensor = layers.Conv2D(num_reduced_filters, 1, activation=activation, padding='same', use_bias=True, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'se_reduce')(se_tensor)\n            se_tensor = layers.Conv2D(filters, 1, activation='sigmoid', padding='same', use_bias=True, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'se_expand')(se_tensor)\n            if backend.backend() == 'theano':\n                pattern = ([True, True, True, False] if (backend.image_data_format() == 'channels_last') else [True, False, True, True])\n                se_tensor = layers.Lambda(lambda x: backend.pattern_broadcast(x, pattern), name=prefix + 'se_broadcast')(se_tensor)\n            x = layers.multiply([x, se_tensor], name=prefix + 'se_excite')\n\n        # Output phase\n        x = layers.Conv2D(block_args.output_filters, 1, padding='same', use_bias=False, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'project_conv')(x)\n        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n        if block_args.id_skip and all(s == 1 for s in block_args.strides) and block_args.input_filters == block_args.output_filters:\n            if drop_rate and (drop_rate > 0):\n                x = Dropout(drop_rate, noise_shape=(None, 1, 1, 1), name=prefix + 'drop')(x)\n            x = layers.add([x, inputs], name=prefix + 'add')\n        return x\n\n\n    def EfficientNet(width_coefficient, depth_coefficient, drop_connect_rate=0.2, depth_divisor=8, input_tensor=None, input_shape=None, freeze_bn=False, **kwargs):\n        BlockArgs = collections.namedtuple('BlockArgs', [\n            'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n            'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n        ])\n        blocks_args = [\n            BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25),\n            BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112, expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25),\n            BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320, expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25)\n        ]\n        \n        features = []\n\n        img_input = layers.Input(shape=input_shape) if (input_tensor is None) else (input_tensor)\n\n        bn_axis = 3 \n        activation = get_swish(**kwargs)\n\n        # Build stem\n        x = img_input\n\n        x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer=CONV_KERNEL_INITIALIZER, name='stem_conv')(x)\n        x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)\n        x = layers.Activation(activation, name='stem_activation')(x)\n\n        # Build blocks\n        num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n        block_num = 0\n        for idx, block_args in enumerate(blocks_args):\n            assert block_args.num_repeat > 0\n            # Update block input and output filters based on depth multiplier.\n            block_args = block_args._replace(\n                input_filters=round_filters(block_args.input_filters, width_coefficient, depth_divisor),\n                output_filters=round_filters(block_args.output_filters, width_coefficient, depth_divisor),\n                num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n\n            # The first block needs to take care of stride and filter size increase.\n            drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n            x = mb_conv_block(x, block_args, activation=activation, drop_rate=drop_rate, prefix='block{}a_'.format(idx + 1), freeze_bn=freeze_bn)\n            block_num += 1\n            if block_args.num_repeat > 1:\n                # pylint: disable=protected-access\n                block_args = block_args._replace(\n                    input_filters=block_args.output_filters, strides=[1, 1])\n                # pylint: enable=protected-access\n                for bidx in range(block_args.num_repeat - 1):\n                    drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n                    block_prefix = 'block{}{}_'.format(idx + 1, string.ascii_lowercase[bidx + 1])\n                    x = mb_conv_block(x, block_args, activation=activation, drop_rate=drop_rate, prefix=block_prefix, freeze_bn=freeze_bn)\n                    block_num += 1\n            if idx < len(blocks_args) - 1 and blocks_args[idx + 1].strides[0] == 2:\n                features.append(x)\n            elif idx == len(blocks_args) - 1:\n                features.append(x)\n        return features\n\n    \n    parms = [\n        { \"width_coefficient\" : 1.0, \"depth_coefficient\" : 1.0, \"default_resolution\" : 224},\n        { \"width_coefficient\" : 1.0, \"depth_coefficient\" : 1.1, \"default_resolution\" : 240},\n        { \"width_coefficient\" : 1.1, \"depth_coefficient\" : 1.2, \"default_resolution\" : 260},\n        { \"width_coefficient\" : 1.2, \"depth_coefficient\" : 1.4, \"default_resolution\" : 300},\n        { \"width_coefficient\" : 1.4, \"depth_coefficient\" : 1.8, \"default_resolution\" : 380},\n        { \"width_coefficient\" : 1.6, \"depth_coefficient\" : 2.2, \"default_resolution\" : 456},\n        { \"width_coefficient\" : 1.8, \"depth_coefficient\" : 2.6, \"default_resolution\" : 528},\n        { \"width_coefficient\" : 2.0, \"depth_coefficient\" : 3.1, \"default_resolution\" : 600},\n    ][n]\n    return EfficientNet(parms['width_coefficient'], parms['depth_coefficient'], input_tensor=input_tensor, input_shape=input_shape, **kwargs)\n\n#print(EfficientNetBN(7, input_shape=(600, 600, 3)))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.498357Z","iopub.execute_input":"2021-07-05T01:04:03.49881Z","iopub.status.idle":"2021-07-05T01:04:03.547021Z","shell.execute_reply.started":"2021-07-05T01:04:03.498776Z","shell.execute_reply":"2021-07-05T01:04:03.54579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MOMENTUM = 0.99\nEPSILON = 1e-3\n\nclass wBiFPNAdd(layers.Layer):\n    def __init__(self, epsilon=1e-4, **kwargs):\n        super(wBiFPNAdd, self).__init__(**kwargs)\n        self.epsilon = epsilon\n\n    def build(self, input_shape):\n        num_in = len(input_shape)\n        self.w = self.add_weight(name=self.name, shape=(num_in,), initializer=initializers.constant(1 / num_in), trainable=True, dtype= tf.float32)\n\n    def call(self, inputs, **kwargs):\n        w = tf.cast(activations.relu(self.w), dtype = inputs[0].dtype)\n        x = tf.reduce_sum([w[i] * inputs[i] for i in range(len(inputs))], axis=0)\n        x = x / (tf.reduce_sum(w) + self.epsilon)\n        return x\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0]\n\n    def get_config(self):\n        config = super(wBiFPNAdd, self).get_config()\n        config.update({ 'epsilon': self.epsilon })\n        return config\n    \n    \ndef SeparableConvBlock(num_channels, kernel_size, strides, name, freeze_bn=False):\n    f1 = layers.SeparableConv2D(num_channels, kernel_size=kernel_size, strides=strides, padding='same',\n                                use_bias=True, name=f'{name}/conv')\n    f2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name=f'{name}/bn')\n    return lambda *args, **kwargs: f2(f1(*args, **kwargs))\n\n\ndef build_wBiFPN(features, num_channels, id, freeze_bn=False):\n    if id == 0:\n        _, _, C3, C4, C5 = features\n        \n        # 第一次BIFPN需要 下采样 与 降通道 获得 p3_in p4_in p5_in p6_in p7_in\n        #-----------------------------下采样 与 降通道----------------------------#\n        P3_in = C3\n        \n        P3_in = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                              name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/conv2d')(P3_in)\n        P3_in = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                          name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/bn')(P3_in)\n\n        P4_in = C4\n        P4_in_1 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/conv2d')(P4_in)\n        P4_in_1 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/bn')(P4_in_1)\n        P4_in_2 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/conv2d')(P4_in)\n        P4_in_2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/bn')(P4_in_2)\n\n        P5_in = C5\n        P5_in_1 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/conv2d')(P5_in)\n        P5_in_1 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/bn')(P5_in_1)\n        P5_in_2 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/conv2d')(P5_in)\n        P5_in_2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/bn')(P5_in_2)\n\n        P6_in = layers.Conv2D(num_channels, kernel_size=1, padding='same', name='resample_p6/conv2d')(C5)\n        P6_in = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name='resample_p6/bn')(P6_in)\n        P6_in = layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='resample_p6/maxpool')(P6_in)\n\n        P7_in = layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='resample_p7/maxpool')(P6_in)\n        #-------------------------------------------------------------------------#\n        #--------------------------构建BIFPN的上下采样循环-------------------------#\n        P7_U = layers.UpSampling2D(dtype = tf.float16)(P7_in)\n        P6_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode0/add')([P6_in, P7_U])\n        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)\n        P6_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode0/op_after_combine5')(P6_td)\n        \n        P6_U = layers.UpSampling2D()(P6_td)\n        P5_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode1/add')([P5_in_1, P6_U])\n        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)\n        P5_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode1/op_after_combine6')(P5_td)\n\n        P5_U = layers.UpSampling2D()(P5_td)\n        P4_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode2/add')([P4_in_1, P5_U])\n        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)\n        P4_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode2/op_after_combine7')(P4_td)\n\n        P4_U = layers.UpSampling2D()(P4_td)\n        P3_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode3/add')([P3_in, P4_U])\n        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)\n        P3_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode3/op_after_combine8')(P3_out)\n\n        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P3_out)\n        P4_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode4/add')([P4_in_2, P4_td, P3_D])\n        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)\n        P4_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode4/op_after_combine9')(P4_out)\n\n        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P4_out)\n        P5_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode5/add')([P5_in_2, P5_td, P4_D])\n        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)\n        P5_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode5/op_after_combine10')(P5_out)\n\n        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P5_out)\n        P6_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode6/add')([P6_in, P6_td, P5_D])\n        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)\n        P6_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode6/op_after_combine11')(P6_out)\n\n        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P6_out)\n        P7_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode7/add')([P7_in, P6_D])\n        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)\n        P7_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode7/op_after_combine12')(P7_out)\n\n    else:\n        P3_in, P4_in, P5_in, P6_in, P7_in = features\n        # Change the Dtypes to float16\n        \n        \n        P7_U = layers.UpSampling2D()(P7_in)\n        P6_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode0/add')([P6_in, P7_U])\n        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)\n        P6_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode0/op_after_combine5')(P6_td)\n\n        P6_U = layers.UpSampling2D()(P6_td)\n        P5_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode1/add')([P5_in, P6_U])\n        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)\n        P5_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode1/op_after_combine6')(P5_td)\n\n        P5_U = layers.UpSampling2D()(P5_td)\n        P4_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode2/add')([P4_in, P5_U])\n        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)\n        P4_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode2/op_after_combine7')(P4_td)\n\n        P4_U = layers.UpSampling2D()(P4_td)\n        \n        P3_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode3/add')([P3_in, P4_U])\n        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)\n        P3_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode3/op_after_combine8')(P3_out)\n\n        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P3_out)\n        P4_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode4/add')([P4_in, P4_td, P3_D])\n        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)\n        P4_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode4/op_after_combine9')(P4_out)\n\n        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P4_out)\n        P5_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode5/add')([P5_in, P5_td, P4_D])\n        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)\n        P5_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode5/op_after_combine10')(P5_out)\n\n        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P5_out)\n        P6_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode6/add')([P6_in, P6_td, P5_D])\n        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)\n        P6_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode6/op_after_combine11')(P6_out)\n\n        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P6_out)\n        P7_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode7/add')([P7_in, P6_D])\n        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)\n        P7_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode7/op_after_combine12')(P7_out)\n    return [P3_out, P4_out, P5_out, P6_out, P7_out]\n\n\nclass PriorProbability(initializers.Initializer):\n    \"\"\" Apply a prior probability to the weights.\n    \"\"\"\n    def __init__(self, probability=0.01):\n        self.probability = probability\n\n    def get_config(self):\n        return { 'probability': self.probability }\n\n    def __call__(self, shape, dtype=None):\n        # set bias to -log((1 - p)/p) for foreground\n        result = np.ones(shape) * -math.log((1 - self.probability) / self.probability)\n\n        return result\n\n    \nclass BoxNet(layers.Layer):\n    def __init__(self, width, depth, num_anchors=9, freeze_bn=False, name='box_net', **kwargs):\n        super().__init__()\n        \n        self.width = width\n        self.depth = depth\n        self.num_anchors = num_anchors\n        options = {\n            'kernel_size': 3,\n            'strides': 1,\n            'padding': 'same',\n            'bias_initializer': 'zeros',\n            'depthwise_initializer': initializers.VarianceScaling(),\n            'pointwise_initializer': initializers.VarianceScaling(),\n        }\n\n        self.convs = [layers.SeparableConv2D(filters=width, name=f'{name}/box-{i}', **options) for i in range(depth)]\n        self.head = layers.SeparableConv2D(filters=num_anchors * 4, name=f'{name}/box-predict', **options)\n\n        self.bns = [\n            [layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name=f'{name}/box-{i}-bn-{j}') for j in\n             range(3, 8)]\n            for i in range(depth)]\n\n        self.relu = layers.Lambda(lambda x: tf.nn.swish(x))\n        self.reshape = layers.Reshape((-1, 4))\n\n    def call(self, inputs):\n        feature, level = inputs\n        for i in range(self.depth):\n            feature = self.convs[i](feature)\n            feature = self.bns[i][level](feature)\n            feature = self.relu(feature)\n        outputs = self.head(feature)\n        outputs = self.reshape(outputs)\n        return outputs\n\n\nclass ClassNet(layers.Layer):\n    def __init__(self, width, depth, num_classes=20, num_anchors=9, freeze_bn=False, name='class_net', **kwargs):\n        super().__init__()\n        \n        self.width = width\n        self.depth = depth\n        self.num_classes = num_classes\n        self.num_anchors = num_anchors\n        options = {\n            'kernel_size': 3,\n            'strides': 1,\n            'padding': 'same',\n            'depthwise_initializer': initializers.VarianceScaling(),\n            'pointwise_initializer': initializers.VarianceScaling(),\n        }\n\n        self.convs = [layers.SeparableConv2D(filters=width, bias_initializer='zeros', name=f'{name}/class-{i}', **options) for i in range(depth)]\n        self.head = layers.SeparableConv2D(filters=num_classes * num_anchors, bias_initializer=PriorProbability(probability=0.01), name=f'{name}/class-predict', **options)\n        self.bns = [[layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name=f'{name}/class-{i}-bn-{j}') for j in range(3, 8)] for i in range(depth)]\n        self.relu = layers.Lambda(lambda x: tf.nn.swish(x))\n        self.reshape = layers.Reshape((-1, num_classes))\n        self.activation = layers.Activation('sigmoid')\n\n    def call(self, inputs):\n        feature, level = inputs\n        for i in range(self.depth):\n            feature = self.convs[i](feature)\n            feature = self.bns[i][level](feature)\n            feature = self.relu(feature)\n        outputs = self.head(feature)\n        outputs = self.reshape(outputs)\n        outputs = self.activation(outputs)\n        return outputs\n\ndef Efficientdet(phi, num_classes=20, num_anchors=9, freeze_bn=True):\n    assert phi in range(8)\n    fpn_num_filters = [64, 88, 112, 160, 224, 288, 384,384]\n    fpn_cell_repeats = [3, 4, 5, 6, 7, 7, 8, 8]\n    box_class_repeats = [3, 3, 3, 4, 4, 4, 5, 5]\n    image_sizes = [512, 640, 768, 896, 1024, 1280, 1408, 1536]\n    \n    image_input = layers.Input((image_sizes[phi], image_sizes[phi], 3), name='input', dtype = TARGET_DTYPE)\n    features = EfficientNetBN(phi, input_tensor=image_input, freeze_bn=freeze_bn)\n \n    fpn_features = features\n    if phi < 6:\n        for i in range(fpn_cell_repeats[phi]):\n            fpn_features = build_wBiFPN(fpn_features, fpn_num_filters[phi], i, freeze_bn=freeze_bn)\n    else:        \n        for i in range(fpn_cell_repeats[phi]):\n            fpn_features = build_BiFPN(fpn_features, fpn_num_filters[phi], i, freeze_bn=freeze_bn)\n\n    box_net = BoxNet(fpn_num_filters[phi], box_class_repeats[phi], num_anchors=num_anchors, freeze_bn=freeze_bn, name='box_net')\n    class_net = ClassNet(fpn_num_filters[phi], box_class_repeats[phi], num_classes=num_classes, num_anchors=num_anchors, freeze_bn=freeze_bn, name='class_net')\n    \n    classification = [class_net([feature, i]) for i, feature in enumerate(fpn_features)]\n    classification = layers.Concatenate(axis=1, name='classification')(classification)\n    regression = [box_net([feature, i]) for i, feature in enumerate(fpn_features)]\n    regression = layers.Concatenate(axis=1, name='regression')(regression)\n\n    model = models.Model(inputs=[image_input], outputs=[regression, classification], name='efficientdet')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.548919Z","iopub.execute_input":"2021-07-05T01:04:03.549263Z","iopub.status.idle":"2021-07-05T01:04:03.636347Z","shell.execute_reply.started":"2021-07-05T01:04:03.549232Z","shell.execute_reply":"2021-07-05T01:04:03.635204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelConfig:\n  num_classes = 1\n  phi = 4\n  model_path = [\n      '../input/gwd-efficientdetd4/best_model_0.h5',\n      \n  ]\n  num_models = len(model_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.638763Z","iopub.execute_input":"2021-07-05T01:04:03.639142Z","iopub.status.idle":"2021-07-05T01:04:03.646733Z","shell.execute_reply.started":"2021-07-05T01:04:03.639108Z","shell.execute_reply":"2021-07-05T01:04:03.645131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model():\n    all_models = []\n    for model_path in ModelConfig.model_path:\n        model = Efficientdet(4, num_classes=1)\n        model.load_weights(model_path)\n        all_models.append(model)\n    return all_models","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.648067Z","iopub.execute_input":"2021-07-05T01:04:03.648373Z","iopub.status.idle":"2021-07-05T01:04:03.65726Z","shell.execute_reply.started":"2021-07-05T01:04:03.648342Z","shell.execute_reply":"2021-07-05T01:04:03.6561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NMS CODE ","metadata":{}},{"cell_type":"code","source":"def replace_index_bbox(bboxes, idx, new_bbox):\n  N, C = bboxes.shape\n  # Bboxes: Tensor(N, 6)\n  # Idx: Tensor(1)\n  # New_BBox: Tensor(6)\n  begin = bboxes[:idx]\n  end = bboxes[idx + 1:]\n  middle = tf.expand_dims(new_bbox, axis = 0)\n\n  new_bbox = tf.concat([begin, middle, end], axis = 0)\n  new_bbox = tf.reshape(new_bbox, (-1, C))\n  return new_bbox\ndef replace_index_scores(scores, idx, new_score):\n  N = scores.shape[0]\n\n  begin = scores[:idx]\n  end = scores[idx + 1:]\n  middle = tf.expand_dims(new_score, axis = 0)\n\n  new_score = tf.concat([begin, middle, end], axis = 0)\n  new_score = tf.reshape(new_score, (-1, ))\n  return new_score ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.658485Z","iopub.execute_input":"2021-07-05T01:04:03.658827Z","iopub.status.idle":"2021-07-05T01:04:03.67131Z","shell.execute_reply.started":"2021-07-05T01:04:03.658796Z","shell.execute_reply":"2021-07-05T01:04:03.670075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replace_index(array, new_val, index):\n    left = array[:index]\n    middle = new_val\n    right = array[index + 1:]\n    new = tf.concat([left, middle, right], axis = 0)\n    return tf.reshape(new, (len(array), ))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.672949Z","iopub.execute_input":"2021-07-05T01:04:03.673261Z","iopub.status.idle":"2021-07-05T01:04:03.688466Z","shell.execute_reply.started":"2021-07-05T01:04:03.673231Z","shell.execute_reply":"2021-07-05T01:04:03.687174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def soft_nms_float(dets, labels, Nt, sigma, thresh, method):\n    \"\"\"\n    Based on: https://github.com/DocF/Soft-NMS/blob/master/soft_nms.py\n    It's different from original soft-NMS because we have float coordinates on range [0; 1]\n    :param dets:   boxes format [x1, y1, x2, y2]\n    :param sc:     scores for boxes\n    :param Nt:     required iou \n    :param sigma:  \n    :param thresh: \n    :param method: 1 - linear soft-NMS, 2 - gaussian soft-NMS, 3 - standard NMS\n    :return: index of boxes to keep\n    \"\"\"\n\n    # indexes concatenate boxes with the last column\n    N = dets.shape[0]\n    indexes = tf.cast(tf.expand_dims(tf.range(N), 1), dtype = dets.dtype)\n    dets = tf.concat([dets, indexes], axis=1) # (N, 6)\n\n    # the order of boxes coordinate is [y1, x1, y2, x2]\n    y1 = dets[:, 1] # (N, )\n    x1 = dets[:, 0] # (N, )\n    y2 = dets[:, 3] # (N, )\n    x2 = dets[:, 2] # (N, )\n\n    scores = dets[:, 4] # (N, )\n    areas = (x2 - x1) * (y2 - y1) # (N, )\n\n    for i in range(N - 1):\n        # intermediate parameters for later parameters exchange\n        tBD = tf.identity(dets[i, :])\n        tscore = tf.identity(scores[i])\n        tarea = tf.identity(areas[i])\n        pos = i + 1\n        if i != N - 1:\n            maxscore = tf.reduce_max(scores[pos:], axis=0)\n            maxpos = tf.argmax(scores[pos:], axis=0)\n        else:\n            maxscore = scores[-1]\n            maxpos = 0\n        if tscore < maxscore:\n            dets = replace_index_bbox(dets, i, dets[maxpos + pos, :])\n            dets = replace_index_bbox(dets, maxpos + pos, tBD)\n            tBD = dets[i, :]\n\n            scores = replace_index_scores(scores, i, scores[maxpos + pos])\n            scores = replace_index_scores(scores, maxpos + pos, tscore)\n            tscore = scores[i]\n\n            areas = replace_index_scores(areas, i, areas[maxpos + pos])\n            areas = replace_index_scores(areas, maxpos + pos, tarea)\n            tarea = areas[i]\n\n        # IoU calculate\n        xx1 = tf.maximum(dets[i, 1], dets[pos:, 1])\n        yy1 = tf.maximum(dets[i, 0], dets[pos:, 0])\n        xx2 = tf.minimum(dets[i, 3], dets[pos:, 3])\n        yy2 = tf.minimum(dets[i, 2], dets[pos:, 2])\n\n        w = tf.maximum(0.0, xx2 - xx1)\n        h = tf.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + tf.gather(areas, pos) - inter)\n        # Three methods: 1.linear 2.gaussian 3.original NMS\n        if method == 1:  # linear\n            weight = tf.ones_like(ovr)\n            boolean_mask = ovr > Nt \n            N = weight.shape[0]\n            for idx in range(N):\n              if boolean_mask[idx]:\n                weight = replace_index_scores(weight, idx, weight[idx] - ovr[idx])\n            \n        elif method == 2:  # gaussian\n            weight = tf.exp(-(ovr * ovr) / sigma)\n        else:  # original NMS\n            weight = tf.ones_like(ovr)\n            boolean_mask = ovr > Nt\n            N = boolean_mask.shape[0]\n            for idx in range(N):\n              weight = replace_index_scores(weight, idx, tf.constant(0.0, dtype = weight.dtype))\n\n        length_left = len(scores) - pos\n        for idx in range(length_left):\n          new_idx = idx + pos\n          scores = replace_index_scores(scores, new_idx, weight[idx] * scores[new_idx])\n\n    # select the boxes and keep the corresponding indexes\n  \n    inds = dets[:, 5][scores > thresh]\n    # Replace Scores \n    x1 = tf.expand_dims(dets[:, 0], axis = 1)\n    y1 = tf.expand_dims(dets[:, 1], axis = 1)\n    x2 = tf.expand_dims(dets[:, 2], axis = 1)\n    y2 = tf.expand_dims(dets[:, 3], axis = 1)\n    scores = tf.expand_dims(scores, axis = 1)\n\n    bboxes = tf.concat([x1, y1, x2, y2, scores], axis = 1)\n    # select out good bounding boxes \n    bboxes = tf.gather(bboxes, tf.cast(inds, tf.int64))\n    labels = tf.gather(labels, tf.cast(inds, tf.int64))\n    \n    labels = tf.squeeze(labels)\n    return bboxes, labels\n\n\ndef nms_float(dets, labels, thresh):\n    \"\"\"\n    # It's different from original nms because we have float coordinates on range [0; 1]\n    :param dets: numpy array of boxes with shape: (N, 5). Order: x1, y1, x2, y2, score. All variables in range [0; 1]\n    :param thresh: IoU value for boxes\n    :return: index of boxes to keep\n    \"\"\"\n    MAX_NUM = DataModule.MAX_BBOXES\n    x1 = dets[:, 0]\n    y1 = dets[:, 1]\n    x2 = dets[:, 2]\n    y2 = dets[:, 3]\n    scores = dets[:, 4]\n    \n    areas = (x2 - x1) * (y2 - y1)\n    order = tf.argsort(scores)[::-1]\n    \n\n    keep = tf.ones((MAX_NUM, ), dtype = tf.int32) * tf.constant(-1, dtype = tf.int32)\n    cur_idx = 0\n    while len(order) != 0:\n        i = order[0]\n\n        new_val = tf.reshape(tf.cast(i, dtype = keep.dtype), (1, ) )\n        keep = replace_index(keep, new_val, cur_idx)\n        cur_idx += 1\n        if order.shape[0] == 1:\n            break\n        i = tf.reshape(i, ())\n        xx1 = tf.maximum(x1[i], tf.gather(x1, order[1:]))\n        yy1 = tf.maximum(y1[i], tf.gather(y1, order[1:]))\n        xx2 = tf.minimum(x2[i], tf.gather(x2, order[1:]))\n        yy2 = tf.minimum(y2[i], tf.gather(y2, order[1:]))\n\n        w = tf.maximum(0.0, xx2 - xx1)\n        h = tf.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + tf.gather(areas, order[1:]) - inter)\n        inds = ovr <= thresh\n        order = tf.boolean_mask(order[1:], inds)\n    keep = keep[:cur_idx]\n    dets = tf.gather(dets, keep)\n    labels = tf.gather(labels, keep)\n    labels = tf.squeeze(labels)\n    \n    # PAD THE BOUNDING BOXES And LABELS\n    num_pad = MAX_NUM - cur_idx;\n    pad_dets = tf.ones((num_pad, 5), dtype = dets.dtype) * tf.constant(-1.0, dtype = dets.dtype)\n    pad_labels = tf.ones((num_pad,), dtype = dets.dtype) * tf.constant(-1.0, dtype = dets.dtype)\n    \n    dets = tf.concat([dets, pad_dets], axis = 0)\n    labels = tf.concat([labels, pad_labels], axis = 0)\n    \n    dets = tf.reshape(dets, (MAX_NUM, 5))\n    labels = tf.reshape(labels, (MAX_NUM, ))\n    return dets, labels\n\n\ndef nms_method(boxes, labels, method=3, iou_thr=0.5, sigma=0.5, thresh=0.001, weights=None):\n    \"\"\"\n    :param boxes: list of boxes predictions from each model, each box is 4 numbers. \n    It has 3 dimensions (models_number, model_preds, 4)\n    Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates [0; 1] \n    :param scores: list of scores for each model \n    :param labels: list of labels for each model\n    :param method: 1 - linear soft-NMS, 2 - gaussian soft-NMS, 3 - standard NMS\n    :param iou_thr: IoU value for boxes to be a match \n    :param sigma: Sigma value for SoftNMS\n    :param thresh: threshold for boxes to keep (important for SoftNMS)\n    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n    :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2). \n    :return: scores: confidence scores\n    :return: labels: boxes labels\n    \"\"\"\n\n    # Run NMS independently for each label\n\n    if method != 3:\n        bboxes, labels = soft_nms_float(boxes, labels, Nt=iou_thr, sigma=sigma, thresh=thresh, method=method)\n    else:\n        # Use faster function\n        bboxes, labels = nms_float(boxes, labels, thresh=iou_thr)\n\n\n    return bboxes, labels\n\ndef nms(boxes, labels, iou_thr=0.5, weights=None):\n    \"\"\"\n    Short call for standard NMS \n    \n    :param boxes: \n    :param scores: \n    :param labels: \n    :param iou_thr: \n    :param weights: \n    :return: \n    \"\"\"\n    return nms_method(boxes, labels, method=3, iou_thr=iou_thr, weights=weights)\n\n\ndef soft_nms(boxes, labels, method=2, iou_thr=0.5, sigma=0.5, thresh=0.001, weights=None):\n    \"\"\"\n    Short call for Soft-NMS\n     \n    :param boxes: \n    :param scores: \n    :param labels: \n    :param method: \n    :param iou_thr: \n    :param sigma: \n    :param thresh: \n    :param weights: \n    :return: \n    \"\"\"\n    return nms_method(boxes, labels, method=method, iou_thr=iou_thr, sigma=sigma, thresh=thresh, weights=weights)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.690297Z","iopub.execute_input":"2021-07-05T01:04:03.69072Z","iopub.status.idle":"2021-07-05T01:04:03.734285Z","shell.execute_reply.started":"2021-07-05T01:04:03.690683Z","shell.execute_reply":"2021-07-05T01:04:03.732875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def increment_index(indices, index):\n  begin = indices[:index]\n  end = indices[index + 1:]\n  middle = tf.expand_dims(indices[index] + 1, axis = 0)\n  indices = tf.concat([begin, middle, end], axis = 0)\n  return indices\ndef replace_index_double_bbox(bboxes, first_index, second_index, new_value):\n  # Double Index\n  first_index = tf.squeeze(first_index)\n  second_index = tf.squeeze(second_index)\n  \n  begin = bboxes[:first_index]\n  end = bboxes[first_index + 1:]\n\n  middle = bboxes[first_index]\n  middle = tf.expand_dims(replace_index_bbox(middle, second_index, new_value), axis = 0)\n  new_bboxes = tf.concat([begin, middle, end], axis = 0)\n  return new_bboxes\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.736367Z","iopub.execute_input":"2021-07-05T01:04:03.736883Z","iopub.status.idle":"2021-07-05T01:04:03.747978Z","shell.execute_reply.started":"2021-07-05T01:04:03.736836Z","shell.execute_reply":"2021-07-05T01:04:03.747151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_weighted_box(bboxes, i):\n  # Computes an AVG Weighted Box\n  # Boxes: Tensor(NUM_BOXES, NUM_BOXES, 5)\n  num_bboxes = len(bboxes)\n  to_avg_bboxes = bboxes[i] # (NUM_BOXES, 5)\n  # Average These Bounding Boxes According to Confi Q\n  Y1 = tf.zeros((1, ), dtype = bboxes.dtype)\n  X2 = tf.zeros((1, ), dtype = bboxes.dtype)\n  Y2 = tf.zeros((1, ), dtype = bboxes.dtype)\n  CONF = tf.zeros((1, ), dtype = bboxes.dtype)\n \n  for j in range(num_bboxes):\n    bbox = to_avg_bboxes[j] # (5)\n    \n    conf = bbox[4]\n    x1 = bbox[0] * conf\n    y1 = bbox[1] * conf\n    x2 = bbox[2] * conf\n    y2 = bbox[3] * conf\n    X1 = X1 + x1\n    Y1 = Y1 + y1\n    X2 = X2 + x2\n    Y2 = Y2 + y2\n    CONF = CONF + conf\n\n  X1 = X1 / CONF\n  Y1 = Y1 / CONF\n  X2 = X2 / CONF\n  Y2 = Y2 / CONF\n  CONF = CONF / tf.cast(num_bboxes, dtype = CONF.dtype)\n  \n  LBL = tf.ones_like(CONF) * bboxes[0, 0, 5]\n  \n  new_bbox = tf.concat([X1, Y1, X2, Y2, CONF, LBL], axis = 0) # (5, )\n  return new_bbox","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.748991Z","iopub.execute_input":"2021-07-05T01:04:03.74938Z","iopub.status.idle":"2021-07-05T01:04:03.762114Z","shell.execute_reply.started":"2021-07-05T01:04:03.74935Z","shell.execute_reply":"2021-07-05T01:04:03.76135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Loop","metadata":{}},{"cell_type":"code","source":"def pad_final_bounding_boxes(bounding_boxes):\n    # PADS THE NUMBER OF BOUNDING BOXES TO MAX_NUM \n    # Also cuts away anything more than N values\n    # SHAPE: Tensor(N, 5)\n    MAX_DET = DataModule.MAX_BBOXES\n    bounding_boxes =  bounding_boxes[:MAX_DET]\n    \n    N = bounding_boxes.shape[0]\n    num_pad = MAX_DET - N\n\n    pad_bboxes = tf.ones((num_pad, 5), dtype = bounding_boxes.dtype) * tf.constant(-1.0, dtype = bounding_boxes.dtype)\n    \n    padded_variant = tf.concat([bounding_boxes, pad_bboxes], axis = 0) # (MAX_DET, 5)\n    return padded_variant \ndef replace_bounding_box_index(bounding_boxes, new_bbox, index):\n    '''\n    bounding_boxes: Tensor(B, MAX_NUM_BBOXES, 5)\n    new_bbox: Tensor(M, 5) \n    '''\n    MAX_DET = DataModule.MAX_BBOXES\n    # Pad Bounding Boxes\n    \n    padded_new_bboxes = tf.expand_dims(new_bbox, axis = 0) # (1, 200, 5) \n    # Grab the Values to the left\n    left_bboxes = bounding_boxes[:index] # (index, 200, 5)\n    # Grab Right Values \n    right_bboxes = bounding_boxes[index + 1:]\n    # Reshape\n    padded_new_bboxes = tf.reshape(padded_new_bboxes, (-1, MAX_DET, 5))\n    left_bboxes = tf.reshape(left_bboxes, (-1, MAX_DET, 5))\n    right_bboxes = tf.reshape(right_bboxes, (-1, MAX_DET, 5))\n    \n    # Concat the all\n    new_bounding_boxes = tf.concat([left_bboxes, padded_new_bboxes, right_bboxes], axis = 0) # (B, 200, 5)\n    return new_bounding_boxes \n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.763144Z","iopub.execute_input":"2021-07-05T01:04:03.763576Z","iopub.status.idle":"2021-07-05T01:04:03.775098Z","shell.execute_reply.started":"2021-07-05T01:04:03.763508Z","shell.execute_reply":"2021-07-05T01:04:03.773766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_bounding_boxes(bboxes, anchors):\n    # Boxes: Tensor(B, 196196, 4)\n    # Anchors: Tensor(B, 196196, 4)\n    B = bboxes.shape[0]\n    anchors = tf.expand_dims(anchors, axis = 0)\n    anchors = tf.repeat(anchors, B, axis = 0) \n    width = anchors[:, :, 2] - anchors[:, :, 0]\n    height = anchors[:, :, 3] - anchors[:, :,  1]\n    # Obj Score should be kept the same for NMS.\n    \n    x1 = tf.expand_dims(bboxes[:, :, 0] + anchors[:,:,  0], axis = 2)\n    y1 = tf.expand_dims(bboxes[:, :, 1] + anchors[:, :, 1], axis = 2)\n    w =  tf.expand_dims(tf.math.exp(bboxes[:, :, 2]) * width, axis = 2)\n    h = tf.expand_dims(tf.math.exp(bboxes[:, :, 3]) * height,  axis = 2)\n    \n    x2 = x1 + w\n    y2 = y1 + h\n    \n    new_bounding_boxes = tf.concat([x1, y1, x2, y2], axis = 2)\n    return new_bounding_boxes","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.776309Z","iopub.execute_input":"2021-07-05T01:04:03.776665Z","iopub.status.idle":"2021-07-05T01:04:03.790935Z","shell.execute_reply.started":"2021-07-05T01:04:03.776632Z","shell.execute_reply":"2021-07-05T01:04:03.790116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replace_number_of_bounding_boxes(bounding_boxes, start_idx, end_idx, new_bboxes):\n    # Bounding_boxes: Tensor(B, N, 4) \n    # new_bboxes: Tensor(B, N, 4)\n    B, N, _ = bounding_boxes.shape\n    starting = bounding_boxes[:, :start_idx, :]\n    ending = bounding_boxes[:,  end_idx:, :] \n    middle = new_bboxes\n    \n    bboxes = tf.concat([starting, middle, ending], axis = 1) # (B, N, 4)\n    bboxes = tf.reshape(bboxes, (B, N, 5))\n    return bboxes","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.793683Z","iopub.execute_input":"2021-07-05T01:04:03.794118Z","iopub.status.idle":"2021-07-05T01:04:03.807242Z","shell.execute_reply.started":"2021-07-05T01:04:03.794088Z","shell.execute_reply":"2021-07-05T01:04:03.806338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_code(model, images, threshold = 0.5):\n    training = False \n    \n    bounding_boxes, classification = model(images, training = training)\n    \n    # Bounding Boxes: Tensor(B, 196196, 4)\n    # Classification: Tensor(B, 196196, 1) \n    # DECODE THE BOUNDING BOXES \n  \n    bounding_boxes = decode_bounding_boxes(bounding_boxes, DataModule.ANCHORS)\n    B = bounding_boxes.shape[0]\n    \n    max_dets = DataModule.MAX_BBOXES\n    final_dets = tf.ones((B, max_dets, 5), dtype = bounding_boxes.dtype) * tf.constant(-1.0, dtype = bounding_boxes.dtype)\n    \n    for b in range(B):\n        single_batch_bbox = bounding_boxes[b] # (N, 4) \n        single_batch_classes = classification[b] # (N, 1)\n      \n        # Filter out the Bad Bounding Boxes\n        keep = single_batch_classes >= threshold\n        keep = tf.reshape(keep, (-1, ))\n        kept_bounding_boxes = tf.boolean_mask(single_batch_bbox, keep) # (N, 4)\n       \n        N = kept_bounding_boxes.shape[0]\n        if N == 0:\n\n            # No Detections whatsoever\n            continue; # Just Skip, it's padded with -1's.\n        kept_classification = tf.expand_dims(tf.boolean_mask(single_batch_classes, keep), axis = 1) # (N, 1)\n        # All Bounding Boxes are 1(It's binary classifcation )\n        kept_bounding_boxes = tf.reshape(kept_bounding_boxes, (-1, 4))\n        kept_classification = tf.reshape(kept_classification, (-1, 1))\n        kept_bounding_boxes = tf.concat([kept_bounding_boxes, kept_classification], axis = 1) # (N, 5)\n        \n        # Non Maximum Suppression on the Bounding Boxes Left \n        detections, labels = nms(kept_bounding_boxes, tf.ones_like(kept_bounding_boxes, dtype = kept_bounding_boxes.dtype)[:, 0], iou_thr = 0.3)\n        # They are all label 1, so just add the new values into the final predictions\n        final_dets = replace_bounding_box_index(final_dets, detections, b)\n    return final_dets\ndef ensemble_model_pred(images):\n    B = images.shape[0]\n    NUM_MODELS = ModelConfig.num_models\n    MAX_BBOXES = DataModule.MAX_BBOXES\n    all_preds = tf.ones((B, MAX_BBOXES * NUM_MODELS, 5), dtype = images.dtype) * tf.constant(-1.0, dtype = images.dtype)\n    \n    start_idx = 0\n    for model in ALL_MODELS:\n        end_idx = start_idx + MAX_BBOXES\n        det_boxes = inference_code(model, images) # (B, N, 5) \n        all_preds = replace_number_of_bounding_boxes(all_preds, start_idx, end_idx, det_boxes)\n        start_idx += MAX_BBOXES\n    return all_preds # (B, 4000, 5)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.808768Z","iopub.execute_input":"2021-07-05T01:04:03.809186Z","iopub.status.idle":"2021-07-05T01:04:03.822618Z","shell.execute_reply.started":"2021-07-05T01:04:03.809156Z","shell.execute_reply":"2021-07-05T01:04:03.821233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_images(images, bboxes):\n    images = images.numpy()\n    bounding = bboxes.numpy()\n    for idx in range(len(bounding)):\n        bbox = bounding[idx, :] # (5)\n        x1, y1, x2, y2 = bbox[:4]\n        coord1 = (x1, y1)\n        coord2 = (x2, y2)\n        print(coord1)\n        print(coord2)\n        cv2.rectangle(images, (int(x1), int(y1)), (int(x2), int(y2)), 220, 3)\n    plt.imshow(images)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.823804Z","iopub.execute_input":"2021-07-05T01:04:03.824221Z","iopub.status.idle":"2021-07-05T01:04:03.839418Z","shell.execute_reply.started":"2021-07-05T01:04:03.824191Z","shell.execute_reply":"2021-07-05T01:04:03.837934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lr_flip(bboxes):\n    # Bbox: (B, N, 4)\n    B, N, _ = bboxes.shape\n    IMG_CENTER = DataModule.IMG_SHAPE[1] // 2\n\n    x1 = tf.expand_dims(bboxes[:, :, 0], 2)\n    y1 = tf.expand_dims(bboxes[:, :, 1], 2)\n    x2 = tf.expand_dims(bboxes[:, :, 2], 2)\n    y2 = tf.expand_dims(bboxes[:, :, 3], 2)\n    obj = bboxes[:, :, 4:]\n    # (B, N, 1) \n\n\n    x1 = x1 + 2 * (IMG_CENTER - x1)\n    x2 = x2 + 2 * (IMG_CENTER - x2) # (B, N, 1) \n\n    box_w = tf.abs(x2 - x1) # (B, N, 1)\n\n    x1 = x1 - box_w\n    x2 = x2 + box_w\n    \n    boolean_mask = box_w == tf.constant(0.0, dtype = box_w.dtype) # (B, N, 1)\n    boolean_mask = tf.constant(1.0, dtype = box_w.dtype) - tf.cast(boolean_mask, dtype = box_w.dtype) # (B, N, 1)\n    \n    x1 = x1 * boolean_mask\n    x2 = x2 * boolean_mask \n    \n    bboxes = tf.concat([x1, y1, x2, y2, obj], axis = 2)\n    bboxes = tf.reshape(bboxes, (B, N, 5))\n    return bboxes\n  \ndef ud_flip(bboxes):\n    # Bbox: (B, N, 4)\n    B, N, _ = bboxes.shape\n    IMG_CENTER = DataModule.IMG_SHAPE[1] // 2\n\n    x1 = tf.expand_dims(bboxes[:, :, 0], 2)\n    y1 = tf.expand_dims(bboxes[:, :, 1], 2)\n    x2 = tf.expand_dims(bboxes[:, :, 2], 2)\n    y2 = tf.expand_dims(bboxes[:, :, 3], 2)\n    obj = bboxes[:, :, 4:]\n    # (B, N, 1) \n\n\n    y1 = y1 + 2 * (IMG_CENTER - y1)\n    y2 = y2 + 2 * (IMG_CENTER - y2) # (B, N, 1) \n\n    box_h = tf.abs(y2 - y1) # (B, N, 1)\n\n    y1 = y1 - box_h\n    y2 = y2 + box_h\n    \n    boolean_mask = box_h == tf.constant(0.0, dtype = box_h.dtype) # (B, N, 1)\n    boolean_mask = tf.constant(1.0, dtype = box_h.dtype) - tf.cast(boolean_mask, dtype = box_h.dtype) # (B, N, 1)\n    \n    y1 = y1 * boolean_mask\n    y2 = y2 * boolean_mask \n    \n    bboxes = tf.concat([x1, y1, x2, y2, obj], axis = 2)\n    bboxes = tf.reshape(bboxes, (B, N, 5))\n    return bboxes\n  ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.84291Z","iopub.execute_input":"2021-07-05T01:04:03.843724Z","iopub.status.idle":"2021-07-05T01:04:03.864671Z","shell.execute_reply.started":"2021-07-05T01:04:03.84367Z","shell.execute_reply":"2021-07-05T01:04:03.8633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef test_dist_step(image0, image1, image2, image3, image_id):\n    # TTA 4: LR FLIP, UD Flip, Normal, LR -> UD Flip.\n    \n    \n    bbox0 = ensemble_model_pred(image0)\n    \n    bbox1 = ensemble_model_pred(image1) # (B, NUM_TTA * MAX_NUM, 5) \n    bbox1 = lr_flip(bbox1)\n    \n    bbox2 = ensemble_model_pred(image2)\n    bbox2 = ud_flip(bbox2)\n    \n    bbox3 = ensemble_model_pred(image3)\n    bbox3 = ud_flip(lr_flip(bbox3))\n    \n    bboxes = tf.concat([bbox0, bbox1, bbox2, bbox3], axis = 1) \n    bboxes = strategy.gather(bboxes, axis = 0)\n    image_id = strategy.gather(image_id, axis = 0)\n    return bboxes, image_id","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.866331Z","iopub.execute_input":"2021-07-05T01:04:03.86679Z","iopub.status.idle":"2021-07-05T01:04:03.880967Z","shell.execute_reply.started":"2021-07-05T01:04:03.866676Z","shell.execute_reply":"2021-07-05T01:04:03.879499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def single_process(bounding_boxes, image_id):\n    bbox = bounding_boxes.numpy() # (MAX_NUM * NUM_TTA *  NUM_MODELS,  4)\n    img_id = image_id.numpy().decode()\n    predString = ''\n  \n    # Map Bbox to Img_id\n    bbox = np.reshape(bbox, ((ModelConfig.num_models, DataModule.MAX_BBOXES * DataModule.NUM_TTA, 5)))\n    all_bounding_boxes = []\n    all_scores = []\n    all_labels = [] \n    for model_box in bbox:\n        # model_box: Tensor(MAX_BBOXES * NUM_TTA, 5) \n        model_box = np.reshape(model_box, (DataModule.NUM_TTA, DataModule.MAX_BBOXES, 5))\n        all_model_boxes = []\n        all_model_scores = []\n        all_model_labels = []\n        for tta_box in model_box:\n            all_tta_boxes = []\n            for box in tta_box:\n                if box[0] == -1 and box[1] == -1 and box[2] == -1 and box[3] == -1:\n                    # Padding\n                    continue\n                if box[4] == -1:\n                    continue\n                x1, y1, x2, y2, obj = box.tolist()\n                \n                all_tta_boxes.append([x1, y1, x2, y2, obj])\n            all_tta_boxes = np.array(all_tta_boxes)\n            all_model_boxes.append(all_tta_boxes[:, :4] / DataModule.IMG_SHAPE[1]) # Normalize the Bounding Boxes\n            all_model_scores.append(all_tta_boxes[:, 4])\n            all_model_labels.append(np.zeros_like(all_tta_boxes[:, 4]))\n        # WBF on TTA Boxes \n        all_model_boxes, all_model_scores, all_model_labels = weighted_boxes_fusion(all_model_boxes, all_model_scores, all_model_labels)\n        # all_model_boxes: tensor(N, 4) \n        # all_model_scores: tensor(N, )\n        # all_model_labels: tensor(N, ) \n        all_bounding_boxes.append(all_model_boxes)\n        all_scores.append(all_model_scores)\n        all_labels.append(all_model_labels)\n    # Weighted box Fusion on Models \n    all_bounding_boxes, all_scores, all_labels = weighted_boxes_fusion(all_bounding_boxes, all_scores, all_labels)\n    # all_bounding_boxes: Tensor(N, 4)\n    # all_scores: Tensor(N, ) \n    # all_Labels: Tensor(N, ) \n\n    bbox = all_bounding_boxes * DataModule.IMG_SHAPE[0]\n    new_bboxes = []\n\n    for box in bbox:\n\n        x1, y1, x2, y2 = box.tolist()\n\n        x1 = round(x1)\n        y1 = round(y1)\n        x2 = round(x2)\n        y2 = round(y2)\n\n        if x1 < 0:\n            x1 = 0\n        elif x1 > 1024:\n            x1 = 1024\n\n        if y1 < 0:\n            y1 = 0\n        elif y1 > 1024:\n            y1 = 1024\n\n        if x2 < 0:\n            x2 = 0\n        elif x2 > 1024:\n            x2 = 1024\n\n        if y2 < 0:\n            y2 = 0\n        elif y2 > 1024:\n            y2 = 1024\n\n        min_val_y = min(y1, y2)\n        max_val_y = max(y1, y2)\n\n        min_val_x = min(x1, x2)\n        max_val_x = max(x1, x2)\n\n        x1 = min_val_x\n        x2 = max_val_x\n\n        y1 = min_val_y\n        y2 = max_val_y\n        new_bboxes.append([x1, y1, x2, y2])\n    return np.array(new_bboxes)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.8841Z","iopub.execute_input":"2021-07-05T01:04:03.884953Z","iopub.status.idle":"2021-07-05T01:04:03.903697Z","shell.execute_reply.started":"2021-07-05T01:04:03.884903Z","shell.execute_reply":"2021-07-05T01:04:03.902461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ALL_MODELS = load_model()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:03.905053Z","iopub.execute_input":"2021-07-05T01:04:03.905341Z","iopub.status.idle":"2021-07-05T01:04:19.091892Z","shell.execute_reply.started":"2021-07-05T01:04:03.905314Z","shell.execute_reply":"2021-07-05T01:04:19.090986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Hours to get a TPU runtime\n- 7 Minutes/100","metadata":{}},{"cell_type":"code","source":"# INFERENCE CODE!\ntest_ds = load_test_data()\nMAX_NUM_BBOXES = DataModule.MAX_BBOXES\npredicted_bounding_boxes = tf.ones((0, MAX_NUM_BBOXES * DataModule.NUM_TTA * ModelConfig.num_models, 5), dtype = tf.float32)\npredicted_image_ids = tf.zeros((0, ), dtype = tf.string)\ncount = 0\ncur_thresh = 0\nfor image0, image1, image2, image3, image_id in test_ds:\n    bounding_boxes, image_id = test_dist_step(image0, image1, image2, image3, image_id) # (N, 4)\n    predicted_bounding_boxes = tf.concat([predicted_bounding_boxes, bounding_boxes,], axis = 0)\n    predicted_image_ids  = tf.concat([predicted_image_ids, image_id], axis = 0)\n    count += BATCH_SIZE\n    \n    if count > cur_thresh:\n        print(count, len(bounding_boxes[bounding_boxes[:, :, -1] != -1.0])) # Sanity Check every 100 turns.\n     \n        cur_thresh += 100\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T01:04:19.095626Z","iopub.execute_input":"2021-07-05T01:04:19.096231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_process(bounding_boxes, image_id):\n  \n    path = '../input/aicrowdwheatdata/submission.csv'\n    df = pd.read_csv(path) \n    orig_df = pd.read_csv(path)\n    mapping = {} \n    # Read in the File and Map Image_Name to Domain \n    for row in df.iterrows():\n        row = row[1]\n        image_name = row.image_name\n        domain = row.domain\n        mapping[image_name] = domain\n    # PROCESS IN THE BOUNDING BOXES\n    mapping_GT = {}\n    N = bounding_boxes.shape[0]\n    for i in range(N):\n        bbox = bounding_boxes[i].numpy() # (MAX_NUM * NUM_TTA *  NUM_MODELS,  4)\n        img_id = image_id[i].numpy().decode()\n        predString = ''\n        if img_id not in mapping:\n            continue # Stupid 7 files that they just added. IDK why.\n        # Map Bbox to Img_id\n        bbox = np.reshape(bbox, (ModelConfig.num_models, DataModule.MAX_BBOXES * DataModule.NUM_TTA, 5))\n        all_bounding_boxes = []\n        all_scores = []\n        all_labels = [] \n        for model_box in bbox:\n            # model_box: Tensor(MAX_BBOXES * NUM_TTA, 5) \n            model_box = np.reshape(model_box, (DataModule.NUM_TTA, DataModule.MAX_BBOXES, 5))\n            all_model_boxes = []\n            all_model_scores = []\n            all_model_labels = []\n            for tta_box in model_box:\n                all_tta_boxes = []\n                for box in tta_box:\n                    if box[0] == -1 and box[1] == -1 and box[2] == -1 and box[3] == -1:\n                        # Padding\n                        continue\n                    if box[4] == -1:\n                        continue\n                    x1, y1, x2, y2, obj = box.tolist()\n                    all_tta_boxes.append([x1, y1, x2, y2, obj])\n                if len(all_tta_boxes) == 0:\n                    all_model_boxes.append(np.ones((0, 4)))\n                    all_model_scores.append(np.ones((0,) ))\n                    all_model_labels.append(np.ones((0, )))\n                    continue\n                all_tta_boxes = np.array(all_tta_boxes)\n                all_model_boxes.append(all_tta_boxes[:, :4] / DataModule.IMG_SHAPE[1]) # Normalize the Bounding Boxes\n                all_model_scores.append(all_tta_boxes[:, 4])\n                all_model_labels.append(np.zeros_like(all_tta_boxes[:, 4]))\n            # WBF on TTA Boxes \n            all_model_boxes, all_model_scores, all_model_labels = weighted_boxes_fusion(all_model_boxes, all_model_scores, all_model_labels)\n            # all_model_boxes: tensor(N, 4) \n            # all_model_scores: tensor(N, )\n            # all_model_labels: tensor(N, ) \n            if len(all_model_boxes) == 0:\n                all_bounding_boxes.append(np.ones((0, 4)))\n                all_scores.append(np.ones((0, )))\n                all_labels.append(np.ones((0, )))\n                continue \n            all_bounding_boxes.append(all_model_boxes)\n            all_scores.append(all_model_scores)\n            all_labels.append(all_model_labels)\n        # Weighted box Fusion on Models \n        all_bounding_boxes, all_scores, all_labels = weighted_boxes_fusion(all_bounding_boxes, all_scores, all_labels)\n        # all_bounding_boxes: Tensor(N, 4)\n        # all_scores: Tensor(N, ) \n        # all_Labels: Tensor(N, ) \n        \n        bbox = all_bounding_boxes * DataModule.IMG_SHAPE[0]\n    \n        for box in bbox:\n            \n            x1, y1, x2, y2 = box.tolist()\n            \n            x1 = round(x1)\n            y1 = round(y1)\n            x2 = round(x2)\n            y2 = round(y2)\n            \n            if x1 < 0:\n                x1 = 0\n            elif x1 > 1024:\n                x1 = 1024\n                \n            if y1 < 0:\n                y1 = 0\n            elif y1 > 1024:\n                y1 = 1024\n            \n            if x2 < 0:\n                x2 = 0\n            elif x2 > 1024:\n                x2 = 1024\n            \n            if y2 < 0:\n                y2 = 0\n            elif y2 > 1024:\n                y2 = 1024\n            \n            min_val_y = min(y1, y2)\n            max_val_y = max(y1, y2)\n            \n            min_val_x = min(x1, x2)\n            max_val_x = max(x1, x2)\n            \n            x1 = min_val_x\n            x2 = max_val_x\n            \n            y1 = min_val_y\n            y2 = max_val_y\n            \n            \n            # Create Bounding Box to the list \n            if predString == '':\n                string_one_bbox = f\"{x1} {y1} {x2} {y2}\"\n            else:\n                string_one_bbox = f\";{x1} {y1} {x2} {y2}\"\n            predString += string_one_bbox\n        if predString == '':\n            print(\"NONE FOUND\")\n            predString = 'no_box'\n        mapping_GT[img_id] = (domain, predString)\n    to_be_df = {'image_name': [], 'PredString': [], \"domain\": []}\n    for row in df.iterrows():\n        row = row[1]\n        img_id = row.image_name\n        domain, predString = mapping_GT[img_id]\n        to_be_df['image_name'].append(img_id)\n        to_be_df['PredString'].append(predString)\n        to_be_df['domain'].append(domain)\n    to_be_df['domain'] = orig_df.domain\n    to_be_df['image_name'] = orig_df.image_name\n    \n    \n    final_df = pd.DataFrame(to_be_df)\n    final_df.to_csv(\"./submission.csv\", index = False)\n    return final_df\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = post_process(predicted_bounding_boxes, predicted_image_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n# Machine Learning and Data Science Imports\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as backend\nimport collections\nfrom tensorflow.keras import *\nimport tensorflow_addons as tfa\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np\nimport string\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom glob import glob\nimport random\nimport math\nfrom tqdm.notebook import tqdm\nimport os\n\n\nimport matplotlib.pyplot as plt\nimport cv2\n\nAUTO = tf.data.experimental.AUTOTUNE\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\nseed_it_all()\n","metadata":{"id":"yV-7Xc23rD1u","execution":{"iopub.status.busy":"2021-07-04T19:40:28.03384Z","iopub.execute_input":"2021-07-04T19:40:28.034247Z","iopub.status.idle":"2021-07-04T19:40:34.163841Z","shell.execute_reply.started":"2021-07-04T19:40:28.034156Z","shell.execute_reply":"2021-07-04T19:40:34.16281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load TPU","metadata":{"id":"HIRTl5qYrD1v"}},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n    keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\nexcept:\n    TPU = None\n    strategy = tf.distribute.get_strategy() \nN_REPLICAS = strategy.num_replicas_in_sync\ntf.config.optimizer.set_jit(True)\nbs = 2\nBATCH_SIZE = bs * N_REPLICAS\nTARGET_DTYPE = tf.bfloat16 if TPU else tf.float32","metadata":{"id":"ws4cjW1hrD1v","execution":{"iopub.status.busy":"2021-07-04T19:40:34.165175Z","iopub.execute_input":"2021-07-04T19:40:34.165471Z","iopub.status.idle":"2021-07-04T19:40:39.711532Z","shell.execute_reply.started":"2021-07-04T19:40:34.165445Z","shell.execute_reply":"2021-07-04T19:40:39.710511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pipeline","metadata":{"id":"Oah3JYD0rD1v"}},{"cell_type":"markdown","source":"Data Module\n- Hosted on Google Cloud Storage for Feeding into TPU.\n","metadata":{"id":"suZLpf49rD1w"}},{"cell_type":"code","source":"def get_anchors(image_size):\n    all_anchors = []\n    grid_size = np.array([8, 16, 32, 64, 128], np.float32)\n    anchor_sizes = grid_size * 4.\n    anchor_ratios = np.array([0.5, 1, 2], np.float32)\n    anchor_scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)], np.float32)\n    for i in range(5):\n        # anchors (1, 9, 4)\n        anchors_list = np.zeros((len(anchor_ratios) * len(anchor_scales), 4))\n        anchors_list[:, 2] = np.tile(anchor_sizes[i] * anchor_scales, 3) / np.sqrt(np.repeat(anchor_ratios, len(anchor_scales)))\n        anchors_list[:, 3] = np.tile(anchor_sizes[i] * anchor_scales, 3) * np.sqrt(np.repeat(anchor_ratios, len(anchor_scales)))\n        anchors_list[:, 0::2] -= anchors_list[:, 2:3] * 0.5\n        anchors_list[:, 1::2] -= anchors_list[:, 3:4] * 0.5\n        anchors_list = np.expand_dims(anchors_list, axis=0)\n        \n        # shift (K, 1, 4)\n        shift_pts = np.arange(grid_size[i] // 2, image_size, grid_size[i], dtype=np.float32)  # [4, 12, 30, ...]\n        shift_list = np.zeros((len(shift_pts) ** 2, 4)) # (K, 1, 4)\n        shift_list[:,0] = shift_list[:,2] = np.tile(shift_pts, len(shift_pts)) # x1 x2   np.tile (0, 1, 2) => (0, 1, 2, 0, 1, 2, 0, 1, 2)\n        shift_list[:,1] = shift_list[:,3] = np.repeat(shift_pts, len(shift_pts)) # y1 y2  np.repeat (0, 1, 2) => (0, 0, 0, 1, 1, 1, 2, 2, 2)\n        shift_list = np.expand_dims(shift_list, axis=1)\n        \n        # merge (K, 9, 4) = > (K * 9, 4)\n        all_anchors.append(np.reshape(anchors_list + shift_list, (-1, 4)))\n    all_anchors = np.concatenate(all_anchors, axis=0)\n    return tf.cast(all_anchors, tf.float32)","metadata":{"id":"Zb5DprfqrD1w","execution":{"iopub.status.busy":"2021-07-04T19:40:39.713241Z","iopub.execute_input":"2021-07-04T19:40:39.713546Z","iopub.status.idle":"2021-07-04T19:40:39.72621Z","shell.execute_reply.started":"2021-07-04T19:40:39.71352Z","shell.execute_reply":"2021-07-04T19:40:39.725017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_area(bbox):\n    # Computes Areas of a Bbox\n    ones = bbox[:, :2] # (N, 2)\n    twos = bbox[:, 2:4] # (N, 2)\n    diff = tf.maximum(twos - ones, 0.0) # (N, 2)\n    return diff[:, 0] * diff[:, 1] # (N,)\ndef filter_bboxes(box):\n    # Filters out Bboxes if their area is < 0\n    indices_for_object = tf.where(tf.math.reduce_all([box[:,4] >= 0, \n                                                          box[:, 2] >= box[:, 0], \n                                                          box[:, 3] >= box[:, 1]], axis=0))\n    box = tf.cond(tf.shape(indices_for_object)[0] == 0, \n                    lambda: tf.reshape([0., 0., -1., -1., 0.], (-1, 1, box.shape[-1])),\n                    lambda: tf.reshape(tf.gather(box, indices_for_object), (-1, 1, box.shape[-1]))) # (?, 1, 5)\n    return box\ndef compute_centers(bbox):\n    return 0.5 * (bbox[:, :2] + bbox[:, 2:4])\ndef compute_iou(bbox, anchors):\n    # Computes IOU Between Bbox and Anchors\n    # Bbox: tensor(N, min(4)) - As long as the first 4 values are (x1, y1, x2, y2)\n    # Anchors: (x1, y1, x2, y2)\n    \n    # Expand bbox and anchor for broadcasting\n    area_bbox = compute_area(bbox) # (N, )\n    area_anchor = compute_area(anchors) # (M,)\n    \n    area_bbox = tf.expand_dims(area_bbox, axis = 0) # (1, N)\n    area_anchor = tf.expand_dims(area_anchor, axis = 1) # (M, 1)\n    \n    \n    bbox = tf.expand_dims(bbox, axis = 0) # (1, N, 5)\n    anchors = tf.expand_dims(anchors, axis = 1) # (M, 1, 5)\n    top_left_bboxes = tf.maximum(bbox[:, :, :2], anchors[:, :, :2]) # (M, N, 2)\n    bottom_right_bbox = tf.minimum(bbox[:, :, 2:4], anchors[:, :, 2:4]) # (M, N, 2)\n    \n    \n    \n    differences = bottom_right_bbox - top_left_bboxes# (M, N, 2)\n    differences = tf.maximum(differences, 0.0)\n    \n    inter = tf.maximum(differences[:, :, 0] * differences[:, :, 1], 0.0) # (M, N)\n    union = area_bbox + area_anchor - inter # (M, N)\n\n    eps = 1e-6\n    return (inter + eps) / (union + eps) # (M, N)","metadata":{"id":"F88zk093rD1x","execution":{"iopub.status.busy":"2021-07-04T19:40:39.72787Z","iopub.execute_input":"2021-07-04T19:40:39.728158Z","iopub.status.idle":"2021-07-04T19:40:39.74531Z","shell.execute_reply.started":"2021-07-04T19:40:39.728134Z","shell.execute_reply":"2021-07-04T19:40:39.744287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_tfrecs(fold_idx, num_folds, num_epochs):\n    if TPU is not None:\n        glob_fn = lambda x: tf.io.gfile.glob(x)\n    else:\n        glob_fn = lambda x: glob(x)\n    \n    # Grab the correct dir for epochs and fold \n    TRAIN_TFRECS = [] \n    VAL_TFRECS = []\n    for i in range(num_folds):\n        if i == fold_idx:\n            base_dir = DataModule.val_dirs[0]\n            VAL_TFRECS.append(glob_fn(f\"{base_dir}/val_fold_{i}*\"))\n    for epoch in range(num_epochs):\n        for i in range(num_folds):\n            if i == fold_idx:\n                continue \n            else:\n                #-------------TRAIN DIR---------------\n                for idx in range(len(DataModule.train_dirs)):\n                    base_dir = DataModule.train_dirs[idx] # The Base Dir \n                    if len(glob_fn(f\"{base_dir}/{epoch}_fold_{i}*\")) == 0:\n                        continue\n                    TRAIN_TFRECS.append(glob_fn(f\"{base_dir}/{epoch}_fold_{i}*\")[0])\n    VAL_NUMBER = sum(1 for _ in tf.data.TFRecordDataset(VAL_TFRECS))\n    TRAIN_NUMBER = VAL_NUMBER * 4\n    ext_NUMBER = sum(1 for _ in tf.data.TFRecordDataset(TRAIN_TFRECS[-1]))\n    TRAIN_NUMBER += ext_NUMBER\n    return TRAIN_TFRECS, VAL_TFRECS, TRAIN_NUMBER, VAL_NUMBER\n\n        \nclass DataModule:\n    # -------------Load Dataset----------------\n    \n    NUM_EPOCHS = 50 # 30 EPOCHS augmented.\n    train_dirs = [\n        'd/andrewshao05/folds-0-10-gwd',\n        'd/andrewshao05/folds-10-20-gwd',\n        'd/andrewshao05/folds-20-30-gwd',\n        'd/andrewshao05/folds-30-40-gwd',\n        'd/andrewshao05/folds-40-50-gwd',\n        # Pseudo Data(The External Didn't Help at all)\n        'pseudo-1-10',\n        'folds-10-20',\n        'pseudo-20-30',\n        'folds-30-40',\n        'pseudo-40-50'\n        \n    ]\n    \n    val_dirs = [\n        'val-folds-gwd'\n    ]\n    if TPU is not None:\n        new_train_dirs = []\n        new_val_dirs = []\n        for td in train_dirs:\n            new_train_dirs.append(KaggleDatasets().get_gcs_path(td))\n            print(td)\n        for vd in val_dirs:\n            new_val_dirs.append(KaggleDatasets().get_gcs_path(vd))\n        train_dirs = new_train_dirs\n        val_dirs = new_val_dirs \n    else:\n        new_train_dirs = [] \n        new_val_dirs = []\n        for td in train_dirs:\n            new_train_dirs.append(f\"../input/{td}\")\n        for vd in val_dirs:\n            new_val_dirs.append(f\"../input/{vd}\")\n        train_dirs = new_train_dirs \n        val_dirs = new_val_dirs \n        \n    SAVE_PATH = './'\n    # -----------OTHER Data Params-------------------\n    IMG_SHAPE = (1024, 1024, 3) # Massive Fricken Images - But EfficientDet + TPUs can handle it.\n    # Generate Anchors, a Constant.\n    ANCHORS = get_anchors(IMG_SHAPE[0]) # Negative Values are fine.\n    # num Classes = 1. Wheat or No Wheat\n    NUM_CLASSES = 1\n    # Max Number of BBoxes == 516, but to be safe, 1024 cap.\n    MAX_BBOXES = 1024\n# Total Number\nCUR_EPOCH = 0\nFOLD_IDX = 0\nNUM_FOLDS = 6#7\nNUM_EPOCHS = DataModule.NUM_EPOCHS\nTRAIN_TFRECS, VAL_TFRECS, TRAIN_NUMBER, VAL_NUMBER =  load_tfrecs(FOLD_IDX, NUM_FOLDS, NUM_EPOCHS)\n","metadata":{"id":"Uw7JBTABrD1x","execution":{"iopub.status.busy":"2021-07-04T20:02:11.277619Z","iopub.execute_input":"2021-07-04T20:02:11.277984Z","iopub.status.idle":"2021-07-04T20:05:32.700473Z","shell.execute_reply.started":"2021-07-04T20:02:11.277949Z","shell.execute_reply":"2021-07-04T20:05:32.69937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations:","metadata":{"id":"vdxdM2NTrD1y"}},{"cell_type":"code","source":"def display_images(images, bboxes):\n    values = tf.where((tf.greater_equal(bboxes[0][:, 4], 1.0)))\n    idx = tf.squeeze(tf.where((tf.greater_equal(bboxes[0][:, 4], 1.0))))\n    bounding = tf.gather(bboxes[0], idx)\n    anchors = tf.gather(DataModule.ANCHORS, idx)\n    images = images.numpy()\n    bounding = decode_bounding_box(bounding, anchors).numpy()\n    for idx in range(len(bounding)):\n        bbox = bounding[idx, :] # (5)\n        x1, y1, x2, y2 = bbox[:4]\n        coord1 = (x1, y1)\n        coord2 = (x2, y2)\n\n\n        cv2.rectangle(images, (int(x1), int(y1)), (int(x2), int(y2)), 220, 3)\n    plt.imshow(images)\n    plt.show()\n    \n\ndef decode_bounding_box(bboxes, anchors, image_size = 1024):\n    # Decodes the Predictions of the Bboxes(N,5) - Only X1,Y1, X2, Y2\n    width = anchors[:, 2] - anchors[:, 0]\n    height = anchors[:, 3] - anchors[:, 1]\n    # Obj Score should be kept the same for NMS.\n    \n    x1 = tf.expand_dims(bboxes[:, 0] + anchors[:, 0], axis = 1)\n    y1 = tf.expand_dims(bboxes[:, 1] + anchors[:, 1], axis = 1)\n    w =  tf.expand_dims(tf.math.exp(bboxes[:, 2]) * width, axis = 1)\n    h = tf.expand_dims(tf.math.exp(bboxes[:, 3]) * height, axis = 1)\n    obj =bboxes[:, 4:]\n    \n    \n    x2 = x1 + w\n    y2 = y1 + h\n    \n    new_bboxes = tf.concat([x1, y1, x2, y2, obj], axis = 1)\n    return new_bboxes\n    ","metadata":{"id":"28i7BXk1rD13","execution":{"iopub.status.busy":"2021-07-04T20:01:45.841635Z","iopub.status.idle":"2021-07-04T20:01:45.842074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ENCODING FN","metadata":{"id":"m3b-y6Ata4gD"}},{"cell_type":"code","source":"# BBox Alignment Code\ndef datasets_encode(x, y, overlap_threshold = 0.5, ignore_threshold = 0.4):\n    # x (Batch Size, H, W, 3)\n    # y (Batch Size, N, 5)  x1, y1, x2, y2, class\n\n    # resize image\n    WIDTH, HEIGHT, _ = DataModule.IMG_SHAPE\n    if x.shape == DataModule.IMG_SHAPE:\n        x_scale, y_scale = DataModule.IMG_SHAPE[0] / x.shape[0], DataModule.IMG_SHAPE[1] / x.shape[1]\n        y = y * [x_scale, y_scale, x_scale, y_scale, 1]\n        x = tf.image.resize(x, [DataModule.IMG_SHAPE[0], DataModule.IMG_SHAPE[1]])\n    \n\n    assignment_x = tf.zeros((DataModule.ANCHORS.shape[0]), tf.float32)\n    assignment_y = tf.zeros((DataModule.ANCHORS.shape[0]), tf.float32)\n    assignment_w = tf.zeros((DataModule.ANCHORS.shape[0]), tf.float32)\n    assignment_h = tf.zeros((DataModule.ANCHORS.shape[0]), tf.float32)\n    assignment_is_obj = tf.zeros((DataModule.ANCHORS.shape[0]), tf.float32)\n\n\n    # filter correct boxes (area > 0)\n    priors = DataModule.ANCHORS # (1, 196416, 4)\n    width = tf.expand_dims(priors[:, 2] - priors[:, 0], axis = 1)\n    height = tf.expand_dims(priors[:, 3] - priors[:, 1], axis = 1)\n    \n    anchor_wh = tf.concat([width, height], axis = 1) # (196416, 2)\n    \n    box = tf.squeeze(filter_bboxes(y), axis = 1)\n   \n    iou = compute_iou(priors, box)\n\n    iou_max = tf.math.reduce_max(iou, axis=0) # (196416)\n    iou_max_idxs = tf.math.argmax(iou, axis=0) # (196416)\n    \n    # ignore box\n    ignore_mask = tf.math.logical_and(iou_max > ignore_threshold, iou_max < overlap_threshold) # (196416)\n    assignment_is_obj = tf.where(ignore_mask, -1., assignment_is_obj)\n\n    # object box\n    assign_mask = iou_max > overlap_threshold # (196416)\n    #print(tf.where(assign_mask))\n    box_best = tf.gather(box, iou_max_idxs, axis=0) # (?, 5) + (196416) => (196416, 5)_\n    assignment_is_obj = tf.where(assign_mask, 1., assignment_is_obj)\n   \n\n\n    box_center = compute_centers(box_best)\n\n    box_wh = box_best[:,2:4] - box_best[:,:2]  #  (196416, 2)\n    assigned_xy = (box_center - compute_centers(priors)) #  (196416, 2)\n    assigned_wh = tf.math.log(box_wh / anchor_wh) #  (196416, 2)\n    assignment_x = tf.where(assign_mask, assigned_xy[:, 0], assignment_x)\n    assignment_y = tf.where(assign_mask, assigned_xy[:, 1], assignment_y)\n    assignment_w = tf.where(assign_mask, assigned_wh[:, 0], assignment_w)\n    assignment_h = tf.where(assign_mask, assigned_wh[:, 1], assignment_h)\n\n\n    regression_list = tf.stack([\n        assignment_x, assignment_y, \n        assignment_w, assignment_h, \n        assignment_is_obj], axis=-1) # (N, 5)  \n    \n\n    classification_list = assignment_is_obj  # Literally Binary CE.\n    \n    return x, (regression_list, classification_list)\ndef batched_dataset_encode(images, bboxes, overlap_threshold = 0.5, ignore_threshold = 0.4):\n  # Images: tensor(B, H, W, 3)\n  # Bboxes: (Tensor(B, N,5), Tensor(B, N, C))\n  B, H, W, C = images.shape\n  _, _, num_channels = bboxes.shape\n  num_anchors = len(DataModule.ANCHORS)\n  num_classes = DataModule.NUM_CLASSES if DataModule.NUM_CLASSES != 1 else 2 \n  IMAGES = tf.ones((0, H, W, C), images.dtype)\n  BBOXES = tf.ones((0, num_anchors, num_channels), images.dtype)\n  CLASSIFICATION = tf.ones((0, num_anchors), images.dtype)\n  for b in range(B):\n    image = images[b] # (H, W, 3)\n    bbox = bboxes[b] # (N, 5)\n    \n    # Drop Padded Values: Where bboxes[:, -1] == 0.0\n    keep = tf.equal(bbox[:, -1], 1.0)\n  \n    bbox = tf.boolean_mask(bbox, keep, axis = 0)\n\n    image, (bbox, Class) = datasets_encode(image, bbox, overlap_threshold = overlap_threshold, ignore_threshold = ignore_threshold)\n    \n    IMAGES = tf.concat([IMAGES, tf.expand_dims(image, axis = 0)], axis = 0)\n    BBOXES = tf.concat([BBOXES, tf.expand_dims(bbox, axis = 0)], axis = 0)\n    CLASSIFICATION = tf.concat([CLASSIFICATION, tf.expand_dims(Class, axis = 0)], axis = 0)\n  return IMAGES, (BBOXES, CLASSIFICATION)\n","metadata":{"id":"bKIm0y41rD13","execution":{"iopub.status.busy":"2021-07-04T20:01:45.844009Z","iopub.status.idle":"2021-07-04T20:01:45.844439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Augments:\n  IMAGE_SIZE = 1024\n  THRESH = 0.25 # Doesn't Matter how large the bounding box is: Just can't be completely outside of the image.\n  BORDER = 100\n  \n  MAX_BBOX = 200 # Assume Max # of Bboxes, to pad to.(You can tune this to the dataset)\n","metadata":{"id":"_kyL2pUe3eE4","execution":{"iopub.status.busy":"2021-07-04T20:01:45.845688Z","iopub.status.idle":"2021-07-04T20:01:45.846091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpers","metadata":{"id":"cRp0twLo3hPK"}},{"cell_type":"code","source":"def load_image(example):\n    feature_dict = {\n        'image': tf.io.FixedLenFeature(shape=[], dtype=tf.string, default_value=''),\n        'bboxes': tf.io.VarLenFeature(dtype = tf.int64)\n        #'classification': tf.io.VarLenFeature(dtype = tf.int64) \n    }\n    features = tf.io.parse_single_example(example, features=feature_dict)\n    \n    image = features['image']\n    bboxes = features['bboxes'] # Classification Exists, but it's just repetition \n    \n    # Load image\n    image = tf.io.decode_jpeg(image, channels = 3)\n    # Cast to Desired Dtype\n    image = tf.cast(image, tf.float32) / 255.0\n    # Reshape the image \n    image = tf.reshape(image,  DataModule.IMG_SHAPE)\n    # Load the Bounding Boxes\n    bboxes = tf.cast(tf.sparse.to_dense(bboxes), tf.float32)\n    bboxes = tf.reshape(bboxes, (-1, 5)) # (N, 4)\n    \n    return image, bboxes\n","metadata":{"id":"_AvnrVMN3iQ_","execution":{"iopub.status.busy":"2021-07-04T20:01:45.84712Z","iopub.status.idle":"2021-07-04T20:01:45.847567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# COMBINATION AUGMENTS","metadata":{"id":"_8pYw6q2a6Q5"}},{"cell_type":"code","source":"def thresh_by_zero(bboxes):\n  img_shape = Augments.IMAGE_SIZE\n  # Bboxes: Tensor(B, 5)\n  x1 = bboxes[:, 0]\n  y1 = bboxes[:, 1]\n  x2 = bboxes[:, 2]\n  y2 = bboxes[:, 3]\n  obj = bboxes[:, 4:]\n\n  # Threshold the Values\n  x1 = tf.expand_dims(tf.clip_by_value(x1, 0.0, img_shape - 1), axis = -1)\n  y1 = tf.expand_dims(tf.clip_by_value(y1, 0.0, img_shape - 1), axis = -1)\n  x2 = tf.expand_dims(tf.clip_by_value(x2, 0.0, img_shape - 1), axis = -1)\n  y2 = tf.expand_dims(tf.clip_by_value(y2, 0.0, img_shape - 1), axis = -1)\n  # Compute Area and Threshold\n  bboxes = tf.concat([x1, y1, x2, y2, bboxes[:, 4:]], axis = 1) # (B, 5)\n  new_area =  compute_area(bboxes) # (N, )\n\n  # Threshold\n  keep = tf.where(tf.greater(new_area, 0.0))\n  kept_bboxes = tf.gather(bboxes, keep, axis = 0) # (M, 5)\n  return kept_bboxes # (N, 5)","metadata":{"id":"1W8gVU9JtOXM","execution":{"iopub.status.busy":"2021-07-04T20:01:45.848671Z","iopub.status.idle":"2021-07-04T20:01:45.849084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_bbox_normal(image, bbox):\n  N, _ = bbox.shape\n  \n  for box in bbox:\n    if box[-1] == 0:\n      continue\n    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), 220, 3)\n  plt.imshow(image)\n  plt.show()  \ndef convert_normal(bboxes, anchors, idx):\n  # Select Valid Bbox\n  indices = tf.where(tf.equal(bboxes[idx, :, -1], 1.0))\n  valid_bboxes = tf.squeeze(tf.gather(bboxes[idx], indices))[:, :-1] # (N, 4)\n  valid_anchors = tf.squeeze(tf.gather(anchors, indices)) # (N, 4)\n  \n  # Converts XYWH bounding to XYXY\n  x1 = valid_bboxes[:, 0] # Represents CX (CX = X - CAX)\n  y1 = valid_bboxes[:, 1] # Represents CY (CY = Y - CAY)\n  w = valid_bboxes[:, 2] # Represents Width change (Log(W / AW))\n  h = valid_bboxes[:, 3] # Represents Height change (Log(H / AH))\n  \n  anchor_centers = compute_centers(valid_anchors)\n  cx = anchor_centers[:, 0]\n  cy = anchor_centers[:, 1]\n\n  anchor_x1 = valid_anchors[:, 0]\n  anchor_y1 = valid_anchors[:, 1]\n  anchor_x2 = valid_anchors[:, 2]\n  anchor_y2 = valid_anchors[:, 3]\n\n  anchor_w = anchor_x2 - anchor_x1\n  anchor_h = anchor_y2 - anchor_y1\n\n  # Convert to normal format\n  new_x1 = x1 + cx\n  new_y1 = y1 + cy\n  new_w = tf.math.exp(w) * anchor_w\n  new_h = tf.math.exp(h) * anchor_h\n \n  new_x1 = new_x1 - new_w / 2\n  new_y1 = new_y1 - new_h / 2\n\n  new_x2 = new_x1 + new_w\n  new_y2 = new_y1 + new_h\n\n\n  new_x1 = tf.expand_dims(new_x1, 1)\n  new_y1 = tf.expand_dims(new_y1, 1)\n  new_x2 = tf.expand_dims(new_x2, 1)\n  new_y2 = tf.expand_dims(new_y2, 1)\n  \n  bboxes = tf.concat([new_x1, new_y1, new_x2, new_y2], axis = 1)\n  return bboxes","metadata":{"id":"LBRYi0SAdsGC","execution":{"iopub.status.busy":"2021-07-04T20:01:45.849811Z","iopub.status.idle":"2021-07-04T20:01:45.850206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dfs(FOLD_IDX):\n    train, val, _, _ = load_tfrecs(FOLD_IDX, NUM_FOLDS, DataModule.NUM_EPOCHS)\n    # Create TFRecordDatasets\n    train_dataset = tf.data.TFRecordDataset(\n        train,\n        num_parallel_reads = AUTO\n    )\n    val_dataset = tf.data.TFRecordDataset(\n        val,\n        num_parallel_reads = AUTO\n    )\n    # Options\n    options = tf.data.Options()\n    options.experimental_deterministic = False\n    \n    train_dataset = train_dataset.with_options(options)\n    val_dataset = val_dataset.with_options(options)\n    # Map Locations\n    train_dataset = train_dataset.map(lambda x: load_image(x), num_parallel_calls = AUTO, deterministic = False)\n    val_dataset = val_dataset.map(lambda x: load_image(x), num_parallel_calls = AUTO, deterministic = False)\n   \n    train_dataset = train_dataset.shuffle(128) \n    \n    # batch the Dataset\n    # TODO: CREATE CUSTOM BATCHING, ALSO CHECK BOUNDING BOXES BEFORE THIS POINT\n    \n    train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder = True)\n    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder = True)   \n   \n    # ALREADY AUGMENTED :), Just encode to Anchor Boxes\n    train_dataset = train_dataset.map(lambda x, y: batched_dataset_encode(x, y), num_parallel_calls = AUTO, deterministic = False)\n    val_dataset = val_dataset.map(lambda x, y: batched_dataset_encode(x, y), num_parallel_calls = AUTO, deterministic = False)\n    train_dataset = train_dataset.repeat()  \n    train_dataset = train_dataset.prefetch(AUTO)\n    val_dataset = val_dataset.prefetch(AUTO)\n    def convert_dtypes(images, bboxes):\n        bboxes, classification = bboxes\n        images = tf.cast(images, dtype = TARGET_DTYPE)\n        bboxes = tf.cast(bboxes, dtype = TARGET_DTYPE)\n        classification = tf.cast(classification, dtype = TARGET_DTYPE)\n        return images, (bboxes, classification)\n    \n    train_dataset = train_dataset.map(lambda x, y: convert_dtypes(x, y))\n    val_dataset = val_dataset.map(lambda x, y: convert_dtypes(x, y))\n    \n    return train_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2021-07-04T20:01:45.851013Z","iopub.status.idle":"2021-07-04T20:01:45.851427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standardize Bounding Boxes","metadata":{"id":"mjV8Q5SoRz54"}},{"cell_type":"code","source":"def fix_bounding_boxes(bboxes, min_height = 0, max_height = 1024, min_width = 0, max_width = 1024):\n  # Corrects the Bounding Boxes\n  x1 = bboxes[:, 0]\n  y1 = bboxes[:, 1]\n  x2 = bboxes[:, 2]\n  y2 = bboxes[:, 3]\n  obj = bboxes[:, 4]\n\n  x1 = tf.clip_by_value(x1, min_width, max_width)\n  y1 = tf.clip_by_value(y1, min_height, max_height) \n  x2 = tf.clip_by_value(x2, min_width, max_width)\n  y2 = tf.clip_by_value(y2, min_height, max_height)\n\n  x1 = tf.expand_dims(x1, axis = 0)\n  y1 = tf.expand_dims(y1, axis = 0)\n  x2 = tf.expand_dims(x2, axis = 0)\n  y2 = tf.expand_dims(y2, axis = 0)\n  obj = tf.expand_dims(obj, axis = 0)\n  \n  # Create Bboxes\n  bboxes = tf.concat([x1, y1, x2, y2, obj], axis = 0) # (N, 5)\n  # Compute Area\n  area = compute_area(bboxes) \n  # Remove Bboxes with 0 area\n  to_be_removed = tf.where(area > 0)\n  bboxes = tf.gather(bboxes, to_be_removed)\n  return tf.squeeze(bboxes, axis = 1)\n","metadata":{"id":"6u8qMCnBR2_U","execution":{"iopub.status.busy":"2021-07-04T20:01:45.852314Z","iopub.status.idle":"2021-07-04T20:01:45.852698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NMS THRESHOLD","metadata":{"id":"VtXMG4iYQrJk"}},{"cell_type":"code","source":"def replace_index_bbox(bboxes, idx, new_bbox):\n  N, C = bboxes.shape\n  # Bboxes: Tensor(N, 6)\n  # Idx: Tensor(1)\n  # New_BBox: Tensor(6)\n  begin = bboxes[:idx]\n  end = bboxes[idx + 1:]\n  middle = tf.expand_dims(new_bbox, axis = 0)\n\n  new_bbox = tf.concat([begin, middle, end], axis = 0)\n  new_bbox = tf.reshape(new_bbox, (-1, C))\n  return new_bbox\ndef replace_index_scores(scores, idx, new_score):\n  N = scores.shape[0]\n\n  begin = scores[:idx]\n  end = scores[idx + 1:]\n  middle = tf.expand_dims(new_score, axis = 0)\n\n  new_score = tf.concat([begin, middle, end], axis = 0)\n  new_score = tf.reshape(new_score, (-1, ))\n  return new_score ","metadata":{"id":"IaOHC35RiKC0","execution":{"iopub.status.busy":"2021-07-04T20:01:45.853446Z","iopub.status.idle":"2021-07-04T20:01:45.853829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def soft_nms_float(dets, labels, Nt, sigma, thresh, method):\n    \"\"\"\n    Based on: https://github.com/DocF/Soft-NMS/blob/master/soft_nms.py\n    It's different from original soft-NMS because we have float coordinates on range [0; 1]\n    :param dets:   boxes format [x1, y1, x2, y2]\n    :param sc:     scores for boxes\n    :param Nt:     required iou \n    :param sigma:  \n    :param thresh: \n    :param method: 1 - linear soft-NMS, 2 - gaussian soft-NMS, 3 - standard NMS\n    :return: index of boxes to keep\n    \"\"\"\n\n    # indexes concatenate boxes with the last column\n    N = dets.shape[0]\n    indexes = tf.cast(tf.expand_dims(tf.range(N), 1), dtype = dets.dtype)\n    dets = tf.concat([dets, indexes], axis=1) # (N, 6)\n\n    # the order of boxes coordinate is [y1, x1, y2, x2]\n    y1 = dets[:, 1] # (N, )\n    x1 = dets[:, 0] # (N, )\n    y2 = dets[:, 3] # (N, )\n    x2 = dets[:, 2] # (N, )\n\n    scores = dets[:, 4] # (N, )\n    areas = (x2 - x1) * (y2 - y1) # (N, )\n\n    for i in range(N - 1):\n        # intermediate parameters for later parameters exchange\n        tBD = tf.identity(dets[i, :])\n        tscore = tf.identity(scores[i])\n        tarea = tf.identity(areas[i])\n        pos = i + 1\n        if i != N - 1:\n            maxscore = tf.reduce_max(scores[pos:], axis=0)\n            maxpos = tf.argmax(scores[pos:], axis=0)\n        else:\n            maxscore = scores[-1]\n            maxpos = 0\n        if tscore < maxscore:\n            dets = replace_index_bbox(dets, i, dets[maxpos + pos, :])\n            dets = replace_index_bbox(dets, maxpos + pos, tBD)\n            tBD = dets[i, :]\n\n            scores = replace_index_scores(scores, i, scores[maxpos + pos])\n            scores = replace_index_scores(scores, maxpos + pos, tscore)\n            tscore = scores[i]\n\n            areas = replace_index_scores(areas, i, areas[maxpos + pos])\n            areas = replace_index_scores(areas, maxpos + pos, tarea)\n            tarea = areas[i]\n\n        # IoU calculate\n        xx1 = tf.maximum(dets[i, 1], dets[pos:, 1])\n        yy1 = tf.maximum(dets[i, 0], dets[pos:, 0])\n        xx2 = tf.minimum(dets[i, 3], dets[pos:, 3])\n        yy2 = tf.minimum(dets[i, 2], dets[pos:, 2])\n\n        w = tf.maximum(0.0, xx2 - xx1)\n        h = tf.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + tf.gather(areas, pos) - inter)\n        # Three methods: 1.linear 2.gaussian 3.original NMS\n        if method == 1:  # linear\n            weight = tf.ones_like(ovr)\n            boolean_mask = ovr > Nt \n            N = weight.shape[0]\n            for idx in range(N):\n              if boolean_mask[idx]:\n                weight = replace_index_scores(weight, idx, weight[idx] - ovr[idx])\n            \n        elif method == 2:  # gaussian\n            weight = tf.exp(-(ovr * ovr) / sigma)\n        else:  # original NMS\n            weight = tf.ones_like(ovr)\n            boolean_mask = ovr > Nt\n            N = boolean_mask.shape[0]\n            for idx in range(N):\n              weight = replace_index_scores(weight, idx, tf.constant(0.0, dtype = weight.dtype))\n\n        length_left = len(scores) - pos\n        for idx in range(length_left):\n          new_idx = idx + pos\n          scores = replace_index_scores(scores, new_idx, weight[idx] * scores[new_idx])\n\n    # select the boxes and keep the corresponding indexes\n  \n    inds = dets[:, 5][scores > thresh]\n    # Replace Scores \n    x1 = tf.expand_dims(dets[:, 0], axis = 1)\n    y1 = tf.expand_dims(dets[:, 1], axis = 1)\n    x2 = tf.expand_dims(dets[:, 2], axis = 1)\n    y2 = tf.expand_dims(dets[:, 3], axis = 1)\n    scores = tf.expand_dims(scores, axis = 1)\n\n    bboxes = tf.concat([x1, y1, x2, y2, scores], axis = 1)\n    # select out good bounding boxes \n    bboxes = tf.gather(bboxes, tf.cast(inds, tf.int64))\n    labels = tf.gather(labels, tf.cast(inds, tf.int64))\n    \n    labels = tf.squeeze(labels)\n    return bboxes, labels\n\n\ndef nms_float(dets, labels, thresh):\n    \"\"\"\n    # It's different from original nms because we have float coordinates on range [0; 1]\n    :param dets: numpy array of boxes with shape: (N, 5). Order: x1, y1, x2, y2, score. All variables in range [0; 1]\n    :param thresh: IoU value for boxes\n    :return: index of boxes to keep\n    \"\"\"\n    x1 = dets[:, 0]\n    y1 = dets[:, 1]\n    x2 = dets[:, 2]\n    y2 = dets[:, 3]\n    scores = dets[:, 4]\n    \n    areas = (x2 - x1) * (y2 - y1)\n    order = tf.argsort(scores)[::-1]\n    \n    keep = tf.zeros((0, ), dtype = tf.int32)\n    while order.shape[0] > 0:\n        i = order[0]\n      \n        keep = tf.concat([keep, tf.reshape(tf.constant(i, dtype = keep.dtype), (1, ) )], axis = 0)\n        i = tf.reshape(i, ())\n        xx1 = tf.maximum(x1[i], tf.gather(x1, order[1:]))\n        yy1 = tf.maximum(y1[i], tf.gather(y1, order[1:]))\n        xx2 = tf.minimum(x2[i], tf.gather(x2, order[1:]))\n        yy2 = tf.minimum(y2[i], tf.gather(y2, order[1:]))\n\n        w = tf.maximum(0.0, xx2 - xx1)\n        h = tf.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + tf.gather(areas, order[1:]) - inter)\n        inds = tf.where(ovr <= thresh)\n        order = tf.gather(order, inds + 1)\n    dets = tf.gather(dets, keep)\n    labels = tf.gather(labels, keep)\n\n    labels = tf.squeeze(labels)\n    return dets, labels\n\n\ndef nms_method(boxes, labels, method=3, iou_thr=0.5, sigma=0.5, thresh=0.001, weights=None):\n    \"\"\"\n    :param boxes: list of boxes predictions from each model, each box is 4 numbers. \n    It has 3 dimensions (models_number, model_preds, 4)\n    Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates [0; 1] \n    :param scores: list of scores for each model \n    :param labels: list of labels for each model\n    :param method: 1 - linear soft-NMS, 2 - gaussian soft-NMS, 3 - standard NMS\n    :param iou_thr: IoU value for boxes to be a match \n    :param sigma: Sigma value for SoftNMS\n    :param thresh: threshold for boxes to keep (important for SoftNMS)\n    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n    :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2). \n    :return: scores: confidence scores\n    :return: labels: boxes labels\n    \"\"\"\n    # Run NMS independently for each label\n    unique_labels = tf.unique(labels)\n    final_boxes = tf.zeros((0, boxes.shape[1]), dtype = boxes.dtype)\n    final_labels = tf.zeros((0, ), dtype = labels.dtype)\n    for l in unique_labels:\n        condition = (labels == tf.cast(l, dtype = labels.dtype))\n        boxes_by_label = boxes[condition]\n        labels_by_label = np.array([l] * len(boxes_by_label))\n\n        if method != 3:\n            bboxes, labels = soft_nms_float(tf.identity(boxes_by_label), labels_by_label, Nt=iou_thr, sigma=sigma, thresh=thresh, method=method)\n        else:\n            # Use faster function\n            bboxes, labels = nms_float(boxes_by_label, labels_by_label, thresh=iou_thr)\n\n\n        final_boxes = tf.concat([final_boxes, bboxes], axis = 0)\n        if len(labels.shape) != len(final_labels.shape):\n          labels = tf.expand_dims(labels, axis = -1)\n        final_labels = tf.concat([final_labels, tf.cast(labels, dtype = final_labels.dtype)], axis = 0)\n  \n    return final_boxes, final_labels\n\n\ndef nms(boxes, labels, iou_thr=0.5, weights=None):\n    \"\"\"\n    Short call for standard NMS \n    \n    :param boxes: \n    :param scores: \n    :param labels: \n    :param iou_thr: \n    :param weights: \n    :return: \n    \"\"\"\n    return nms_method(boxes, labels, method=3, iou_thr=iou_thr, weights=weights)\n\n\ndef soft_nms(boxes, labels, method=2, iou_thr=0.5, sigma=0.5, thresh=0.001, weights=None):\n    \"\"\"\n    Short call for Soft-NMS\n     \n    :param boxes: \n    :param scores: \n    :param labels: \n    :param method: \n    :param iou_thr: \n    :param sigma: \n    :param thresh: \n    :param weights: \n    :return: \n    \"\"\"\n    return nms_method(boxes, labels, method=method, iou_thr=iou_thr, sigma=sigma, thresh=thresh, weights=weights)","metadata":{"id":"c9tbHLgkQv2S","execution":{"iopub.status.busy":"2021-07-04T20:01:45.854668Z","iopub.status.idle":"2021-07-04T20:01:45.855055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WBF\n\n","metadata":{"id":"WMruHPaAz2At"}},{"cell_type":"code","source":"def increment_index(indices, index):\n  begin = indices[:index]\n  end = indices[index + 1:]\n  middle = tf.expand_dims(indices[index] + 1, axis = 0)\n  indices = tf.concat([begin, middle, end], axis = 0)\n  return indices\ndef replace_index_double_bbox(bboxes, first_index, second_index, new_value):\n  # Double Index\n  first_index = tf.squeeze(first_index)\n  second_index = tf.squeeze(second_index)\n  \n  begin = bboxes[:first_index]\n  end = bboxes[first_index + 1:]\n\n  middle = bboxes[first_index]\n  middle = tf.expand_dims(replace_index_bbox(middle, second_index, new_value), axis = 0)\n  new_bboxes = tf.concat([begin, middle, end], axis = 0)\n  return new_bboxes\n","metadata":{"id":"dpt25ZSt_LX1","execution":{"iopub.status.busy":"2021-07-04T20:01:45.856162Z","iopub.status.idle":"2021-07-04T20:01:45.856572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_weighted_box(bboxes, i):\n  # Computes an AVG Weighted Box\n  # Boxes: Tensor(NUM_BOXES, NUM_BOXES, 5)\n  num_bboxes = len(bboxes)\n  to_avg_bboxes = bboxes[i] # (NUM_BOXES, 5)\n  # Average These Bounding Boxes According to Confidence Score\n  X1 = tf.zeros((1, ), dtype = bboxes.dtype)\n  Y1 = tf.zeros((1, ), dtype = bboxes.dtype)\n  X2 = tf.zeros((1, ), dtype = bboxes.dtype)\n  Y2 = tf.zeros((1, ), dtype = bboxes.dtype)\n  CONF = tf.zeros((1, ), dtype = bboxes.dtype)\n \n  for j in range(num_bboxes):\n    bbox = to_avg_bboxes[j] # (5)\n    \n    conf = bbox[4]\n    x1 = bbox[0] * conf\n    y1 = bbox[1] * conf\n    x2 = bbox[2] * conf\n    y2 = bbox[3] * conf\n    X1 = X1 + x1\n    Y1 = Y1 + y1\n    X2 = X2 + x2\n    Y2 = Y2 + y2\n    CONF = CONF + conf\n\n  X1 = X1 / CONF\n  Y1 = Y1 / CONF\n  X2 = X2 / CONF\n  Y2 = Y2 / CONF\n  CONF = CONF / tf.cast(num_bboxes, dtype = CONF.dtype)\n  \n  LBL = tf.ones_like(CONF) * bboxes[0, 0, 5]\n  \n  new_bbox = tf.concat([X1, Y1, X2, Y2, CONF, LBL], axis = 0) # (5, )\n  return new_bbox","metadata":{"id":"6nN143NLIWwp","execution":{"iopub.status.busy":"2021-07-04T20:01:45.857431Z","iopub.status.idle":"2021-07-04T20:01:45.857805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_matching_box(boxes, new_box, match_iou):\n    # Boxes: Tensor(Len(boxes), 5)\n    # New_box: Tensor(5)\n    boxes_idx = tf.where(tf.not_equal(boxes[:, 4], 0.0))\n    boxes = tf.squeeze(tf.gather(boxes, boxes_idx), axis = 1)\n    new_box = tf.expand_dims(new_box, axis = 0)\n    iou_computation = compute_iou(boxes, new_box)\n    max_iou = tf.reduce_max(iou_computation)\n    if max_iou > match_iou:\n        # Find the Maximum\n        idx = tf.squeeze(tf.argmax(iou_computation, axis = -1))\n        return tf.cast(idx, dtype = tf.int32)\n    else:\n      return tf.constant(-1, dtype = tf.int32)\n@tf.function\ndef weighted_boxes_fusion(boxes, labels, weights=None, iou_thr=0.55, skip_box_thr=0.0, conf_type='avg', allows_overflow=False):\n    '''\n    :param boxes_list: list of boxes predictions from each model, each box is 4 numbers.\n    It has 3 dimensions (models_number, model_preds, 4)\n    Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates [0; 1]\n    Boxes: Tensor(M, N, 5)\n    Labels: Tensor(m, N)\n    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n    :param iou_thr: IoU value for boxes to be a match\n    :param skip_box_thr: exclude boxes with score lower than this variable\n    :param conf_type: how to calculate confidence in weighted boxes. 'avg': average value, 'max': maximum value, 'box_and_model_avg': box and model wise hybrid weighted average, 'absent_model_aware_avg': weighted average that takes into account the absent model.\n    :param allows_overflow: false if we want confidence score not exceed 1.0\n    :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2).\n    :return: scores: confidence scores\n    :return: labels: boxes labels\n    '''\n\n    if weights is None:\n        weights = tf.ones(len(boxes))\n    SUM_OF_WEIGHTS = tf.cast(tf.reduce_sum(weights), dtype = boxes.dtype)\n    # Append the Labels to the Bounding Box \n    N = boxes.shape[0] * boxes.shape[1]\n    final_bounding_boxes = tf.zeros((N, 6), dtype = boxes.dtype)\n\n    expanded_labels = tf.expand_dims(labels, axis = 2)\n    boxes = tf.concat([boxes, expanded_labels], axis = 2)\n\n    boxes = tf.reshape(boxes, (-1, 6))\n    unique_labels = tf.unique(tf.reshape(labels, (-1, )))[0]\n    labels = tf.reshape(labels, (-1, ))\n    bounding_idx = tf.zeros((1, ), dtype = tf.int64)\n    for i in range(len(unique_labels)):\n      cur_lbl = unique_labels[i]\n      # Select Bboxes with this lbl\n      boolean_mask = tf.equal(labels, cur_lbl)\n      cur_boxes = tf.boolean_mask(boxes, boolean_mask, axis = 0)\n\n      new_boxes = tf.zeros((len(cur_boxes), len(cur_boxes), 6), dtype = cur_boxes.dtype)\n      weighted_boxes = tf.zeros((len(cur_boxes), 6), dtype = cur_boxes.dtype)\n      cur_idx = tf.zeros((len(cur_boxes), ), dtype = tf.int32)\n      cur_filled_idx = tf.zeros((1, ), dtype = tf.int32)\n    \n      # Clusterize boxes\n      for j in range(0, len(cur_boxes)):\n          bounding_box = tf.identity(cur_boxes[j])\n          index = find_matching_box(weighted_boxes, bounding_box, iou_thr)\n          \n          if index != -1:\n              new_boxes = replace_index_double_bbox(new_boxes, index, tf.gather(cur_idx, index), bounding_box)\n              # Compute New Weighted Boxes.\n              weighted_box = compute_weighted_box(new_boxes, index)\n              weighted_boxes = replace_index_bbox(weighted_boxes, index, weighted_box)\n\n              cur_idx = increment_index(cur_idx, index)\n          else:\n              idx = tf.squeeze(cur_filled_idx)\n              new_boxes = replace_index_double_bbox(new_boxes, cur_filled_idx, cur_idx[idx], bounding_box)\n              weighted_boxes = replace_index_bbox(weighted_boxes, idx, bounding_box)\n              cur_idx = increment_index(cur_idx, idx)\n              cur_filled_idx = cur_filled_idx + 1\n      # Find Number of Bounding Boxes\n      num_weighted = cur_filled_idx  #idx is 0 based\n      # Rescale confidence based on number of models and boxes\n      for i in range(tf.squeeze(num_weighted)):\n          clustered_boxes = new_boxes[i] # (NUM_BBOXES, 5)\n          num_boxes = tf.cast(tf.not_equal(clustered_boxes[:, 4], 0.0), dtype = clustered_boxes.dtype)\n          num_boxes = tf.reduce_sum(num_boxes)\n\n          weighted_score = weighted_boxes[i, 4] * tf.minimum(SUM_OF_WEIGHTS, num_boxes) / SUM_OF_WEIGHTS\n          x1 = tf.expand_dims(weighted_boxes[i, 0], axis = 0)\n          y1 = tf.expand_dims(weighted_boxes[i, 1], axis = 0)\n          x2 = tf.expand_dims(weighted_boxes[i, 2], axis = 0)\n          y2 = tf.expand_dims(weighted_boxes[i, 3], axis = 0)\n          lbl = tf.expand_dims(weighted_boxes[i, 5], axis = 0)\n          weighted_score = tf.expand_dims(weighted_score, axis = 0)\n\n          bbox = tf.concat([x1, y1, x2, y2, weighted_score, lbl], axis = 0)\n          bbox = tf.expand_dims(bbox, axis = 0)\n\n          begin = weighted_boxes[:i]\n          end = weighted_boxes[i + 1:]\n          weighted_boxes = tf.concat([begin, bbox, end], axis = 0)\n      weighted_boxes = weighted_boxes[:tf.squeeze(num_weighted)]\n      num_bounding_boxes = len(weighted_boxes)\n      cur_idx = tf.squeeze(bounding_idx)\n\n      begin = final_bounding_boxes[:cur_idx]\n      end = final_bounding_boxes[tf.cast(cur_idx, dtype =num_bounding_boxes.dtype)  + num_bounding_boxes:]\n      middle = weighted_boxes\n\n\n      bounding_idx = bounding_idx + tf.cast(num_bounding_boxes, dtype = bounding_idx.dtype)\n      if cur_idx == 0:\n        final_bounding_boxes = tf.concat([middle, end], axis = 0)\n      elif cur_idx + tf.cast(num_bounding_boxes, dtype = cur_idx.dtype) >= tf.cast(len(final_bounding_boxes), dtype = cur_idx.dtype):\n        final_bounding_boxes = tf.concat([begin, middle], axis = 0)\n      else:\n        final_bounding_boxes = tf.concat([begin, middle, end], axis = 0)\n      final_bounding_boxes = tf.reshape(final_bounding_boxes, (N, 6))\n    x1 = tf.expand_dims(final_bounding_boxes[:, 0], axis = 1)\n    y1 = tf.expand_dims(final_bounding_boxes[:, 1], axis = 1)\n    x2 = tf.expand_dims(final_bounding_boxes[:, 2], axis = 1)\n    y2 = tf.expand_dims(final_bounding_boxes[:, 3], axis = 1)\n    obj = tf.expand_dims(final_bounding_boxes[:, 4], axis = 1)\n    labels = final_bounding_boxes[:, 5]\n\n    boxes = tf.concat([x1, y1, x2, y2, obj], axis = 1)\n    return boxes, labels\n","metadata":{"id":"dnF8PMdwz1kK","execution":{"iopub.status.busy":"2021-07-04T20:01:45.858857Z","iopub.status.idle":"2021-07-04T20:01:45.85927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metric Computation: \"Accuracy\"(Actually Precision)","metadata":{"id":"bEGPAZKVrD14"}},{"cell_type":"code","source":"class Accuracy(keras.metrics.Metric):\n  # Average Accuracy Across Validation(close enough to ADA) \n  def __init__(self, name = 'accuracy', threshold = 0.5, **kwargs):\n    super().__init__(name = name, **kwargs)\n    self.threshold = threshold\n    self.tp = tf.Variable(tf.constant(0.0, dtype = TARGET_DTYPE))\n    self.fp = tf.Variable(tf.constant(0.0, dtype = TARGET_DTYPE))\n    self.fn = tf.Variable(tf.constant(0.0, dtype = TARGET_DTYPE))\n  def reset_states(self):\n    self.tp.assign(0.0)\n    self.fp.assign(0.0)\n    self.fn.assign(0.0)\n  @tf.function  \n  def update_state(self, GT_bbox, GT_class, pred_bbox, pred_class):\n    # GT_bbox: Tensor(B, N, 5)\n    # GT_class: Tensor(B, 196196, 5)\n    B = GT_bbox.shape[0]\n    for b in range(B):\n        ground_truth_bbox = GT_bbox[b] # (196196, 5)\n        ground_truth_class = ground_truth_bbox[:, -1:] # (196196, 1)\n        ground_truth_bbox = ground_truth_bbox[:, :-1] # (196196, 4)\n        \n        predicted_bounding_boxes = pred_bbox[b] # (196196, 5)\n        predicted_classes = predicted_bounding_boxes[:, -1:] # (196196, 1)\n        predicted_bounding_boxes = predicted_bounding_boxes[:, :-1] # (196196, 4)\n        \n        # Threshold the Bounding Boxes(to reduce the work of NMS)\n        \n    \n    self.matching_method(GT_bbox, GT_class, pred_bbox, pred_class)\n  def matching_method(self, GT_bbox, GT_class, pred_bbox, pred_class, threshold = None):\n    # Matches Bounding Boxes to Ground-Truths\n    if threshold is None:\n      threshold = self.threshold\n    # Bboxes: Tensor(M, 4) - Remove the OBJ score simply due to how these are already nms threshed.\n    # GT: Tensor(N, 4) - X1, Y1, X2, Y2 quads, no labels needed since there is only 1 class.\n    M, _ = GT_bbox.shape\n    N, _ = pred_bbox.shape\n    already_matched = tf.ones((N,), dtype = GT_bbox.dtype) * tf.constant(-1, dtype = GT_bbox.dtype)\n    for i in range(M):\n      ground_truth_class = GT_class[i] # (1,)\n      ground_truth = tf.expand_dims(GT_bbox[i], axis = 0) # (1, 4)\n      iou_computation = tf.squeeze(compute_iou(pred_bbox, ground_truth)) # (N, )\n      # Mask out the Previously Selected Bounding Boxes.\n      boolean_mask = tf.equal(already_matched, tf.constant(-1, dtype = pred_bbox.dtype)) # (N, )\n      boolean_mask = tf.cast(boolean_mask, dtype = pred_bbox.dtype) # (N, )\n      iou_computation = iou_computation * boolean_mask # (N, )\n      # Check if Any Bboxes Currently Match(IOU > 0.5) - Find the First One.\n      thresholded = iou_computation > threshold\n      index = tf.argmax(tf.cast(thresholded, dtype = TARGET_DTYPE))\n      if tf.reduce_sum(tf.cast(thresholded[index], tf.float32)) == 0.0:# and ground_truth_class == pred_class[index]:\n        # Nothing Found, so False Negative.\n        self.fn.assign_add(1.0)\n      else:\n        # Found One, remove this bounding box and increase tp\n        self.tp.assign_add(1.0) \n        already_matched = replace_index_scores(already_matched, index, tf.constant(1.0, dtype = pred_bbox.dtype))\n    # Find all False Positives Left\n    num_false_positives = tf.equal(already_matched, tf.constant(-1, dtype = pred_bbox.dtype))\n    num_false_positives = tf.cast(num_false_positives, dtype = TARGET_DTYPE)\n    num_false_positives = tf.reduce_sum(num_false_positives)\n\n    self.fp.assign_add(num_false_positives)      \n  def result(self):\n    tp = self.tp\n    fp = self.fp\n    fn = self.fn\n\n    eps = 1e-10\n    return (tp + eps) / (tp + fp + fn + eps)","metadata":{"id":"DLx83-wXrD14","execution":{"iopub.status.busy":"2021-07-04T20:01:45.860168Z","iopub.status.idle":"2021-07-04T20:01:45.860575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Definitions\n- Code Copied from GitHub Repo and slightly modified for easier training(outside of built in fn's).\n- Similar to Official AutoML EfficientDet.\n\n# Metric:\n- Thankfully, it's a really simple metric: Accuracy, where accuracy is computed using:\n- ACC = TP / (TP + FN + FP) \n-","metadata":{"id":"7u9nJLCZrD15"}},{"cell_type":"markdown","source":"EfficientNet Backbone(B4)","metadata":{"id":"KULeHCa8rD15"}},{"cell_type":"code","source":"def EfficientNetBN(n, input_tensor=None, input_shape=None, **kwargs):\n    CONV_KERNEL_INITIALIZER = {\n        'class_name': 'VarianceScaling',\n        'config': {\n            'scale': 2.0,\n            'mode': 'fan_out',\n            # EfficientNet actually uses an untruncated normal distribution for\n            # initializing conv layers, but keras.initializers.VarianceScaling use\n            # a truncated distribution.\n            # We decided against a custom initializer for better serializability.\n            'distribution': 'normal'\n        }\n    }\n\n    def get_swish():\n        def swish(x):\n            return x * tf.math.sigmoid(x)\n        return swish\n\n\n    def get_dropout():\n        class FixedDropout(layers.Dropout):\n            def _get_noise_shape(self, inputs):\n                if self.noise_shape is None:\n                    return self.noise_shape\n                symbolic_shape = tf.shape(inputs)\n                noise_shape = [symbolic_shape[axis] if (shape is None) else shape for axis, shape in enumerate(self.noise_shape)]\n                return tuple(noise_shape)\n        return FixedDropout\n\n\n    def round_filters(filters, width_coefficient, depth_divisor):\n        filters *= width_coefficient\n        new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n        new_filters = max(depth_divisor, new_filters)\n        if new_filters < 0.9 * filters:\n            new_filters += depth_divisor\n        return int(new_filters)\n\n\n    def round_repeats(repeats, depth_coefficient):\n        return int(math.ceil(depth_coefficient * repeats))\n\n\n    def mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', freeze_bn=False):\n        has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n        bn_axis = 3 \n\n        Dropout = get_dropout()\n\n        filters = block_args.input_filters * block_args.expand_ratio\n        if block_args.expand_ratio != 1:\n            x = layers.Conv2D(filters, 1, padding='same', use_bias=False, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'expand_conv')(inputs)\n            x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'expand_bn')(x)\n            x = layers.Activation(activation, name=prefix + 'expand_activation')(x)\n        else:\n            x = inputs\n\n        # Depthwise Convolution\n        x = layers.DepthwiseConv2D(block_args.kernel_size, strides=block_args.strides, padding='same', use_bias=False, depthwise_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'dwconv')(x)\n        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'bn')(x)\n        x = layers.Activation(activation, name=prefix + 'activation')(x)\n\n        # Squeeze and Excitation phase\n        if has_se:\n            num_reduced_filters = max(1, int(block_args.input_filters * block_args.se_ratio))\n            se_tensor = layers.GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)\n\n            target_shape = (1, 1, filters) if backend.image_data_format() == 'channels_last' else (filters, 1, 1)\n            se_tensor = layers.Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n            se_tensor = layers.Conv2D(num_reduced_filters, 1, activation=activation, padding='same', use_bias=True, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'se_reduce')(se_tensor)\n            se_tensor = layers.Conv2D(filters, 1, activation='sigmoid', padding='same', use_bias=True, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'se_expand')(se_tensor)\n            if backend.backend() == 'theano':\n                pattern = ([True, True, True, False] if (backend.image_data_format() == 'channels_last') else [True, False, True, True])\n                se_tensor = layers.Lambda(lambda x: backend.pattern_broadcast(x, pattern), name=prefix + 'se_broadcast')(se_tensor)\n            x = layers.multiply([x, se_tensor], name=prefix + 'se_excite')\n\n        # Output phase\n        x = layers.Conv2D(block_args.output_filters, 1, padding='same', use_bias=False, kernel_initializer=CONV_KERNEL_INITIALIZER, name=prefix + 'project_conv')(x)\n        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n        if block_args.id_skip and all(s == 1 for s in block_args.strides) and block_args.input_filters == block_args.output_filters:\n            if drop_rate and (drop_rate > 0):\n                x = Dropout(drop_rate, noise_shape=(None, 1, 1, 1), name=prefix + 'drop')(x)\n            x = layers.add([x, inputs], name=prefix + 'add')\n        return x\n\n\n    def EfficientNet(width_coefficient, depth_coefficient, drop_connect_rate=0.2, depth_divisor=8, input_tensor=None, input_shape=None, freeze_bn=False, **kwargs):\n        BlockArgs = collections.namedtuple('BlockArgs', [\n            'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n            'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n        ])\n        blocks_args = [\n            BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25),\n            BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112, expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25),\n            BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192, expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n            BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320, expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25)\n        ]\n        \n        features = []\n\n        img_input = layers.Input(shape=input_shape) if (input_tensor is None) else (input_tensor)\n\n        bn_axis = 3 \n        activation = get_swish(**kwargs)\n\n        # Build stem\n        x = img_input\n\n        x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer=CONV_KERNEL_INITIALIZER, name='stem_conv')(x)\n        x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)\n        x = layers.Activation(activation, name='stem_activation')(x)\n\n        # Build blocks\n        num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n        block_num = 0\n        for idx, block_args in enumerate(blocks_args):\n            assert block_args.num_repeat > 0\n            # Update block input and output filters based on depth multiplier.\n            block_args = block_args._replace(\n                input_filters=round_filters(block_args.input_filters, width_coefficient, depth_divisor),\n                output_filters=round_filters(block_args.output_filters, width_coefficient, depth_divisor),\n                num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n\n            # The first block needs to take care of stride and filter size increase.\n            drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n            x = mb_conv_block(x, block_args, activation=activation, drop_rate=drop_rate, prefix='block{}a_'.format(idx + 1), freeze_bn=freeze_bn)\n            block_num += 1\n            if block_args.num_repeat > 1:\n                # pylint: disable=protected-access\n                block_args = block_args._replace(\n                    input_filters=block_args.output_filters, strides=[1, 1])\n                # pylint: enable=protected-access\n                for bidx in range(block_args.num_repeat - 1):\n                    drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n                    block_prefix = 'block{}{}_'.format(idx + 1, string.ascii_lowercase[bidx + 1])\n                    x = mb_conv_block(x, block_args, activation=activation, drop_rate=drop_rate, prefix=block_prefix, freeze_bn=freeze_bn)\n                    block_num += 1\n            if idx < len(blocks_args) - 1 and blocks_args[idx + 1].strides[0] == 2:\n                features.append(x)\n            elif idx == len(blocks_args) - 1:\n                features.append(x)\n        return features\n\n    \n    parms = [\n        { \"width_coefficient\" : 1.0, \"depth_coefficient\" : 1.0, \"default_resolution\" : 224},\n        { \"width_coefficient\" : 1.0, \"depth_coefficient\" : 1.1, \"default_resolution\" : 240},\n        { \"width_coefficient\" : 1.1, \"depth_coefficient\" : 1.2, \"default_resolution\" : 260},\n        { \"width_coefficient\" : 1.2, \"depth_coefficient\" : 1.4, \"default_resolution\" : 300},\n        { \"width_coefficient\" : 1.4, \"depth_coefficient\" : 1.8, \"default_resolution\" : 380},\n        { \"width_coefficient\" : 1.6, \"depth_coefficient\" : 2.2, \"default_resolution\" : 456},\n        { \"width_coefficient\" : 1.8, \"depth_coefficient\" : 2.6, \"default_resolution\" : 528},\n        { \"width_coefficient\" : 2.0, \"depth_coefficient\" : 3.1, \"default_resolution\" : 600},\n    ][n]\n    return EfficientNet(parms['width_coefficient'], parms['depth_coefficient'], input_tensor=input_tensor, input_shape=input_shape, **kwargs)\n\n#print(EfficientNetBN(7, input_shape=(600, 600, 3)))","metadata":{"id":"dJ1nmjJ6rD15","execution":{"iopub.status.busy":"2021-07-04T20:01:45.861701Z","iopub.status.idle":"2021-07-04T20:01:45.862089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nMOMENTUM = 0.99\nEPSILON = 1e-3\n\nclass wBiFPNAdd(layers.Layer):\n    def __init__(self, epsilon=1e-4, **kwargs):\n        super(wBiFPNAdd, self).__init__(**kwargs)\n        self.epsilon = epsilon\n\n    def build(self, input_shape):\n        num_in = len(input_shape)\n        self.w = self.add_weight(name=self.name, shape=(num_in,), initializer=initializers.constant(1 / num_in), trainable=True, dtype= tf.float32)\n\n    def call(self, inputs, **kwargs):\n        w = tf.cast(activations.relu(self.w), dtype = inputs[0].dtype)\n        x = tf.reduce_sum([w[i] * inputs[i] for i in range(len(inputs))], axis=0)\n        x = x / (tf.reduce_sum(w) + self.epsilon)\n        return x\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0]\n\n    def get_config(self):\n        config = super(wBiFPNAdd, self).get_config()\n        config.update({ 'epsilon': self.epsilon })\n        return config\n    \n    \ndef SeparableConvBlock(num_channels, kernel_size, strides, name, freeze_bn=False):\n    f1 = layers.SeparableConv2D(num_channels, kernel_size=kernel_size, strides=strides, padding='same',\n                                use_bias=True, name=f'{name}/conv')\n    f2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name=f'{name}/bn')\n    return lambda *args, **kwargs: f2(f1(*args, **kwargs))\n\n\ndef build_wBiFPN(features, num_channels, id, freeze_bn=False):\n    if id == 0:\n        _, _, C3, C4, C5 = features\n        \n        # 第一次BIFPN需要 下采样 与 降通道 获得 p3_in p4_in p5_in p6_in p7_in\n        #-----------------------------下采样 与 降通道----------------------------#\n        P3_in = C3\n        \n        P3_in = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                              name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/conv2d')(P3_in)\n        P3_in = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                          name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/bn')(P3_in)\n\n        P4_in = C4\n        P4_in_1 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/conv2d')(P4_in)\n        P4_in_1 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/bn')(P4_in_1)\n        P4_in_2 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/conv2d')(P4_in)\n        P4_in_2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/bn')(P4_in_2)\n\n        P5_in = C5\n        P5_in_1 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/conv2d')(P5_in)\n        P5_in_1 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/bn')(P5_in_1)\n        P5_in_2 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/conv2d')(P5_in)\n        P5_in_2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/bn')(P5_in_2)\n\n        P6_in = layers.Conv2D(num_channels, kernel_size=1, padding='same', name='resample_p6/conv2d')(C5)\n        P6_in = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name='resample_p6/bn')(P6_in)\n        P6_in = layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='resample_p6/maxpool')(P6_in)\n\n        P7_in = layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='resample_p7/maxpool')(P6_in)\n        #-------------------------------------------------------------------------#\n        #--------------------------构建BIFPN的上下采样循环-------------------------#\n        P7_U = layers.UpSampling2D(dtype = tf.float16)(P7_in)\n        P6_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode0/add')([P6_in, P7_U])\n        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)\n        P6_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode0/op_after_combine5')(P6_td)\n        \n        P6_U = layers.UpSampling2D(dtype = tf.float16)(P6_td)\n        P5_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode1/add')([P5_in_1, P6_U])\n        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)\n        P5_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode1/op_after_combine6')(P5_td)\n\n        P5_U = layers.UpSampling2D(dtype = tf.float16)(P5_td)\n        P4_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode2/add')([P4_in_1, P5_U])\n        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)\n        P4_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode2/op_after_combine7')(P4_td)\n\n        P4_U = layers.UpSampling2D(dtype = tf.float16)(P4_td)\n        P3_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode3/add')([P3_in, P4_U])\n        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)\n        P3_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode3/op_after_combine8')(P3_out)\n\n        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P3_out)\n        P4_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode4/add')([P4_in_2, P4_td, P3_D])\n        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)\n        P4_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode4/op_after_combine9')(P4_out)\n\n        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P4_out)\n        P5_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode5/add')([P5_in_2, P5_td, P4_D])\n        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)\n        P5_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode5/op_after_combine10')(P5_out)\n\n        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P5_out)\n        P6_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode6/add')([P6_in, P6_td, P5_D])\n        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)\n        P6_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode6/op_after_combine11')(P6_out)\n\n        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P6_out)\n        P7_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode7/add')([P7_in, P6_D])\n        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)\n        P7_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode7/op_after_combine12')(P7_out)\n\n    else:\n        P3_in, P4_in, P5_in, P6_in, P7_in = features\n        # Change the Dtypes to float16\n        \n        \n        P7_U = layers.UpSampling2D(dtype = tf.float16)(P7_in)\n        P6_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode0/add')([P6_in, P7_U])\n        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)\n        P6_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode0/op_after_combine5')(P6_td)\n\n        P6_U = layers.UpSampling2D(dtype = tf.float16)(P6_td)\n        P5_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode1/add')([P5_in, P6_U])\n        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)\n        P5_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode1/op_after_combine6')(P5_td)\n\n        P5_U = layers.UpSampling2D(dtype = tf.float16)(P5_td)\n        P4_td = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode2/add')([P4_in, P5_U])\n        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)\n        P4_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode2/op_after_combine7')(P4_td)\n\n        P4_U = layers.UpSampling2D(dtype = tf.float16)(P4_td)\n        \n        P3_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode3/add')([P3_in, P4_U])\n        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)\n        P3_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode3/op_after_combine8')(P3_out)\n\n        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P3_out)\n        P4_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode4/add')([P4_in, P4_td, P3_D])\n        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)\n        P4_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode4/op_after_combine9')(P4_out)\n\n        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P4_out)\n        P5_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode5/add')([P5_in, P5_td, P4_D])\n        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)\n        P5_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode5/op_after_combine10')(P5_out)\n\n        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P5_out)\n        P6_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode6/add')([P6_in, P6_td, P5_D])\n        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)\n        P6_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode6/op_after_combine11')(P6_out)\n\n        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P6_out)\n        P7_out = wBiFPNAdd(name=f'fpn_cells/cell_{id}/fnode7/add')([P7_in, P6_D])\n        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)\n        P7_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode7/op_after_combine12')(P7_out)\n    return [P3_out, P4_out, P5_out, P6_out, P7_out]\ndef build_BiFPN(features, num_channels, id, freeze_bn=False):\n    if id == 0:\n        # 第一次BIFPN需要 下采样 与 降通道 获得 p3_in p4_in p5_in p6_in p7_in\n        #-----------------------------下采样 与 降通道----------------------------#\n        _, _, C3, C4, C5 = features\n        P3_in = C3\n        P3_in = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                              name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/conv2d')(P3_in)\n        P3_in = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                          name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/bn')(P3_in)\n\n        P4_in = C4\n        P4_in_1 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/conv2d')(P4_in)\n        P4_in_1 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/bn')(P4_in_1)\n        P4_in_2 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/conv2d')(P4_in)\n        P4_in_2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/bn')(P4_in_2)\n\n        P5_in = C5\n        P5_in_1 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/conv2d')(P5_in)\n        P5_in_1 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/bn')(P5_in_1)\n        P5_in_2 = layers.Conv2D(num_channels, kernel_size=1, padding='same',\n                                name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/conv2d')(P5_in)\n        P5_in_2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON,\n                                            name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/bn')(P5_in_2)\n\n        P6_in = layers.Conv2D(num_channels, kernel_size=1, padding='same', name='resample_p6/conv2d')(C5)\n        P6_in = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name='resample_p6/bn')(P6_in)\n        P6_in = layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='resample_p6/maxpool')(P6_in)\n\n        P7_in = layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='resample_p7/maxpool')(P6_in)\n        #-------------------------------------------------------------------------#\n\n        #--------------------------构建BIFPN的上下采样循环-------------------------#\n        P7_U = layers.UpSampling2D(dtype = tf.float16)(P7_in)\n        P6_td = layers.Add(name=f'fpn_cells/cell_{id}/fnode0/add')([P6_in, P7_U])\n        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)\n        P6_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode0/op_after_combine5')(P6_td)\n\n        P6_U = layers.UpSampling2D(dtype = tf.float16)(P6_td)\n        P5_td = layers.Add(name=f'fpn_cells/cell_{id}/fnode1/add')([P5_in_1, P6_U])\n        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)\n        P5_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode1/op_after_combine6')(P5_td)\n\n        P5_U = layers.UpSampling2D(dtype = tf.float16)(P5_td)\n        P4_td = layers.Add(name=f'fpn_cells/cell_{id}/fnode2/add')([P4_in_1, P5_U])\n        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)\n        P4_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode2/op_after_combine7')(P4_td)\n\n        P4_U = layers.UpSampling2D(dtype = tf.float16)(P4_td)\n        P3_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode3/add')([P3_in, P4_U])\n        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)\n        P3_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode3/op_after_combine8')(P3_out)\n\n        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P3_out)\n        P4_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode4/add')([P4_in_2, P4_td, P3_D])\n        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)\n        P4_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode4/op_after_combine9')(P4_out)\n\n        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P4_out)\n        P5_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode5/add')([P5_in_2, P5_td, P4_D])\n        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)\n        P5_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode5/op_after_combine10')(P5_out)\n\n        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P5_out)\n        P6_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode6/add')([P6_in, P6_td, P5_D])\n        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)\n        P6_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode6/op_after_combine11')(P6_out)\n\n        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P6_out)\n        P7_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode7/add')([P7_in, P6_D])\n        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)\n        P7_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode7/op_after_combine12')(P7_out)\n\n    else:\n        P3_in, P4_in, P5_in, P6_in, P7_in = features\n        P7_U = layers.UpSampling2D(dtype = tf.float16)(P7_in)\n        P6_td = layers.Add(name=f'fpn_cells/cell_{id}/fnode0/add')([P6_in, P7_U])\n        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)\n        P6_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode0/op_after_combine5')(P6_td)\n\n        P6_U = layers.UpSampling2D(dtype = tf.float16)(P6_td)\n        P5_td = layers.Add(name=f'fpn_cells/cell_{id}/fnode1/add')([P5_in, P6_U])\n        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)\n        P5_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode1/op_after_combine6')(P5_td)\n\n        P5_U = layers.UpSampling2D(dtype = tf.float16)(P5_td)\n        P4_td = layers.Add(name=f'fpn_cells/cell_{id}/fnode2/add')([P4_in, P5_U])\n        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)\n        P4_td = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                   name=f'fpn_cells/cell_{id}/fnode2/op_after_combine7')(P4_td)\n\n        P4_U = layers.UpSampling2D(dtype = tf.float16)(P4_td)\n        P3_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode3/add')([P3_in, P4_U])\n        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)\n        P3_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode3/op_after_combine8')(P3_out)\n\n        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P3_out)\n        P4_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode4/add')([P4_in, P4_td, P3_D])\n        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)\n        P4_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode4/op_after_combine9')(P4_out)\n\n        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P4_out)\n        P5_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode5/add')([P5_in, P5_td, P4_D])\n        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)\n        P5_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode5/op_after_combine10')(P5_out)\n\n        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P5_out)\n        P6_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode6/add')([P6_in, P6_td, P5_D])\n        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)\n        P6_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode6/op_after_combine11')(P6_out)\n\n        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(P6_out)\n        P7_out = layers.Add(name=f'fpn_cells/cell_{id}/fnode7/add')([P7_in, P6_D])\n        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)\n        P7_out = SeparableConvBlock(num_channels=num_channels, kernel_size=3, strides=1,\n                                    name=f'fpn_cells/cell_{id}/fnode7/op_after_combine12')(P7_out)\n    return [P3_out, P4_out, P5_out, P6_out, P7_out]\n\n\nclass PriorProbability(initializers.Initializer):\n    \"\"\" Apply a prior probability to the weights.\n    \"\"\"\n    def __init__(self, probability=0.01):\n        self.probability = probability\n\n    def get_config(self):\n        return { 'probability': self.probability }\n\n    def __call__(self, shape, dtype=None):\n        # set bias to -log((1 - p)/p) for foreground\n        result = np.ones(shape) * -math.log((1 - self.probability) / self.probability)\n\n        return result\n\n    \nclass BoxNet(layers.Layer):\n    def __init__(self, width, depth, num_anchors=9, freeze_bn=False, name='box_net', **kwargs):\n        super().__init__()\n        \n        self.width = width\n        self.depth = depth\n        self.num_anchors = num_anchors\n        options = {\n            'kernel_size': 3,\n            'strides': 1,\n            'padding': 'same',\n            'bias_initializer': 'zeros',\n            'depthwise_initializer': initializers.VarianceScaling(),\n            'pointwise_initializer': initializers.VarianceScaling(),\n        }\n\n        self.convs = [layers.SeparableConv2D(filters=width, name=f'{name}/box-{i}', **options) for i in range(depth)]\n        self.head = layers.SeparableConv2D(filters=num_anchors * 4, name=f'{name}/box-predict', **options)\n\n        self.bns = [\n            [layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name=f'{name}/box-{i}-bn-{j}') for j in\n             range(3, 8)]\n            for i in range(depth)]\n\n        self.relu = layers.Lambda(lambda x: tf.nn.swish(x))\n        self.reshape = layers.Reshape((-1, 4))\n\n    def call(self, inputs):\n        feature, level = inputs\n        for i in range(self.depth):\n            feature = self.convs[i](feature)\n            feature = self.bns[i][level](feature)\n            feature = self.relu(feature)\n        outputs = self.head(feature)\n        outputs = self.reshape(outputs)\n        return outputs\n\n\nclass ClassNet(layers.Layer):\n    def __init__(self, width, depth, num_classes=20, num_anchors=9, freeze_bn=False, name='class_net', **kwargs):\n        super().__init__()\n        \n        self.width = width\n        self.depth = depth\n        self.num_classes = num_classes\n        self.num_anchors = num_anchors\n        options = {\n            'kernel_size': 3,\n            'strides': 1,\n            'padding': 'same',\n            'depthwise_initializer': initializers.VarianceScaling(),\n            'pointwise_initializer': initializers.VarianceScaling(),\n        }\n\n        self.convs = [layers.SeparableConv2D(filters=width, bias_initializer='zeros', name=f'{name}/class-{i}', **options) for i in range(depth)]\n        self.head = layers.SeparableConv2D(filters=num_classes * num_anchors, bias_initializer=PriorProbability(probability=0.01), name=f'{name}/class-predict', **options)\n        self.bns = [[layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name=f'{name}/class-{i}-bn-{j}') for j in range(3, 8)] for i in range(depth)]\n        self.relu = layers.Lambda(lambda x: tf.nn.swish(x))\n        self.reshape = layers.Reshape((-1, num_classes))\n        self.activation = layers.Activation('sigmoid')\n\n    def call(self, inputs):\n        feature, level = inputs\n        for i in range(self.depth):\n            feature = self.convs[i](feature)\n            feature = self.bns[i][level](feature)\n            feature = self.relu(feature)\n        outputs = self.head(feature)\n        outputs = self.reshape(outputs)\n        outputs = self.activation(outputs)\n        return outputs\n\ndef Efficientdet(phi, num_classes=20, num_anchors=9, freeze_bn=True): # MY BATCH SIZE is 2, so no chance BN works.\n    assert phi in range(8)\n    fpn_num_filters = [64, 88, 112, 160, 224, 288, 384,384]\n    fpn_cell_repeats = [3, 4, 5, 6, 7, 7, 8, 8]\n    box_class_repeats = [3, 3, 3, 4, 4, 4, 5, 5]\n    image_sizes = [512, 640, 768, 896, 1024, 1024, 1024]\n    \n    image_input = layers.Input((image_sizes[phi], image_sizes[phi], 3), name='input', dtype = TARGET_DTYPE)\n    features = EfficientNetBN(phi, input_tensor=image_input, freeze_bn=freeze_bn)\n \n    fpn_features = features\n    if phi < 6:\n        for i in range(fpn_cell_repeats[phi]):\n            fpn_features = build_wBiFPN(fpn_features, fpn_num_filters[phi], i, freeze_bn=freeze_bn)\n    else:        \n        for i in range(fpn_cell_repeats[phi]):\n            fpn_features = build_BiFPN(fpn_features, fpn_num_filters[phi], i, freeze_bn=freeze_bn)\n\n    box_net = BoxNet(fpn_num_filters[phi], box_class_repeats[phi], num_anchors=num_anchors, freeze_bn=freeze_bn, name='box_net')\n    class_net = ClassNet(fpn_num_filters[phi], box_class_repeats[phi], num_classes=num_classes, num_anchors=num_anchors, freeze_bn=freeze_bn, name='class_net')\n    \n    classification = [class_net([feature, i]) for i, feature in enumerate(fpn_features)]\n    classification = layers.Concatenate(axis=1, name='classification')(classification)\n    regression = [box_net([feature, i]) for i, feature in enumerate(fpn_features)]\n    regression = layers.Concatenate(axis=1, name='regression')(regression)\n\n    model = models.Model(inputs=[image_input], outputs=[regression, classification], name='efficientdet')\n\n    return model","metadata":{"id":"gNHQAQearD15","execution":{"iopub.status.busy":"2021-07-04T20:01:45.863297Z","iopub.status.idle":"2021-07-04T20:01:45.863692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Focal Losses","metadata":{"id":"uUOKCHkqrD18"}},{"cell_type":"code","source":"# Classification Loss\ndef focal_loss(y_true, y_pred):\n    # Assign Y_true, Y_bbox, Y_pred\n    y_true = tf.cast(y_true, dtype = tf.float32)\n    y_pred = tf.cast(y_pred, dtype = tf.float32)\n    alpha=0.25 \n    gamma=2.0\n    # print(y_true.shape, y_pred.shape)\n    # y_true [batch_size, num_anchor, num_classes+1]\n    # y_pred [batch_size, num_anchor, num_classes]\n    anchor_state   = y_true # (B, Num_Anchors) # -1: ignrore, 0: background, 1: object\n    classification = y_pred # (B, Num_Anchors)\n\n\n    # Focal Loss for postive sample (Object)\n    pos_bool = tf.equal(anchor_state, tf.constant(1.0, dtype = anchor_state.dtype))\n    labels_for_object         = tf.boolean_mask(anchor_state, pos_bool)\n    classification_for_object = tf.boolean_mask(classification, pos_bool)\n    \n\n    alpha_factor_for_object = tf.ones_like(labels_for_object) * alpha\n    alpha_factor_for_object = tf.where(tf.equal(labels_for_object, 1), alpha_factor_for_object, 1 - alpha_factor_for_object)\n    focal_weight_for_object = tf.where(tf.equal(labels_for_object, 1), 1 - classification_for_object, classification_for_object)\n    focal_weight_for_object = alpha_factor_for_object * focal_weight_for_object ** gamma\n\n    cls_loss_for_object = focal_weight_for_object * backend.binary_crossentropy(labels_for_object, classification_for_object)\n    cls_loss_for_object = tf.reduce_sum(cls_loss_for_object)\n        \n    # Focal Loss for negative sample (Background)\n    neg_bool = tf.equal(anchor_state, tf.constant(0.0, dtype = anchor_state.dtype))\n    labels_for_back         = tf.boolean_mask(anchor_state, neg_bool)\n    classification_for_back = tf.boolean_mask(classification, neg_bool)\n\n    alpha_factor_for_back = tf.ones_like(labels_for_back) * (1 - alpha)\n    focal_weight_for_back = classification_for_back\n    focal_weight_for_back = alpha_factor_for_back * focal_weight_for_back ** gamma\n\n    cls_loss_for_back = focal_weight_for_back * backend.binary_crossentropy(labels_for_back, classification_for_back)\n    cls_loss_for_back = tf.reduce_sum(cls_loss_for_back)\n\n    # num of postive sample (Object) \n    normalizer = tf.where(tf.equal(anchor_state, 1))\n    normalizer = tf.cast(tf.shape(normalizer)[0], tf.float32)\n    normalizer = tf.maximum(normalizer, 1.0)\n\n\n    # totoal loss\n    loss = (cls_loss_for_object + cls_loss_for_back) / normalizer  # norm by num of postive samples\n    return loss\n\n# Regression Loss\n\ndef smooth_l1(y_true, y_pred, sigma =3.0):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    sigma_squared = sigma ** 2\n    # print(y_true.shape, y_pred.shape)\n    # y_true [batch_size, num_anchor, 5]\n    # y_pred [batch_size, num_anchor, 4]\n    \n    regression        = y_pred\n    regression_target = y_true[:, :, :-1]\n    anchor_state      = y_true[:, :, -1]\n\n    # Select postive samples\n    indices           = tf.where(tf.equal(anchor_state, 1))\n    regression        = tf.gather_nd(regression, indices)\n    regression_target = tf.gather_nd(regression_target, indices)\n\n    # compute smooth L1 loss\n    # f(x) = 0.5 * (sigma * x)^2   if |x| < 1 / sigma / sigma\n    # |x| - 0.5 / sigma / sigma    otherwise\n    regression_diff = regression - regression_target\n    regression_diff = tf.abs(regression_diff)\n    regression_loss = tf.where(regression_diff <= (1.0 / sigma_squared), 0.5 * sigma_squared * tf.math.pow(regression_diff, 2), regression_diff - 0.5 / sigma_squared)\n\n    # compute the normalizer: the number of positive anchors\n    normalizer = tf.maximum(tf.shape(indices)[0], 1)\n    normalizer = tf.cast(normalizer, tf.float32)\n    return tf.reduce_sum(regression_loss) / normalizer / 4\n\n","metadata":{"id":"1w0UafXKrD18","execution":{"iopub.status.busy":"2021-07-04T20:01:45.864545Z","iopub.status.idle":"2021-07-04T20:01:45.864942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build the Model","metadata":{"id":"hnNMRyVyrD18"}},{"cell_type":"code","source":"class ModelConfig:\n  num_classes = 1\n  phi = 4","metadata":{"id":"bRIXUSHshBTy","execution":{"iopub.status.busy":"2021-07-04T20:01:45.865749Z","iopub.status.idle":"2021-07-04T20:01:45.866151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model():\n  model = Efficientdet(4, num_classes=1)\n  model.load_weights('../input/pretrainedmodelwheat/model_32_0.1533_0.0336_0.1197_0.00006.h5', by_name=True, skip_mismatch=False)\n  return model","metadata":{"id":"Yj2X4M_mhGIo","execution":{"iopub.status.busy":"2021-07-04T20:01:45.86696Z","iopub.status.idle":"2021-07-04T20:01:45.86737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T20:01:45.868102Z","iopub.status.idle":"2021-07-04T20:01:45.868511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Lr Scheduler ","metadata":{"id":"olrroQXykjvL"}},{"cell_type":"code","source":"class ParamScheduler:\n    def __init__(self, start, end, num_iter):\n        self.start = start\n        self.end = end\n        self.num_iter = num_iter\n        self.idx = -1\n        \n    def step(self):\n        self.idx+=1\n        return self.func(self.start, self.end, self.idx/self.num_iter)\n    \n    def reset(self):\n        self.idx=-1\n        \n    def is_complete(self):\n        return self.idx >= self.num_iter\n\nclass CosineScheduler(ParamScheduler):\n    def func(self, start_val, end_val, pct):\n        cos_out = np.cos(np.pi * pct) + 1\n        return end_val + (start_val - end_val)/2 * cos_out\nclass ConstantScheduler(ParamScheduler):\n    def __init__(self, init_lr, num_steps):\n        self.init_lr = init_lr\n        self.num_steps = num_steps\n        self.steps = -1\n    def step(self):\n        self.steps += 1\n        return self.init_lr\n    def reset(self):\n        self.steps = -1\n    def is_complete(self):\n        return self.steps >= self.num_steps\nclass OneCycleScheduler(keras.callbacks.Callback):\n    \n    def __init__(self, init_lr, max_lr, min_lr, warm_steps, peak_steps, total_steps):\n        momentums=(0.95,0.85)\n        start_div=25.\n        pct_start=warm_steps\n        pct_climax = peak_steps# Stay at the peak for 0.1 of training.\n        verbose=True\n        sched=CosineScheduler\n        end_div=None\n        self.pct_climax = pct_climax\n        self.max_lr, self.momentums, self.start_div, self.pct_start, self.verbose, self.sched, self.end_div = max_lr, momentums, start_div, pct_start, verbose, sched, end_div\n        if self.end_div is None:\n            self.end_div = start_div * 1e4\n        self.logs = {}\n        self.min_lr = min_lr\n        self.init_lr = init_lr\n  \n        self.start_lr = self.max_lr/self.start_div\n        self.end_lr = self.max_lr/self.end_div \n        self.num_iter = int(total_steps * 0.8) # Pad the Steps a bit to make sure no overflow.\n        self.num_iter_1 = int(self.pct_start*self.num_iter)\n        self.num_iter_2 = int(self.pct_climax * self.num_iter)\n        self.num_iter_3 = self.num_iter - self.num_iter_1 - self.num_iter_2\n        \n        self.lr_scheds = (self.sched(self.start_lr, self.max_lr, self.num_iter_1), ConstantScheduler(self.max_lr, self.num_iter_2), self.sched(self.max_lr, self.end_lr, self.num_iter_3))\n        self.sched_idx = 0 \n        \n    def optimizer_params_step(self):\n        try:\n          next_lr = self.lr_scheds[self.sched_idx].step()\n        except:\n          next_lr = self.min_lr\n        next_lr = tf.maximum(next_lr, self.min_lr)\n        next_lr = tf.cast(next_lr, tf.float32)\n        # update optimizer params\n        return next_lr\n        \n    def step(self, idx):\n        for i in range(TRAIN_NUMBER // BATCH_SIZE):\n            lr = self.optimizer_params_step()\n        try:\n          if self.lr_scheds[self.sched_idx].is_complete():\n              self.sched_idx += 1\n        except:\n          pass\n        return lr","metadata":{"id":"H62cd9TZklAg","execution":{"iopub.status.busy":"2021-07-04T20:01:45.869355Z","iopub.status.idle":"2021-07-04T20:01:45.869736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grad Acc Adam","metadata":{"id":"f7tm42ZvuVdR"}},{"cell_type":"code","source":"class GradAccAdam():\n    # Just a Wrapper to Accumulate Gradients and Send them to Adam\n    def __init__(self, model, learning_rate, grad_acc_steps, prev_optim_path = None):\n        self.learning_rate = learning_rate\n        self.grad_acc_steps = grad_acc_steps\n        \n        self.weight_decay = TrainingConfig.weight_decay\n        self.optimizer = tfa.optimizers.AdamW(learning_rate = self.learning_rate, weight_decay = self.weight_decay)\n        \n        self.PrevModelPath = prev_optim_path\n        if self.PrevModelPath:\n            self.opt_weights = np.load(f'{self.PrevModelPath}optimizer_last.npy', allow_pickle = True)\n        \n            trainable_weights = model.trainable_weights\n            \n            zero_grads = [tf.zeros_like(w) for w in trainable_weights]\n            @tf.function\n            def f():\n                self.optimizer.apply_gradients(zip(zero_grads, trainable_weights))\n            strategy.run(f)\n            self.optimizer.set_weights(self.opt_weights)\n            print(\"Loaded Weights\")\n        \n        self.gradients = None\n        self.cur_grad_acc = 0\n    def apply_gradients(self, gradients, variables):\n        if self.gradients is None:\n            self.gradients = [g / tf.constant(float(self.grad_acc_steps)) for g in gradients]\n            self.cur_grad_acc += 1\n        else:\n            for i in range(len(gradients)):\n                self.gradients[i] += gradients[i] / tf.constant(float(self.grad_acc_steps))\n            self.cur_grad_acc += 1\n        if self.cur_grad_acc == self.grad_acc_steps:\n            self.optimizer.apply_gradients(zip(self.gradients, variables))\n            self.gradients = None\n            self.cur_grad_acc = 0","metadata":{"id":"bipgqrf6uXAz","execution":{"iopub.status.busy":"2021-07-04T20:01:45.870662Z","iopub.status.idle":"2021-07-04T20:01:45.871045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Config","metadata":{"id":"U269wY7QlFMi"}},{"cell_type":"code","source":"class TrainingConfig:\n  learning_rate = 1e-5\n  max_lr = 1e-4\n  min_lr = 1e-9\n  \n\n\n  WARM_STEPS = 0.1\n  PEAK_STEPS = 0.1\n\n  weight_decay = 0.\n\n  STEPS_PER_EPOCH = TRAIN_NUMBER // BATCH_SIZE\n  TOTAL_STEPS = STEPS_PER_EPOCH * NUM_EPOCHS","metadata":{"id":"ZdgZJpdylG7f","execution":{"iopub.status.busy":"2021-07-04T20:01:45.871868Z","iopub.status.idle":"2021-07-04T20:01:45.872268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model under TPU Strategy","metadata":{"id":"LuE-K6jzkguG"}},{"cell_type":"code","source":"def save_states(model_path):\n  save_path = f\"{DataModule.SAVE_PATH}{model_path}\"\n  optimizer_path = f\"{save_path}_optim.npy\"\n  with open(optimizer_path, 'w') as file:\n    pass\n  np.save(optimizer_path, optimizer.optimizer.get_weights())\n\n  model_path = f\"{save_path}_model.h5\"\n  with open(model_path, 'w') as file:\n    pass \n  model.save_weights(model_path)","metadata":{"id":"DkHrl8sPxM0x","execution":{"iopub.status.busy":"2021-07-04T20:01:45.873156Z","iopub.status.idle":"2021-07-04T20:01:45.873568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_model():\n  with strategy.scope():\n    print('-------------CREATING MODEL -------------------')\n    model = load_model()\n    print('-----------------CREATING LOSS_FN-------------')\n    def loss_fn(y_true_bbox, y_true_cls, y_pred_bbox, y_pred_cls):\n      y_true_bbox = tf.cast(y_true_bbox, tf.float32)\n      y_true_cls = tf.cast(y_true_cls, tf.float32)\n      y_pred_bbox = tf.cast(y_pred_bbox, tf.float32)\n      y_pred_cls = tf.cast(y_pred_cls, tf.float32)\n    \n      loss_bbox = smooth_l1(y_true_cls, y_pred_cls)\n      loss_cls = focal_loss(y_true_bbox, y_pred_bbox)\n      # Sum Loss\n      return loss_bbox + loss_cls\n    print('-------------------CREATING OPTIMIZERS--------------')\n    #optimizer = GradAccAdam(model, TrainingConfig.learning_rate, 1)\n    print('-----------------CREATING SCHEDULER------------------')\n    scheduler = OneCycleScheduler(TrainingConfig.learning_rate, TrainingConfig.max_lr, TrainingConfig.min_lr, TrainingConfig.WARM_STEPS, TrainingConfig.PEAK_STEPS, TrainingConfig.TOTAL_STEPS)\n    print('-----------------CREATING METRICS-------------------')\n    metrics = {\n        'train_loss': keras.metrics.Mean(),\n        'val_loss': keras.metrics.Mean(),\n        #'val_acc': Accuracy()\n    } # accuracy is too slow to reasonably Compute Anyways. I will use public LB as a evaluation metric.\n  return model, scheduler, loss_fn#model, optimizer, scheduler, loss_fn, metrics\n\n","metadata":{"id":"lc5SdTTyouNR","outputId":"b88764c6-658b-4c40-edac-09a5757b3666","execution":{"iopub.status.busy":"2021-07-04T20:01:45.874413Z","iopub.status.idle":"2021-07-04T20:01:45.8748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stat Logger.","metadata":{"id":"M0BCbST2zQKb"}},{"cell_type":"code","source":"class StatLogger():\n  def __init__(self):\n    self.best_loss = float('inf')\n    self.best_accuracy = 0.0\n    self.EPOCH = 0\n  #def on_epoch_end(self, epoch, logs = {}):\n    \n  def update_val(self):\n    # Updates at the end of a validation loop\n    # grab the metrics \n    train_loss = metrics['train_loss'].result().numpy().item()\n    val_loss = metrics['val_loss'].result().numpy().item() \n    val_acc = metrics['val_acc'].result().numpy().item()\n    \n    if val_loss <= self.best_loss:\n      self.best_loss = val_loss\n      save_states('loss')\n    if val_acc >= self.best_accuracy:\n      self.best_accuracy = val_acc\n      save_states('acc')\n    \n    print(f\"E: {self.EPOCH}, BL: {self.best_loss}, BA: {self.best_accuracy}, TL: {train_loss} VL: {val_loss}, VA: {val_acc}\")\n    self.EPOCH += 1\n","metadata":{"id":"67jnKTuTzRRT","execution":{"iopub.status.busy":"2021-07-04T20:01:45.875654Z","iopub.status.idle":"2021-07-04T20:01:45.876084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model using TPU's.","metadata":{"id":"jEYVLRk4rD19"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use Model.Fit \ndef train_model(fold_idx):\n    # Prepare Callbacks\n    lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler.step, verbose=1)\n    save_model = keras.callbacks.ModelCheckpoint(f'./best_model_{fold_idx}.h5', save_best_only = True, save_weights_only = True)\n    cbs = [\n        lr_schedule,\n        save_model\n    ]\n    \n    # Fit the Model\n    model.compile(\n        optimizer = tfa.optimizers.AdamW(\n            weight_decay = TrainingConfig.weight_decay,\n            learning_rate = TrainingConfig.learning_rate\n        ),\n        loss = {'regression': smooth_l1, 'classification': focal_loss}\n    )\n    train_dataset, val_dataset = get_dfs(fold_idx)\n    model.fit(\n        train_dataset,\n        epochs = NUM_EPOCHS,\n        callbacks = cbs,\n        steps_per_epoch = TRAIN_NUMBER // BATCH_SIZE,\n        validation_data = val_dataset,\n        validation_steps = VAL_NUMBER // BATCH_SIZE\n    )","metadata":{"execution":{"iopub.status.busy":"2021-07-04T20:01:45.877031Z","iopub.status.idle":"2021-07-04T20:01:45.877485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLDS_TO_TRAIN = [0]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T20:01:45.878366Z","iopub.status.idle":"2021-07-04T20:01:45.878772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for FOLD_IDX in FOLDS_TO_TRAIN:\n    model, scheduler, loss_fn = prepare_model()\n    train_model(FOLD_IDX)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T20:01:45.87982Z","iopub.status.idle":"2021-07-04T20:01:45.880248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-f9Le-kAXobD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}